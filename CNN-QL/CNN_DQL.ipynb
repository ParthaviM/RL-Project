{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpdOQQ2oyrSP",
    "outputId": "e82dffe5-9c40-45ec-a982-31c40a8fda41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/MyDrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-sR0Yo5S-kkA"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1oXTQcg2yuCC"
   },
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iSJzJ4MzyydC"
   },
   "outputs": [],
   "source": [
    "#initialize a new game\n",
    "def new_game(n):\n",
    "    matrix = np.zeros([n,n])\n",
    "    return matrix\n",
    "\n",
    "#add 2 or 4 in the matrix\n",
    "def add_two(mat):\n",
    "    empty_cells = []\n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat[0])):\n",
    "            if(mat[i][j]==0):\n",
    "                empty_cells.append((i,j))\n",
    "    if(len(empty_cells)==0):\n",
    "        return mat\n",
    "    \n",
    "    index_pair = empty_cells[random.randint(0,len(empty_cells)-1)]\n",
    "    \n",
    "    prob = random.random()\n",
    "    if(prob>=0.9):\n",
    "        mat[index_pair[0]][index_pair[1]]=4\n",
    "    else:\n",
    "        mat[index_pair[0]][index_pair[1]]=2\n",
    "    return mat\n",
    "\n",
    "#to check state of the game\n",
    "def game_state(mat):\n",
    "    #if 2048 in mat:\n",
    "    #    return 'win'\n",
    "    \n",
    "    for i in range(len(mat)-1): #intentionally reduced to check the row on the right and below\n",
    "        for j in range(len(mat[0])-1): #more elegant to use exceptions but most likely this will be their solution\n",
    "            if mat[i][j]==mat[i+1][j] or mat[i][j+1]==mat[i][j]:\n",
    "                return 'not over'\n",
    "            \n",
    "    for i in range(len(mat)): #check for any zero entries\n",
    "        for j in range(len(mat[0])):\n",
    "            if mat[i][j]==0:\n",
    "                return 'not over'\n",
    "            \n",
    "    for k in range(len(mat)-1): #to check the left/right entries on the last row\n",
    "        if mat[len(mat)-1][k]==mat[len(mat)-1][k+1]:\n",
    "            return 'not over'\n",
    "        \n",
    "    for j in range(len(mat)-1): #check up/down entries on last column\n",
    "        if mat[j][len(mat)-1]==mat[j+1][len(mat)-1]:\n",
    "            return 'not over'\n",
    "        \n",
    "    return 'lose'\n",
    "\n",
    "\n",
    "def reverse(mat):\n",
    "    new=[]\n",
    "    for i in range(len(mat)):\n",
    "        new.append([])\n",
    "        for j in range(len(mat[0])):\n",
    "            new[i].append(mat[i][len(mat[0])-j-1])\n",
    "    return new\n",
    "\n",
    "def transpose(mat):\n",
    "    new=[]\n",
    "    for i in range(len(mat[0])):\n",
    "        new.append([])\n",
    "        for j in range(len(mat)):\n",
    "            new[i].append(mat[j][i])\n",
    "            \n",
    "    return np.transpose(mat)\n",
    "\n",
    "def cover_up(mat):\n",
    "    new = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "    done = False\n",
    "    for i in range(4):\n",
    "        count = 0\n",
    "        for j in range(4):\n",
    "            if mat[i][j]!=0:\n",
    "                new[i][count] = mat[i][j]\n",
    "                if j!=count:\n",
    "                    done=True\n",
    "                count+=1\n",
    "    return (new,done)\n",
    "\n",
    "def merge(mat):\n",
    "    done=False\n",
    "    score = 0\n",
    "    for i in range(4):\n",
    "        for j in range(3):\n",
    "            if mat[i][j]==mat[i][j+1] and mat[i][j]!=0:\n",
    "                mat[i][j]*=2\n",
    "                score += mat[i][j]   \n",
    "                mat[i][j+1]=0\n",
    "                done=True\n",
    "    return (mat,done,score)\n",
    "\n",
    "#up move\n",
    "def up(game):\n",
    "        game = transpose(game)\n",
    "        game,done = cover_up(game)\n",
    "        temp = merge(game)\n",
    "        game = temp[0]\n",
    "        done = done or temp[1]\n",
    "        game = cover_up(game)[0]\n",
    "        game = transpose(game)\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#down move\n",
    "def down(game):\n",
    "        game=reverse(transpose(game))\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        game=transpose(reverse(game))\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#left move\n",
    "def left(game):\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        return (game,done,temp[2])\n",
    "\n",
    "#right move\n",
    "def right(game):\n",
    "        game=reverse(game)\n",
    "        game,done=cover_up(game)\n",
    "        temp=merge(game)\n",
    "        game=temp[0]\n",
    "        done=done or temp[1]\n",
    "        game=cover_up(game)[0]\n",
    "        game=reverse(game)\n",
    "        return (game,done,temp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0TNlOH9y2fs"
   },
   "source": [
    "# Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yRGrLNALy0Ji"
   },
   "outputs": [],
   "source": [
    "controls = {0:up,1:left,2:right,3:down}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyZS7lkpy5dC"
   },
   "source": [
    "# Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fKf0nW44y4GY"
   },
   "outputs": [],
   "source": [
    "#convert the input game matrix into corresponding power of 2 matrix.\n",
    "def change_values(X):\n",
    "    power_mat = np.zeros(shape=(1,4,4,16),dtype=np.float32)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if(X[i][j]==0):\n",
    "                power_mat[0][i][j][0] = 1.0\n",
    "            else:\n",
    "                power = int(math.log(X[i][j],2))\n",
    "                power_mat[0][i][j][power] = 1.0\n",
    "    return power_mat        \n",
    "\n",
    "#find the number of empty cells in the game matrix.\n",
    "def findemptyCell(mat):\n",
    "    count = 0\n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat)):\n",
    "            if(mat[i][j]==0):\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFs88u54y8dW"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ItFsSrs8y7G6"
   },
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "start_learning_rate = 0.0005\n",
    "\n",
    "#gamma for Q-learning\n",
    "gamma = 0.9\n",
    "\n",
    "#epsilon greedy approach\n",
    "epsilon = 0.9\n",
    "\n",
    "#to store states and lables of the game for training\n",
    "#states of the game\n",
    "replay_memory = list()\n",
    "\n",
    "#labels of the states\n",
    "replay_labels = list()\n",
    "\n",
    "#capacity of memory\n",
    "mem_capacity = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CEC90QdRy9r9"
   },
   "outputs": [],
   "source": [
    "#first convolution layer depth\n",
    "depth1 = 128\n",
    "\n",
    "#second convolution layer depth\n",
    "depth2 = 128\n",
    "\n",
    "#batch size for batch gradient descent\n",
    "batch_size = 512\n",
    "\n",
    "#input units\n",
    "input_units = 16\n",
    "\n",
    "#fully connected layer neurons\n",
    "hidden_units = 256\n",
    "\n",
    "#output neurons = number of moves\n",
    "output_units = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjhpQNhGzAhs"
   },
   "source": [
    "# Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMorO_Rqy_ET",
    "outputId": "d374b384-1742-45d0-961e-576622601eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsJebcPMzBtu",
    "outputId": "3480c547-c832-45f4-eb86-7f7b0dbf9d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/rmsprop.py:188: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#input data\n",
    "tf_batch_dataset = tf.placeholder(tf.float32,shape=(batch_size,4,4,16))\n",
    "tf_batch_labels  = tf.placeholder(tf.float32,shape=(batch_size,output_units))\n",
    "\n",
    "single_dataset   = tf.placeholder(tf.float32,shape=(1,4,4,16))\n",
    "\n",
    "\n",
    "#CONV LAYERS\n",
    "#conv layer1 weights\n",
    "conv1_layer1_weights = tf.Variable(tf.truncated_normal([1,2,input_units,depth1],mean=0,stddev=0.01))\n",
    "conv2_layer1_weights = tf.Variable(tf.truncated_normal([2,1,input_units,depth1],mean=0,stddev=0.01))\n",
    "\n",
    "#conv layer2 weights\n",
    "conv1_layer2_weights = tf.Variable(tf.truncated_normal([1,2,depth1,depth2],mean=0,stddev=0.01))\n",
    "conv2_layer2_weights = tf.Variable(tf.truncated_normal([2,1,depth1,depth2],mean=0,stddev=0.01))\n",
    "\n",
    "#conv layer1 biases\n",
    "\n",
    "#FUllY CONNECTED LAYERS\n",
    "expand_size = 2*4*depth2*2 + 3*3*depth2*2 + 4*3*depth1*2\n",
    "fc_layer1_weights = tf.Variable(tf.truncated_normal([expand_size,hidden_units],mean=0,stddev=0.01))\n",
    "fc_layer1_biases = tf.Variable(tf.truncated_normal([1,hidden_units],mean=0,stddev=0.01))\n",
    "fc_layer2_weights = tf.Variable(tf.truncated_normal([hidden_units,output_units],mean=0,stddev=0.01))\n",
    "fc_layer2_biases = tf.Variable(tf.truncated_normal([1,output_units],mean=0,stddev=0.01))\n",
    "\n",
    "\n",
    "#model\n",
    "def model(dataset):\n",
    "    #layer1\n",
    "    conv1 = tf.nn.conv2d(dataset,conv1_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    conv2 = tf.nn.conv2d(dataset,conv2_layer1_weights,[1,1,1,1],padding='VALID') \n",
    "    \n",
    "    #layer1 relu activation\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    #layer2\n",
    "    conv11 = tf.nn.conv2d(relu1,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv12 = tf.nn.conv2d(relu1,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    conv21 = tf.nn.conv2d(relu2,conv1_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "    conv22 = tf.nn.conv2d(relu2,conv2_layer2_weights,[1,1,1,1],padding='VALID') \n",
    "\n",
    "    #layer2 relu activation\n",
    "    relu11 = tf.nn.relu(conv11)\n",
    "    relu12 = tf.nn.relu(conv12)\n",
    "    relu21 = tf.nn.relu(conv21)\n",
    "    relu22 = tf.nn.relu(conv22)\n",
    "    \n",
    "    #get shapes of all activations\n",
    "    shape1 = relu1.get_shape().as_list()\n",
    "    shape2 = relu2.get_shape().as_list()\n",
    "    \n",
    "    shape11 = relu11.get_shape().as_list()\n",
    "    shape12 = relu12.get_shape().as_list()\n",
    "    shape21 = relu21.get_shape().as_list()\n",
    "    shape22 = relu22.get_shape().as_list()\n",
    "\n",
    "    #expansion\n",
    "    hidden1 = tf.reshape(relu1,[shape1[0],shape1[1]*shape1[2]*shape1[3]])\n",
    "    hidden2 = tf.reshape(relu2,[shape2[0],shape2[1]*shape2[2]*shape2[3]])\n",
    "    \n",
    "    hidden11 = tf.reshape(relu11,[shape11[0],shape11[1]*shape11[2]*shape11[3]])\n",
    "    hidden12 = tf.reshape(relu12,[shape12[0],shape12[1]*shape12[2]*shape12[3]])\n",
    "    hidden21 = tf.reshape(relu21,[shape21[0],shape21[1]*shape21[2]*shape21[3]])\n",
    "    hidden22 = tf.reshape(relu22,[shape22[0],shape22[1]*shape22[2]*shape22[3]])\n",
    "\n",
    "    #concatenation\n",
    "    hidden = tf.concat([hidden1,hidden2,hidden11,hidden12,hidden21,hidden22],axis=1)\n",
    "\n",
    "    #full connected layers\n",
    "    hidden = tf.matmul(hidden,fc_layer1_weights) + fc_layer1_biases\n",
    "    hidden = tf.nn.relu(hidden)\n",
    "\n",
    "    #output layer\n",
    "    output = tf.matmul(hidden,fc_layer2_weights) + fc_layer2_biases\n",
    "    \n",
    "    #return output\n",
    "    return output\n",
    "\n",
    "#for single example\n",
    "single_output = model(single_dataset)\n",
    "\n",
    "#for batch data\n",
    "logits = model(tf_batch_dataset)\n",
    "\n",
    "#loss\n",
    "loss = tf.square(tf.subtract(tf_batch_labels,logits))\n",
    "loss = tf.reduce_sum(loss,axis=1,keep_dims=True)\n",
    "loss = tf.reduce_mean(loss)/2.0\n",
    "\n",
    "#optimizer\n",
    "global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "learning_rate = tf.train.exponential_decay(float(start_learning_rate), global_step, 1000, 0.90, staircase=True)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3-qcKNZnzFqZ"
   },
   "outputs": [],
   "source": [
    "#loss\n",
    "J = []\n",
    "\n",
    "#scores\n",
    "scores = []\n",
    "\n",
    "#to store final parameters\n",
    "final_parameters = {}\n",
    "\n",
    "#number of episodes\n",
    "M = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2po2Qk9zJkj"
   },
   "source": [
    "Create training dataset and Train Simultaneously\n",
    "* Current Reward = number of merges + log(new max,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFnqqxRDzH6k",
    "outputId": "e3128609-a9db-4505-afb3-8e0c768bc865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8714 finished with score 2908.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 16. 256.   8.   4.]\n",
      " [ 32.  16. 128.  32.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8715 finished with score 784.0, result : lose board : [[2.0, 16.0, 8.0, 4], [32.0, 64.0, 16.0, 8.0], [2.0, 16.0, 32.0, 4.0], [8.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8716 finished with score 1592.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 16.0, 64.0, 8.0], [128.0, 64.0, 8.0, 4.0], [16.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8717 finished with score 3096.0, result : lose board : [[ 64.   2.   4.   2.]\n",
      " [  4. 256.  32.   8.]\n",
      " [128.  32.  16.   4.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8718 finished with score 1664.0, result : lose board : [[  4.  16.   2.   4.]\n",
      " [  2. 128.  16.   8.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  8.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8719 finished with score 1908.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [128.  32.   8.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8720 finished with score 1712.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [ 64.  32.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 64.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8721 finished with score 2648.0, result : lose board : [[32.0, 4.0, 16.0, 2], [64.0, 16.0, 8.0, 4.0], [256.0, 32.0, 16.0, 8.0], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8722 finished with score 3224.0, result : lose board : [[ 16   2  16   2]\n",
      " [ 32   8  32   4]\n",
      " [128 256  16   8]\n",
      " [  2  64   4   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8723 finished with score 3104.0, result : lose board : [[32.0, 8.0, 4, 2], [128.0, 4.0, 8.0, 4.0], [256.0, 64.0, 16.0, 2.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8724 finished with score 1712.0, result : lose board : [[8.0, 2.0, 16.0, 4.0], [128.0, 16.0, 8.0, 2.0], [16.0, 128.0, 2.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8725 finished with score 884.0, result : lose board : [[16.  8.  2.  4.]\n",
      " [ 2. 32. 64.  8.]\n",
      " [ 8. 16.  4.  2.]\n",
      " [64.  2.  8.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8726 finished with score 5260.0, result : lose board : [[ 16.   2.   8.   4.]\n",
      " [  2.  32.  16.   2.]\n",
      " [ 32. 128. 512.   4.]\n",
      " [  4.  16.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8727 finished with score 576.0, result : lose board : [[2.0, 8.0, 4.0, 2], [4.0, 64.0, 2.0, 8.0], [8.0, 32.0, 8.0, 4.0], [4.0, 8.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8728 finished with score 3048.0, result : lose board : [[8.0, 64.0, 4.0, 2.0], [128.0, 256.0, 16.0, 8.0], [8.0, 16.0, 32.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8729 finished with score 1508.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [64.0, 32.0, 8.0, 2.0], [8.0, 128.0, 32.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8730 finished with score 3140.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [128.  64.  32.   4.]\n",
      " [  4. 256.   2.  16.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8731 finished with score 3524.0, result : lose board : [[ 64.  16.   8.   2.]\n",
      " [  2.  32.  64.   4.]\n",
      " [256. 128.  16.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8732 finished with score 2544.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 16.  64.  32.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8733, Score : 5584.0, Iters : 400, Finish : lose\n",
      "Episode 8733 finished with score 5584.0, result : lose board : [[2.0, 16.0, 32.0, 2.0], [128.0, 512.0, 16.0, 4.0], [8.0, 64.0, 32.0, 8.0], [2.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8734 finished with score 2316.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [128.  64.  16.   8.]\n",
      " [  2. 128.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8735 finished with score 3312.0, result : lose board : [[2.0, 16.0, 64.0, 4.0], [64.0, 32.0, 4.0, 2.0], [4.0, 256.0, 2.0, 8.0], [16.0, 128.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8736 finished with score 1568.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [ 64. 128.  16.   8.]\n",
      " [  4.  16.  32.   4.]\n",
      " [ 32.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8737 finished with score 1372.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [ 16.   8.  16.   4.]\n",
      " [  4.  64. 128.   8.]\n",
      " [ 16.   4.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8738 finished with score 4376.0, result : lose board : [[8.0, 32.0, 4.0, 2], [2.0, 512.0, 2.0, 32.0], [8.0, 4.0, 16.0, 2.0], [2.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 213, Loss : 0.5504631996154785\n",
      "Mini-Batch - 1 Back-Prop : 213, Loss : 0.4481413662433624\n",
      "Mini-Batch - 2 Back-Prop : 213, Loss : 0.43977952003479004\n",
      "Mini-Batch - 3 Back-Prop : 213, Loss : 0.45851388573646545\n",
      "Mini-Batch - 4 Back-Prop : 213, Loss : 0.5370244979858398\n",
      "Mini-Batch - 5 Back-Prop : 213, Loss : 1.2469587326049805\n",
      "Mini-Batch - 6 Back-Prop : 213, Loss : 0.563930094242096\n",
      "Mini-Batch - 7 Back-Prop : 213, Loss : 0.5774917006492615\n",
      "Mini-Batch - 8 Back-Prop : 213, Loss : 0.6679097414016724\n",
      "Mini-Batch - 9 Back-Prop : 213, Loss : 0.8394653797149658\n",
      "Mini-Batch - 10 Back-Prop : 213, Loss : 0.8128174543380737\n",
      "Episode 8739 finished with score 3300.0, result : lose board : [[  4.   2.   4.   2.]\n",
      " [ 64.  32.   8. 128.]\n",
      " [  2.  64. 256.   4.]\n",
      " [  8.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8740 finished with score 3096.0, result : lose board : [[  2.  64.  16.   2.]\n",
      " [256.  16.  32.   4.]\n",
      " [  4. 128.  16.   2.]\n",
      " [  8.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8741 finished with score 1328.0, result : lose board : [[16.0, 8.0, 4.0, 2], [4.0, 2.0, 16.0, 4.0], [128.0, 32.0, 2.0, 8.0], [16.0, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8742 finished with score 844.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2, 4.0, 64.0, 8.0], [64.0, 16.0, 8.0, 2.0], [2.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8743 finished with score 3480.0, result : lose board : [[16.0, 8, 2, 4], [4.0, 32.0, 64.0, 8.0], [64.0, 256.0, 32.0, 2.0], [2.0, 128.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8744 finished with score 1284.0, result : lose board : [[4.0, 32.0, 8.0, 4.0], [8.0, 128.0, 32.0, 2.0], [16.0, 32.0, 16.0, 4.0], [2.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8745 finished with score 2352.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [4, 256.0, 64.0, 8.0], [32.0, 8.0, 4.0, 2.0], [4.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8746 finished with score 3472.0, result : lose board : [[2.0, 4.0, 64.0, 4.0], [32.0, 256.0, 128.0, 16.0], [8.0, 32.0, 8.0, 4.0], [64.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8747 finished with score 2460.0, result : lose board : [[32.0, 16.0, 4.0, 2], [2.0, 256.0, 64.0, 4.0], [32.0, 16.0, 2.0, 8.0], [8.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8748 finished with score 5008.0, result : lose board : [[32.0, 8.0, 2, 4], [512.0, 16.0, 32.0, 8.0], [2.0, 64.0, 8.0, 4.0], [64.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8749 finished with score 3136.0, result : lose board : [[16.0, 4.0, 32.0, 2.0], [128.0, 64.0, 4.0, 8.0], [8.0, 256.0, 2.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8750 finished with score 2488.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4.  32. 256.   8.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8751 finished with score 1632.0, result : lose board : [[16.0, 8.0, 4, 2], [128.0, 2.0, 8.0, 4.0], [4.0, 128.0, 4.0, 2.0], [2.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8752 finished with score 2052.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [ 64. 128.  64.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8753 finished with score 1564.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [64.0, 8.0, 16.0, 4.0], [16.0, 64.0, 128.0, 2.0], [8.0, 2.0, 8.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8754 finished with score 2480.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [16.0, 32.0, 8.0, 4.0], [2.0, 256.0, 64.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8755 finished with score 3288.0, result : lose board : [[32.0, 8.0, 4.0, 2], [256.0, 64.0, 8.0, 32.0], [4.0, 32.0, 128.0, 4.0], [16.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8756 finished with score 1668.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [  4.  64.  32.   2.]\n",
      " [ 32. 128.  64.   8.]\n",
      " [  2.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8757 finished with score 3028.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [32.0, 256.0, 32.0, 4.0], [4.0, 128.0, 16.0, 8.0], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8758 finished with score 608.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 32.0, 2.0, 4.0], [2.0, 64.0, 4.0, 8.0], [16.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8759 finished with score 2840.0, result : lose board : [[16.0, 8.0, 4, 2], [4.0, 128.0, 16.0, 8.0], [16.0, 256.0, 32.0, 2.0], [8.0, 4.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8760 finished with score 2048.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [ 64. 128.  64.   8.]\n",
      " [  8.  32.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8761 finished with score 4780.0, result : lose board : [[8.0, 32.0, 8.0, 2.0], [512.0, 8.0, 64.0, 4.0], [32.0, 2.0, 16.0, 8.0], [4.0, 32.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8762 finished with score 720.0, result : lose board : [[16  2  4  2]\n",
      " [32 64 16  8]\n",
      " [ 4 32  2  4]\n",
      " [ 2 16  8  2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8763 finished with score 1716.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [64.0, 4.0, 64.0, 4.0], [4.0, 128.0, 32.0, 8.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8764 finished with score 2292.0, result : lose board : [[2, 8.0, 4, 2], [8.0, 64.0, 8.0, 4.0], [32.0, 16.0, 256.0, 2.0], [2.0, 8.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8765 finished with score 2592.0, result : lose board : [[4.0, 32.0, 4, 2], [64.0, 16.0, 8.0, 16.0], [256.0, 32.0, 16.0, 2.0], [32.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8766 finished with score 676.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [32.0, 8.0, 32.0, 4.0], [8.0, 2.0, 16.0, 8.0], [2.0, 64.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8767 finished with score 1732.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 64. 128.  32.   8.]\n",
      " [  8.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 214, Loss : 0.5399587750434875\n",
      "Mini-Batch - 1 Back-Prop : 214, Loss : 0.7142003774642944\n",
      "Mini-Batch - 2 Back-Prop : 214, Loss : 0.5247362852096558\n",
      "Mini-Batch - 3 Back-Prop : 214, Loss : 0.5634325742721558\n",
      "Mini-Batch - 4 Back-Prop : 214, Loss : 0.6366731524467468\n",
      "Mini-Batch - 5 Back-Prop : 214, Loss : 1.2094159126281738\n",
      "Mini-Batch - 6 Back-Prop : 214, Loss : 0.9859685897827148\n",
      "Mini-Batch - 7 Back-Prop : 214, Loss : 0.5434043407440186\n",
      "Mini-Batch - 8 Back-Prop : 214, Loss : 0.5538525581359863\n",
      "Mini-Batch - 9 Back-Prop : 214, Loss : 0.4918849766254425\n",
      "Mini-Batch - 10 Back-Prop : 214, Loss : 0.6250216364860535\n",
      "Episode 8768 finished with score 824.0, result : lose board : [[2.0, 32.0, 8.0, 2], [4.0, 64.0, 16.0, 8.0], [32.0, 8.0, 32.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8769 finished with score 3056.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 32.0, 2.0, 4.0], [256.0, 128.0, 16.0, 8.0], [64.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8770 finished with score 4808.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [16.0, 32.0, 64.0, 4.0], [32.0, 512.0, 32.0, 8.0], [2, 16.0, 8.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8771 finished with score 2480.0, result : lose board : [[2.0, 8.0, 4.0, 2], [16.0, 256.0, 32.0, 4.0], [32.0, 64.0, 16.0, 2.0], [16.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8772 finished with score 1712.0, result : lose board : [[2.0, 32.0, 4, 2], [4.0, 64.0, 16.0, 8.0], [2.0, 128.0, 64.0, 2.0], [4.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8773 finished with score 1532.0, result : lose board : [[2.0, 4.0, 32.0, 4.0], [8.0, 64.0, 8.0, 16.0], [4.0, 128.0, 32.0, 4.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8774 finished with score 3192.0, result : lose board : [[32.0, 16.0, 4.0, 2], [2, 128.0, 64.0, 4.0], [256.0, 16.0, 8.0, 2.0], [2.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8775 finished with score 1352.0, result : lose board : [[  2.   4.  16.   2.]\n",
      " [  8.  32.   4.   8.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 16.   4.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8776 finished with score 1456.0, result : lose board : [[16.0, 8.0, 4.0, 2], [8.0, 128.0, 16.0, 4.0], [32.0, 64.0, 32.0, 8.0], [4.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8777 finished with score 3384.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [128.  32.  64.   4.]\n",
      " [  4. 256.  16.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8778 finished with score 1452.0, result : lose board : [[32.0, 8.0, 4, 2], [128.0, 32.0, 16.0, 4.0], [64.0, 8.0, 4.0, 2.0], [16.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8779 finished with score 2244.0, result : lose board : [[ 32.   2.   4.   2.]\n",
      " [  4.  32. 256.   8.]\n",
      " [ 16.   2.  16.   4.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8780 finished with score 5440.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  4.  32. 128.   4.]\n",
      " [ 32. 512.  16.   8.]\n",
      " [  2.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8781 finished with score 3500.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [  4.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8782 finished with score 2612.0, result : lose board : [[4.0, 8.0, 4.0, 2], [64.0, 32.0, 16.0, 8.0], [256.0, 2.0, 64.0, 4.0], [16.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8783 finished with score 5524.0, result : lose board : [[32.0, 8, 4, 2], [128.0, 32.0, 16.0, 8.0], [512.0, 64.0, 8.0, 2.0], [4.0, 32.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8784 finished with score 1576.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [128.   2.  32.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8785 finished with score 3224.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [256. 128.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8786 finished with score 3188.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 256.0, 32.0, 8.0], [128.0, 64.0, 16.0, 4.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8787 finished with score 1640.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [64.0, 32.0, 16.0, 4.0], [2.0, 128.0, 32.0, 8.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8788 finished with score 1716.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [4.0, 64.0, 16.0, 4.0], [2.0, 128.0, 64.0, 8.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8789 finished with score 2984.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [128.  32.  16.   4.]\n",
      " [  4. 256.  32.   8.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8790 finished with score 724.0, result : lose board : [[2, 8.0, 16.0, 2], [16.0, 64.0, 8.0, 4.0], [2.0, 32.0, 2.0, 8.0], [32.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8791 finished with score 3192.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 32. 256.   8.   4.]\n",
      " [128.   4.  32.  16.]\n",
      " [  4.  64.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8792 finished with score 2800.0, result : lose board : [[4.0, 16.0, 8.0, 2], [64.0, 32.0, 16.0, 4.0], [4.0, 256.0, 32.0, 8.0], [2.0, 64.0, 4.0, 16.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8793 finished with score 3296.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [32.0, 256.0, 32.0, 8.0], [64.0, 128.0, 8.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8794 finished with score 1740.0, result : lose board : [[2.0, 16.0, 4.0, 2], [64.0, 32.0, 8.0, 16.0], [128.0, 64.0, 4.0, 2.0], [16.0, 4.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 215, Loss : 0.5333817005157471\n",
      "Mini-Batch - 1 Back-Prop : 215, Loss : 0.2855054438114166\n",
      "Mini-Batch - 2 Back-Prop : 215, Loss : 0.6272160410881042\n",
      "Mini-Batch - 3 Back-Prop : 215, Loss : 0.4383910596370697\n",
      "Mini-Batch - 4 Back-Prop : 215, Loss : 0.5493190288543701\n",
      "Mini-Batch - 5 Back-Prop : 215, Loss : 0.5146888494491577\n",
      "Mini-Batch - 6 Back-Prop : 215, Loss : 0.4058094024658203\n",
      "Mini-Batch - 7 Back-Prop : 215, Loss : 0.4433870017528534\n",
      "Mini-Batch - 8 Back-Prop : 215, Loss : 0.5509531497955322\n",
      "Mini-Batch - 9 Back-Prop : 215, Loss : 0.3507039546966553\n",
      "Mini-Batch - 10 Back-Prop : 215, Loss : 0.6707749962806702\n",
      "Episode 8795 finished with score 1292.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [2.0, 32.0, 16.0, 8.0], [32.0, 128.0, 8.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8796 finished with score 3008.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [  2. 256.  16.   2.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [ 16.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8797 finished with score 1600.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2.0, 64.0, 2.0, 4.0], [8.0, 128.0, 16.0, 8.0], [2.0, 8.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8798 finished with score 4736.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [512.  64.  32.   8.]\n",
      " [ 16.   4.  16.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8799 finished with score 3212.0, result : lose board : [[2, 4.0, 16.0, 2], [256.0, 64.0, 128.0, 32.0], [2.0, 4.0, 16.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8800 finished with score 3564.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [2.0, 128.0, 8.0, 4.0], [128.0, 32.0, 16.0, 8.0], [2.0, 256.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8801 finished with score 2436.0, result : lose board : [[  8.   4.   8.   2.]\n",
      " [  2. 256.  64.  32.]\n",
      " [  4.  32.  16.   8.]\n",
      " [ 16.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8802 finished with score 1316.0, result : lose board : [[4, 8.0, 4, 2], [64.0, 32.0, 8.0, 4.0], [128.0, 8.0, 4.0, 8.0], [16.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8803 finished with score 2364.0, result : lose board : [[4.0, 64.0, 8.0, 2.0], [128.0, 32.0, 16.0, 4.0], [4.0, 128.0, 64.0, 8.0], [2.0, 16.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8804 finished with score 1020.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 128.0, 8.0, 4.0], [32.0, 8.0, 16.0, 2.0], [8.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8805 finished with score 852.0, result : lose board : [[32.0, 16.0, 2.0, 8.0], [2.0, 4.0, 32.0, 4.0], [32.0, 64.0, 16.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8806 finished with score 3352.0, result : lose board : [[32.0, 16.0, 4.0, 2], [256.0, 128.0, 16.0, 4.0], [2.0, 64.0, 4.0, 8.0], [64.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8807 finished with score 3276.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  2.  32. 128.   4.]\n",
      " [  4.  64. 256.   8.]\n",
      " [  8.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8808 finished with score 3028.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  4. 128.  16.   8.]\n",
      " [ 32. 256.  32.   4.]\n",
      " [ 16.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8809 finished with score 1548.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [8.0, 64.0, 16.0, 2.0], [32.0, 128.0, 32.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8810 finished with score 1532.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  4.  16.  32.   2.]\n",
      " [ 16. 128.  64.   8.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8811 finished with score 5464.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [512.  32.   4.   8.]\n",
      " [128.  64.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8812 finished with score 2332.0, result : lose board : [[  4.  64.   2.   8.]\n",
      " [  8. 256.  16.   4.]\n",
      " [  2.  16.  32.   2.]\n",
      " [  8.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8813 finished with score 1068.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 16.   8.  32.   4.]\n",
      " [  4. 128.   8.  16.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8814 finished with score 3056.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [128.0, 64.0, 16.0, 2], [2.0, 16.0, 32.0, 4.0], [8.0, 4.0, 256.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8815 finished with score 2836.0, result : lose board : [[8.0, 16.0, 8.0, 4.0], [2.0, 4.0, 32.0, 16.0], [16.0, 256.0, 128.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8816 finished with score 2464.0, result : lose board : [[  2.  64.   2.   4.]\n",
      " [  4. 256.   8.   2.]\n",
      " [  8.  64.   2.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8817 finished with score 1464.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [64.0, 32.0, 2.0, 8.0], [2.0, 128.0, 32.0, 4.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8818 finished with score 2176.0, result : lose board : [[2, 32.0, 16.0, 2], [4.0, 16.0, 128.0, 8.0], [128.0, 4.0, 64.0, 4.0], [32.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8819 finished with score 1068.0, result : lose board : [[8.0, 16.0, 8.0, 2], [2.0, 32.0, 16.0, 8.0], [64.0, 4.0, 64.0, 4.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8820 finished with score 1180.0, result : lose board : [[  4.  16.   2.   4.]\n",
      " [  2. 128.   4.  16.]\n",
      " [  8.  32.   8.   4.]\n",
      " [ 16.   8.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8821 finished with score 1676.0, result : lose board : [[16.0, 8.0, 4.0, 2], [4.0, 64.0, 16.0, 4.0], [64.0, 128.0, 32.0, 8.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8822 finished with score 5536.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [128. 512.   8.   2.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  2.  16.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8823 finished with score 1024.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [4.0, 128.0, 16.0, 2], [2.0, 16.0, 4.0, 16.0], [32.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 216, Loss : 0.5311570167541504\n",
      "Mini-Batch - 1 Back-Prop : 216, Loss : 0.2566061019897461\n",
      "Mini-Batch - 2 Back-Prop : 216, Loss : 0.33594846725463867\n",
      "Mini-Batch - 3 Back-Prop : 216, Loss : 0.3569161295890808\n",
      "Mini-Batch - 4 Back-Prop : 216, Loss : 0.7171542048454285\n",
      "Mini-Batch - 5 Back-Prop : 216, Loss : 1.020241618156433\n",
      "Mini-Batch - 6 Back-Prop : 216, Loss : 0.8265781402587891\n",
      "Mini-Batch - 7 Back-Prop : 216, Loss : 0.5770672559738159\n",
      "Mini-Batch - 8 Back-Prop : 216, Loss : 0.5821033716201782\n",
      "Mini-Batch - 9 Back-Prop : 216, Loss : 0.7057116627693176\n",
      "Mini-Batch - 10 Back-Prop : 216, Loss : 0.4601286053657532\n",
      "Episode 8824 finished with score 1624.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [8.0, 4.0, 16.0, 4.0], [32.0, 128.0, 4.0, 16.0], [2, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8825 finished with score 1836.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [ 16. 128.  16.   4.]\n",
      " [ 64.  32.  64.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8826 finished with score 1536.0, result : lose board : [[  2.   8.  32.   2.]\n",
      " [  4.  32. 128.  16.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8827 finished with score 2464.0, result : lose board : [[  4.   8.   2.   4.]\n",
      " [ 32. 256.  16.   2.]\n",
      " [ 64.  32.   8.   4.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8828 finished with score 3104.0, result : lose board : [[16.0, 8.0, 4, 2], [64.0, 256.0, 8.0, 4.0], [128.0, 8.0, 4.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8829 finished with score 1584.0, result : lose board : [[16.0, 2.0, 16.0, 4.0], [32.0, 64.0, 32.0, 8.0], [4.0, 128.0, 16.0, 4.0], [32.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8830 finished with score 1676.0, result : lose board : [[16.0, 4.0, 8.0, 4.0], [32.0, 16.0, 64.0, 16.0], [64.0, 2.0, 16.0, 8.0], [4.0, 128.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8831 finished with score 4760.0, result : lose board : [[  4.   8.   2.  16.]\n",
      " [  2.  64.  32.   2.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  2. 512.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8832 finished with score 3200.0, result : lose board : [[  2.   4.  32.   2.]\n",
      " [128.  64.   8.   4.]\n",
      " [  4. 256.  32.  16.]\n",
      " [ 16.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8833 finished with score 2524.0, result : lose board : [[ 32.   2.   8.   2.]\n",
      " [  2.   8.  32.   4.]\n",
      " [256.  64.  16.   8.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8834 finished with score 2680.0, result : lose board : [[  8.  32.   8.   4.]\n",
      " [ 64.   4.  64.   2.]\n",
      " [  2. 256.  16.   4.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8835 finished with score 1216.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [ 64.   2.   8.   4.]\n",
      " [  8.   4. 128.   8.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8836 finished with score 2428.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8837 finished with score 1380.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  8. 128.  32.   2.]\n",
      " [  4.  64.   4.   8.]\n",
      " [ 32.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8838, Score : 6096.0, Iters : 400, Finish : not over\n",
      "Episode 8838 finished with score 6956.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4. 256. 128.  32.]\n",
      " [512.  32.   8.   4.]\n",
      " [ 32.   2.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8839 finished with score 1400.0, result : lose board : [[  8.   4.  16.   2.]\n",
      " [  2. 128.   8.   4.]\n",
      " [ 16.  64.  16.   2.]\n",
      " [ 32.   8.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8840 finished with score 3048.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [4.0, 64.0, 2.0, 8.0], [256.0, 128.0, 16.0, 4.0], [8.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8841 finished with score 2356.0, result : lose board : [[8.0, 2.0, 4.0, 2.0], [64.0, 16.0, 8.0, 4.0], [8.0, 256.0, 32.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8842 finished with score 1552.0, result : lose board : [[4.0, 64.0, 4.0, 2], [2.0, 16.0, 8.0, 16.0], [16.0, 64.0, 128.0, 4.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8843 finished with score 4840.0, result : lose board : [[  8.   4.  64.   2.]\n",
      " [  4.  32.   8.   4.]\n",
      " [512.   4.   2.  16.]\n",
      " [ 64.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8844 finished with score 1748.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [ 32.  64.  32.   8.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8845 finished with score 2512.0, result : lose board : [[ 16.   2.   4.   2.]\n",
      " [  8.  16.  64.   4.]\n",
      " [ 32. 256.   8.  32.]\n",
      " [  8.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8846 finished with score 3212.0, result : lose board : [[4.0, 64.0, 4.0, 2], [8.0, 128.0, 8.0, 4.0], [4.0, 64.0, 16.0, 8.0], [2.0, 256.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8847 finished with score 3004.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [16.0, 128.0, 256.0, 4.0], [2.0, 64.0, 16.0, 8.0], [16.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8848 finished with score 3276.0, result : lose board : [[2.0, 32.0, 8.0, 4.0], [128.0, 64.0, 4.0, 8.0], [256.0, 32.0, 16.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8849 finished with score 2308.0, result : lose board : [[4.0, 16.0, 4.0, 2], [8.0, 64.0, 8.0, 4.0], [4.0, 256.0, 16.0, 8.0], [2.0, 32.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 217, Loss : 0.34513115882873535\n",
      "Mini-Batch - 1 Back-Prop : 217, Loss : 0.44756951928138733\n",
      "Mini-Batch - 2 Back-Prop : 217, Loss : 0.5459831953048706\n",
      "Mini-Batch - 3 Back-Prop : 217, Loss : 0.5464641451835632\n",
      "Mini-Batch - 4 Back-Prop : 217, Loss : 0.3401685953140259\n",
      "Mini-Batch - 5 Back-Prop : 217, Loss : 0.42083585262298584\n",
      "Mini-Batch - 6 Back-Prop : 217, Loss : 0.32474201917648315\n",
      "Mini-Batch - 7 Back-Prop : 217, Loss : 0.35159832239151\n",
      "Mini-Batch - 8 Back-Prop : 217, Loss : 0.3014236092567444\n",
      "Mini-Batch - 9 Back-Prop : 217, Loss : 0.49228590726852417\n",
      "Mini-Batch - 10 Back-Prop : 217, Loss : 0.43791893124580383\n",
      "Episode 8850 finished with score 5564.0, result : lose board : [[  4.  64.   4.   2.]\n",
      " [ 16. 128.   8.   4.]\n",
      " [ 64.  32.   4.   8.]\n",
      " [  2.   8. 512.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8851 finished with score 3064.0, result : lose board : [[16.0, 8.0, 4, 2], [4.0, 16.0, 64.0, 8.0], [8.0, 256.0, 8.0, 2.0], [2.0, 32.0, 2.0, 128.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8852 finished with score 2892.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [ 64. 128.   8.   2.]\n",
      " [  2.   4. 256.   4.]\n",
      " [ 16.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8853 finished with score 1924.0, result : lose board : [[2, 8.0, 32.0, 2], [32.0, 128.0, 2.0, 4.0], [128.0, 16.0, 4.0, 8.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8854 finished with score 3044.0, result : lose board : [[ 32.   2.   8.   2.]\n",
      " [  4. 256.  16.   4.]\n",
      " [128.  16.  32.   8.]\n",
      " [ 32.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8855 finished with score 1496.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 16.  32.  16.   2.]\n",
      " [  8. 128.  64.   4.]\n",
      " [  2.  32.   2.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8856 finished with score 912.0, result : lose board : [[ 2. 16.  4.  2.]\n",
      " [ 4. 32. 64.  8.]\n",
      " [64. 16.  2.  4.]\n",
      " [16.  2.  8.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8857 finished with score 2540.0, result : lose board : [[16.0, 4.0, 16.0, 2.0], [64.0, 8.0, 32.0, 4.0], [32.0, 256.0, 16.0, 2], [4.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8858 finished with score 2912.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 32. 256. 128.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8859 finished with score 1752.0, result : lose board : [[32.0, 16, 2, 4], [64.0, 32.0, 16.0, 8.0], [8.0, 128.0, 8.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8860 finished with score 852.0, result : lose board : [[4.0, 16.0, 4.0, 2], [16.0, 64.0, 8.0, 4.0], [2.0, 32.0, 4.0, 2.0], [64.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8861 finished with score 1760.0, result : lose board : [[32.0, 16.0, 4.0, 2], [128.0, 64.0, 8.0, 4.0], [64.0, 32.0, 16.0, 2.0], [2.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8862 finished with score 3244.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [8.0, 256.0, 128.0, 32.0], [32.0, 64.0, 16.0, 8.0], [2, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8863 finished with score 2828.0, result : lose board : [[4.0, 32.0, 4.0, 2], [8.0, 64.0, 2.0, 4.0], [32.0, 256.0, 16.0, 8.0], [2.0, 64.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8864, Score : 6100.0, Iters : 400, Finish : not over\n",
      "Episode 8864 finished with score 6116.0, result : lose board : [[4.0, 8.0, 4.0, 2], [2.0, 32.0, 16.0, 4.0], [256.0, 8.0, 512.0, 16.0], [2.0, 4.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8865 finished with score 2196.0, result : lose board : [[ 32.   2.  16.   2.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  8. 128.  32.  16.]\n",
      " [ 64.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8866 finished with score 1592.0, result : lose board : [[2, 16.0, 4, 2], [32.0, 64.0, 8.0, 4.0], [2.0, 128.0, 64.0, 2.0], [8.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8867 finished with score 2168.0, result : lose board : [[2.0, 16.0, 2.0, 8.0], [4.0, 256.0, 32.0, 4.0], [32.0, 2.0, 8.0, 16.0], [16.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8868 finished with score 2256.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [128.  64.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 32.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8869 finished with score 2864.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [ 64.  32.   4.   8.]\n",
      " [  2. 256.  16.   4.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8870 finished with score 3456.0, result : lose board : [[4.0, 32.0, 4.0, 2], [64.0, 128.0, 8.0, 4.0], [256.0, 16.0, 64.0, 32.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8871 finished with score 1404.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [16.0, 32.0, 8.0, 4.0], [2.0, 128.0, 64.0, 16.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8872 finished with score 1456.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [4.0, 64.0, 128.0, 8.0], [2.0, 16.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8873 finished with score 3172.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  2.   4. 128.   4.]\n",
      " [  4.  64. 256.   8.]\n",
      " [ 16.   4.  32.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8874 finished with score 2660.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 64.0, 32.0, 4.0], [64.0, 256.0, 16.0, 2.0], [4.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8875 finished with score 1348.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 64.0, 8.0, 4.0], [128.0, 32.0, 16.0, 8.0], [4.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8876 finished with score 2524.0, result : lose board : [[2.0, 16.0, 4.0, 8.0], [32.0, 4.0, 32.0, 2.0], [2, 64.0, 256.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8877 finished with score 1844.0, result : lose board : [[ 64.  16.   4.   2.]\n",
      " [  4. 128.  32.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [ 32.  16.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 218, Loss : 0.5928146243095398\n",
      "Mini-Batch - 1 Back-Prop : 218, Loss : 0.5702518224716187\n",
      "Mini-Batch - 2 Back-Prop : 218, Loss : 0.5137303471565247\n",
      "Mini-Batch - 3 Back-Prop : 218, Loss : 0.4373144805431366\n",
      "Mini-Batch - 4 Back-Prop : 218, Loss : 0.6139640212059021\n",
      "Mini-Batch - 5 Back-Prop : 218, Loss : 0.9368935823440552\n",
      "Mini-Batch - 6 Back-Prop : 218, Loss : 1.1040823459625244\n",
      "Mini-Batch - 7 Back-Prop : 218, Loss : 0.5501057505607605\n",
      "Mini-Batch - 8 Back-Prop : 218, Loss : 0.5584235191345215\n",
      "Mini-Batch - 9 Back-Prop : 218, Loss : 0.4922214448451996\n",
      "Mini-Batch - 10 Back-Prop : 218, Loss : 0.5034573078155518\n",
      "Episode 8878 finished with score 2712.0, result : lose board : [[4.0, 16.0, 4, 2], [32.0, 256.0, 8.0, 4.0], [2.0, 64.0, 32.0, 2.0], [64.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8879 finished with score 628.0, result : lose board : [[8.0, 4.0, 8.0, 2.0], [2.0, 16.0, 64.0, 4.0], [4.0, 32.0, 16.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8880 finished with score 1592.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  8.  64.   4.   2.]\n",
      " [ 32. 128.  64.   4.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8881 finished with score 2816.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [4.0, 16.0, 256.0, 8.0], [8.0, 128.0, 32.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8882 finished with score 1352.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [  2.  16.   8.  16.]\n",
      " [  4. 128.  64.   4.]\n",
      " [  2.  32.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8883 finished with score 1576.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [64.0, 32.0, 16.0, 2.0], [2.0, 128.0, 32.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8884 finished with score 1476.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [4.0, 8.0, 32.0, 8.0], [8.0, 64.0, 128.0, 16.0], [32.0, 16.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8885 finished with score 4004.0, result : lose board : [[ 16.   2.   4.   2.]\n",
      " [  4.  16. 256.   4.]\n",
      " [  2. 256.  32.   2.]\n",
      " [ 64.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8886 finished with score 2788.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [4.0, 128.0, 16.0, 2], [2.0, 256.0, 32.0, 4.0], [8.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8887 finished with score 1428.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4.   8.  32.   8.]\n",
      " [ 32. 128.  64.   2.]\n",
      " [  2.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8888 finished with score 1484.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [ 16.  64.  16.   8.]\n",
      " [  2.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8889 finished with score 1416.0, result : lose board : [[32.0, 8.0, 4, 2], [4.0, 128.0, 2.0, 8.0], [16.0, 32.0, 8.0, 4.0], [8.0, 16.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8890 finished with score 3936.0, result : lose board : [[256.  16.   8.   4.]\n",
      " [128.  32. 128.   8.]\n",
      " [  4.  64.  32.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8891 finished with score 860.0, result : lose board : [[16.  4. 16.  4.]\n",
      " [ 2.  8. 32.  8.]\n",
      " [32. 64. 16.  4.]\n",
      " [ 2. 32.  8.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8892 finished with score 1520.0, result : lose board : [[  4.   8.   2.   4.]\n",
      " [  8. 128.  16.   2.]\n",
      " [ 64.  16.  64.   4.]\n",
      " [  2.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8893 finished with score 2688.0, result : lose board : [[4.0, 8.0, 2.0, 8.0], [2.0, 32.0, 64.0, 2.0], [16.0, 64.0, 4.0, 8.0], [256.0, 32.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8894 finished with score 796.0, result : lose board : [[ 2. 16.  8.  4.]\n",
      " [16. 64. 16.  8.]\n",
      " [32.  8. 32.  2.]\n",
      " [ 8. 16.  8.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8895 finished with score 4268.0, result : lose board : [[4.0, 32.0, 8.0, 2.0], [256.0, 64.0, 16.0, 4.0], [32.0, 4.0, 32.0, 8.0], [8.0, 256.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8896 finished with score 3468.0, result : lose board : [[32.0, 8.0, 4.0, 2], [64.0, 256.0, 128.0, 8.0], [4.0, 32.0, 16.0, 4.0], [64.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8897 finished with score 2436.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [4.0, 32.0, 16.0, 2], [64.0, 256.0, 2.0, 4.0], [2.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8898 finished with score 3688.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [128. 256.  16.   4.]\n",
      " [  2.   4. 128.   8.]\n",
      " [ 64.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8899 finished with score 2996.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [64.0, 4.0, 16.0, 4.0], [256.0, 128.0, 4.0, 2], [2, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8900 finished with score 3116.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [ 32. 128. 256.   4.]\n",
      " [  2.  64.  16.   8.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8901 finished with score 1608.0, result : lose board : [[16.0, 4.0, 8.0, 2.0], [32.0, 128.0, 32.0, 4.0], [4.0, 64.0, 16.0, 8.0], [32.0, 16.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8902 finished with score 3200.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 64.0, 16.0, 8.0], [16.0, 256.0, 32.0, 4.0], [4.0, 128.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8903, Score : 5612.0, Iters : 400, Finish : not over\n",
      "Episode 8903 finished with score 7008.0, result : lose board : [[2.0, 8.0, 512.0, 2.0], [4.0, 256.0, 64.0, 4.0], [2.0, 128.0, 16.0, 8.0], [32.0, 2, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8904 finished with score 1660.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [4.0, 32.0, 8.0, 16.0], [64.0, 128.0, 64.0, 4.0], [2, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8905 finished with score 3924.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 64.0, 256.0, 4.0], [4.0, 128.0, 32.0, 8.0], [128.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 219, Loss : 0.5155404806137085\n",
      "Mini-Batch - 1 Back-Prop : 219, Loss : 0.3841741979122162\n",
      "Mini-Batch - 2 Back-Prop : 219, Loss : 0.3992127776145935\n",
      "Mini-Batch - 3 Back-Prop : 219, Loss : 0.4432949125766754\n",
      "Mini-Batch - 4 Back-Prop : 219, Loss : 0.44862237572669983\n",
      "Mini-Batch - 5 Back-Prop : 219, Loss : 0.44064652919769287\n",
      "Mini-Batch - 6 Back-Prop : 219, Loss : 0.4684903919696808\n",
      "Mini-Batch - 7 Back-Prop : 219, Loss : 0.410831093788147\n",
      "Mini-Batch - 8 Back-Prop : 219, Loss : 0.40978825092315674\n",
      "Mini-Batch - 9 Back-Prop : 219, Loss : 0.6562249660491943\n",
      "Mini-Batch - 10 Back-Prop : 219, Loss : 0.8170733451843262\n",
      "Episode 8906 finished with score 3160.0, result : lose board : [[ 32.   4.   2.   4.]\n",
      " [  2.   8. 256.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [  8.   2.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8907 finished with score 1636.0, result : lose board : [[16.0, 8.0, 4.0, 2.0], [4.0, 64.0, 32.0, 4.0], [128.0, 2.0, 16.0, 8.0], [4.0, 64.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8908 finished with score 1564.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  2. 128.  16.   8.]\n",
      " [  4.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8909 finished with score 1388.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [ 64.   4.  16.   4.]\n",
      " [128.  32.   4.   8.]\n",
      " [  2.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8910 finished with score 2580, result : lose board : [[ 16   4   2   4]\n",
      " [ 64  16   8   2]\n",
      " [256  64  16   4]\n",
      " [  8  16   4   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8911, Score : 5700.0, Iters : 400, Finish : not over\n",
      "Episode 8911 finished with score 6708.0, result : lose board : [[8.0, 16.0, 8, 2], [4, 2.0, 512.0, 16.0], [64.0, 256.0, 64.0, 4.0], [8.0, 32.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8912 finished with score 2568.0, result : lose board : [[32.0, 2.0, 32.0, 4.0], [2.0, 64.0, 8.0, 2.0], [32.0, 256.0, 2.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8913 finished with score 3416.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [128.  16.   8.   4.]\n",
      " [  4. 256.  64.  16.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8914 finished with score 700.0, result : lose board : [[16.0, 4.0, 16.0, 4.0], [4.0, 16.0, 32.0, 8.0], [16.0, 64.0, 2.0, 4.0], [2, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8915 finished with score 3468.0, result : lose board : [[  8.   2. 128.   2.]\n",
      " [  4.  64.  32.  16.]\n",
      " [  8. 256.  64.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8916 finished with score 1592.0, result : lose board : [[  4.   8.   2.   4.]\n",
      " [ 64. 128.   8.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [  8.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8917 finished with score 1716.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32. 128.  32.  64.]\n",
      " [  2.  64.   8.   2.]\n",
      " [  8.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8918 finished with score 1616.0, result : lose board : [[2.0, 8.0, 4.0, 2], [64.0, 128.0, 16.0, 4.0], [16.0, 64.0, 32.0, 8.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8919 finished with score 2412.0, result : lose board : [[  8. 256.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [  2.  32.   4.   8.]\n",
      " [  4.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8920 finished with score 3204.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [ 32.   8.  64.   4.]\n",
      " [  8. 128.  32.   8.]\n",
      " [  2. 256.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8921 finished with score 1856.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [128.   2.  16.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8922 finished with score 2212.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  4. 128.   8.   4.]\n",
      " [128.  64.  16.   8.]\n",
      " [  8.  32.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8923 finished with score 1564.0, result : lose board : [[4.0, 32.0, 4.0, 2], [8.0, 128.0, 8.0, 4.0], [32.0, 64.0, 32.0, 16.0], [2.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8924 finished with score 3328.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [ 64. 256.   8.  16.]\n",
      " [  2.   8.  32.   4.]\n",
      " [128.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8925 finished with score 1032.0, result : lose board : [[ 2. 16.  8.  2.]\n",
      " [32.  2. 16.  4.]\n",
      " [ 2. 16. 64.  8.]\n",
      " [ 4. 64. 32.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8926 finished with score 2216.0, result : lose board : [[ 16.   2.  16.   2.]\n",
      " [  2. 256.  32.   4.]\n",
      " [ 16.   4.  16.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8927 finished with score 4152.0, result : lose board : [[32.0, 8.0, 16.0, 2.0], [8.0, 128.0, 64.0, 4.0], [128.0, 256.0, 16.0, 8.0], [4.0, 64.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8928 finished with score 3808.0, result : lose board : [[2, 8.0, 4.0, 2], [8.0, 128.0, 16.0, 4.0], [16.0, 256.0, 8.0, 2.0], [128.0, 2.0, 64.0, 32.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8929 finished with score 1708.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [64.0, 4.0, 32.0, 8.0], [8.0, 64.0, 8.0, 4.0], [128.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8930 finished with score 2988.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [64.0, 16.0, 8.0, 2], [8.0, 256.0, 128.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8931 finished with score 1628.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4.  64.  32.   8.]\n",
      " [128.   4.  64.   2.]\n",
      " [ 16.   2.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8932 finished with score 952.0, result : lose board : [[ 2. 16.  8.  2.]\n",
      " [ 8. 32. 64.  4.]\n",
      " [64. 16.  4.  8.]\n",
      " [16.  2.  8.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8933 finished with score 1352.0, result : lose board : [[2.0, 16.0, 2.0, 8.0], [16.0, 64.0, 16.0, 2.0], [8.0, 128.0, 8.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 220, Loss : 0.7270835041999817\n",
      "Mini-Batch - 1 Back-Prop : 220, Loss : 0.5771780014038086\n",
      "Mini-Batch - 2 Back-Prop : 220, Loss : 0.6477494239807129\n",
      "Mini-Batch - 3 Back-Prop : 220, Loss : 0.5157385468482971\n",
      "Mini-Batch - 4 Back-Prop : 220, Loss : 0.625466525554657\n",
      "Mini-Batch - 5 Back-Prop : 220, Loss : 0.4604795277118683\n",
      "Mini-Batch - 6 Back-Prop : 220, Loss : 0.7178952097892761\n",
      "Mini-Batch - 7 Back-Prop : 220, Loss : 0.9641717672348022\n",
      "Mini-Batch - 8 Back-Prop : 220, Loss : 0.5580275058746338\n",
      "Mini-Batch - 9 Back-Prop : 220, Loss : 0.8474234342575073\n",
      "Mini-Batch - 10 Back-Prop : 220, Loss : 0.5590923428535461\n",
      "Episode 8934 finished with score 1420.0, result : lose board : [[8.0, 4.0, 16.0, 4.0], [16.0, 128.0, 32.0, 2.0], [4.0, 64.0, 16.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8935 finished with score 4808.0, result : lose board : [[4.0, 2.0, 16.0, 8.0], [2.0, 8.0, 4.0, 2.0], [8.0, 512.0, 8.0, 4.0], [4.0, 128.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8936 finished with score 2544.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [  4. 256.  32.   8.]\n",
      " [ 64.  16.   4.   2.]\n",
      " [ 16.   4.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8937 finished with score 1676.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  8. 128.  32.   8.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8938 finished with score 1560.0, result : lose board : [[  2.   8.  32.   2.]\n",
      " [ 32.  16.   8.   4.]\n",
      " [128.   4.  64.   2.]\n",
      " [  4.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8939 finished with score 3724.0, result : lose board : [[ 64.  16.   8.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [ 64. 256.  32.   8.]\n",
      " [  2.  64.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8940 finished with score 1464.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [ 64.  32.   8.   4.]\n",
      " [128.   8.  32.   2.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8941 finished with score 1848.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [  2.   4.  64.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8942 finished with score 1352.0, result : lose board : [[64.0, 8.0, 4.0, 2.0], [2, 4.0, 32.0, 8.0], [8.0, 128.0, 16.0, 4.0], [16.0, 8.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8943 finished with score 1364.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  4.   2.  32.   2.]\n",
      " [  8. 128.  16.   8.]\n",
      " [  2.  16.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8944 finished with score 3212.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 64.  32. 256.  16.]\n",
      " [  8.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8945, Score : 6084.0, Iters : 400, Finish : not over\n",
      "Episode 8945 finished with score 6824.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2.0, 256.0, 16.0, 4.0], [512.0, 128.0, 32.0, 2.0], [8.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8946 finished with score 3184.0, result : lose board : [[16.0, 32.0, 2.0, 4.0], [256.0, 128.0, 4.0, 2.0], [2, 64.0, 32.0, 16.0], [8.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8947 finished with score 2548.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [8.0, 32.0, 4.0, 2], [16.0, 256.0, 32.0, 4.0], [32.0, 4.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8948 finished with score 2444.0, result : lose board : [[32.0, 4.0, 2.0, 4.0], [8.0, 32.0, 16.0, 2], [16.0, 64.0, 256.0, 4.0], [4.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8949 finished with score 1328.0, result : lose board : [[ 16.   8.   2.   8.]\n",
      " [128.  16.   4.   2.]\n",
      " [  4.  64.   8.   4.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8950 finished with score 1368.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [  4.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8951 finished with score 3072.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 128.0, 8.0, 4.0], [16.0, 256.0, 16.0, 2.0], [4.0, 64.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8952 finished with score 3084.0, result : lose board : [[  8.   2.   8.   4.]\n",
      " [ 16.  64. 128.   2.]\n",
      " [ 32. 256.  16.   8.]\n",
      " [  4.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8953 finished with score 1484.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [2.0, 128.0, 32.0, 4.0], [16.0, 64.0, 16.0, 8.0], [4.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8954 finished with score 1784.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [ 16.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8955 finished with score 1116.0, result : lose board : [[4, 16.0, 4, 2], [16.0, 32.0, 16.0, 4], [32.0, 128.0, 4.0, 2], [2.0, 8.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8956, Score : 5668.0, Iters : 400, Finish : not over\n",
      "Episode 8956 finished with score 5684.0, result : lose board : [[16.0, 8, 4, 2], [4, 64.0, 512.0, 16.0], [16.0, 128.0, 64.0, 8.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8957 finished with score 2144.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [64.0, 128.0, 16.0, 4.0], [8.0, 64.0, 32.0, 8.0], [64.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8958 finished with score 5512.0, result : lose board : [[  8.   2.   8.   4.]\n",
      " [  2.  16. 128.   8.]\n",
      " [ 64. 512.  64.   2.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8959 finished with score 2100.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  8. 128.  32.   4.]\n",
      " [128.   2.  16.   8.]\n",
      " [  8.  64.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8960 finished with score 2904.0, result : lose board : [[2.0, 16.0, 4, 2], [4.0, 32.0, 256.0, 4.0], [16.0, 8.0, 32.0, 16.0], [2.0, 128.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 221, Loss : 0.45860809087753296\n",
      "Mini-Batch - 1 Back-Prop : 221, Loss : 0.662928581237793\n",
      "Mini-Batch - 2 Back-Prop : 221, Loss : 0.39302730560302734\n",
      "Mini-Batch - 3 Back-Prop : 221, Loss : 0.5066282749176025\n",
      "Mini-Batch - 4 Back-Prop : 221, Loss : 0.4578706920146942\n",
      "Mini-Batch - 5 Back-Prop : 221, Loss : 0.49189049005508423\n",
      "Mini-Batch - 6 Back-Prop : 221, Loss : 0.4908492863178253\n",
      "Mini-Batch - 7 Back-Prop : 221, Loss : 0.6150434017181396\n",
      "Mini-Batch - 8 Back-Prop : 221, Loss : 0.8162496089935303\n",
      "Mini-Batch - 9 Back-Prop : 221, Loss : 0.5477180480957031\n",
      "Mini-Batch - 10 Back-Prop : 221, Loss : 0.6940146684646606\n",
      "Episode 8961 finished with score 3064.0, result : lose board : [[  8.   2.   8.   4.]\n",
      " [128.   8.  64.   2.]\n",
      " [ 32. 256.   4.  16.]\n",
      " [  2.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8962 finished with score 1444.0, result : lose board : [[4.0, 32.0, 4.0, 2], [2.0, 128.0, 8.0, 4.0], [64.0, 2.0, 16.0, 8.0], [16.0, 8.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8963 finished with score 3932.0, result : lose board : [[  2.  32.  16.   2.]\n",
      " [ 64. 256.   8.   4.]\n",
      " [  2. 128.  16.   2.]\n",
      " [128.   8.  32.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8964 finished with score 3220.0, result : lose board : [[32.0, 16.0, 8.0, 2], [256.0, 32.0, 2.0, 8.0], [2.0, 128.0, 32.0, 4.0], [4.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8965 finished with score 2784.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64.  32.  16.   8.]\n",
      " [ 16. 256.  32.   2.]\n",
      " [ 64.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8966 finished with score 3192.0, result : lose board : [[ 64.   2.   8.   2.]\n",
      " [  2. 256.  16.   4.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8967 finished with score 3156.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [128.  16.   8.   4.]\n",
      " [  8.  64. 256.  16.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8968 finished with score 1816.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [ 16. 128.  32.  16.]\n",
      " [  4.   2.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8969 finished with score 696.0, result : lose board : [[ 4. 16.  4.  2.]\n",
      " [ 2. 64. 32.  4.]\n",
      " [ 8.  4. 16.  8.]\n",
      " [ 2. 32.  4.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8970 finished with score 1232.0, result : lose board : [[ 16.   2.   4.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [ 16.   8.   4.   8.]\n",
      " [  4.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8971, Score : 5712.0, Iters : 400, Finish : not over\n",
      "Episode 8971 finished with score 5732.0, result : lose board : [[2.0, 32.0, 4.0, 2], [128.0, 512.0, 16.0, 4.0], [64.0, 4.0, 32.0, 8.0], [2.0, 64.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8972 finished with score 1388.0, result : lose board : [[2.0, 8.0, 4, 2], [32.0, 64.0, 16.0, 4.0], [2.0, 8.0, 128.0, 16.0], [8.0, 4.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8973, Score : 5712.0, Iters : 400, Finish : not over\n",
      "Episode 8973 finished with score 7212.0, result : lose board : [[ 16.  64.   4.   2.]\n",
      " [ 32. 512.  16.   8.]\n",
      " [256. 128.  32.   4.]\n",
      " [  8.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8974 finished with score 3960.0, result : lose board : [[32.0, 8.0, 4, 2], [64.0, 128.0, 16.0, 4.0], [256.0, 64.0, 32.0, 8.0], [64.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8975 finished with score 3684.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [ 32. 256.  16.   8.]\n",
      " [  4. 128.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8976 finished with score 1460.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  4.  16.   8.   4.]\n",
      " [  2. 128.  16.  64.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8977, Score : 6156.0, Iters : 400, Finish : not over\n",
      "Episode 8977 finished with score 6556.0, result : lose board : [[32.0, 16.0, 2, 4], [4.0, 512.0, 64.0, 8.0], [32.0, 256.0, 32.0, 16.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 8978, Score : 5672.0, Iters : 400, Finish : not over\n",
      "Episode 8978 finished with score 5872.0, result : lose board : [[ 32.  64.   4.   2.]\n",
      " [512. 128.   8.  16.]\n",
      " [  2.  64.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8979 finished with score 3004.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [128.0, 32.0, 16.0, 8.0], [2.0, 256.0, 8.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8980 finished with score 1612.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  4.  32.  16.   4.]\n",
      " [128.  64.  32.   8.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8981 finished with score 1392.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  4.  16.  32.   4.]\n",
      " [ 64. 128.  16.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8982 finished with score 2164.0, result : lose board : [[2.0, 32.0, 4.0, 2], [256.0, 16.0, 8.0, 4.0], [16.0, 32.0, 2.0, 8.0], [8.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8983 finished with score 2524.0, result : lose board : [[2.0, 16.0, 8.0, 2], [128.0, 64.0, 16.0, 8.0], [8.0, 128.0, 64.0, 4.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 222, Loss : 0.5719148516654968\n",
      "Mini-Batch - 1 Back-Prop : 222, Loss : 0.5225191712379456\n",
      "Mini-Batch - 2 Back-Prop : 222, Loss : 0.42814236879348755\n",
      "Mini-Batch - 3 Back-Prop : 222, Loss : 0.5460874438285828\n",
      "Mini-Batch - 4 Back-Prop : 222, Loss : 0.4865976572036743\n",
      "Mini-Batch - 5 Back-Prop : 222, Loss : 0.41751426458358765\n",
      "Mini-Batch - 6 Back-Prop : 222, Loss : 0.48890382051467896\n",
      "Mini-Batch - 7 Back-Prop : 222, Loss : 0.5852679014205933\n",
      "Mini-Batch - 8 Back-Prop : 222, Loss : 0.837828516960144\n",
      "Mini-Batch - 9 Back-Prop : 222, Loss : 0.7618932723999023\n",
      "Mini-Batch - 10 Back-Prop : 222, Loss : 0.764947772026062\n",
      "Episode 8984 finished with score 1904.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [ 32.  16.  32.   2.]\n",
      " [  2.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8985 finished with score 1656.0, result : lose board : [[16.0, 8.0, 4.0, 2], [64.0, 16.0, 2.0, 8.0], [8.0, 128.0, 8.0, 4.0], [64.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8986 finished with score 4060.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  8.  16.   8.   4.]\n",
      " [ 16. 256.  64. 256.]\n",
      " [ 32.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8987 finished with score 2024.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [ 32.   8.  32.   4.]\n",
      " [128.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8988 finished with score 3108.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [ 64. 256.   8.   2.]\n",
      " [  4.  32.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8989 finished with score 3512.0, result : lose board : [[16.0, 4.0, 8.0, 2.0], [32.0, 64.0, 16.0, 4.0], [8.0, 256.0, 32.0, 64.0], [128.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8990 finished with score 1572.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [64.0, 32.0, 128.0, 16.0], [2.0, 16.0, 8.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8991 finished with score 720.0, result : lose board : [[ 2. 16.  2.  4.]\n",
      " [ 4. 32.  8. 16.]\n",
      " [ 2. 16. 64.  8.]\n",
      " [ 4.  2. 32.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8992 finished with score 2740.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2. 256.   8.   4.]\n",
      " [128.  16.  32.   2.]\n",
      " [  2.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8993 finished with score 2596.0, result : lose board : [[16.0, 32.0, 4.0, 2], [256.0, 64.0, 8.0, 4.0], [2.0, 8.0, 16.0, 2.0], [64.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8994 finished with score 3448.0, result : lose board : [[2.0, 32.0, 4.0, 2], [8.0, 128.0, 16.0, 8.0], [256.0, 2.0, 64.0, 16.0], [64.0, 32.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8995 finished with score 812.0, result : lose board : [[ 2. 16.  2.  8.]\n",
      " [ 8.  2.  8.  4.]\n",
      " [32. 16. 32.  2.]\n",
      " [ 4. 32.  4. 64.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8996 finished with score 1776.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  4. 128.   8.  16.]\n",
      " [  8.   4.  32.   4.]\n",
      " [  4. 128.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8997 finished with score 1512.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [ 64.   8.   4.   8.]\n",
      " [  8.  64.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8998 finished with score 2000.0, result : lose board : [[  2.  64.   4.   2.]\n",
      " [128.  32.   8.   4.]\n",
      " [  2.  64.  16.   8.]\n",
      " [ 32.   4.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 8999 finished with score 3284.0, result : lose board : [[  4.   2.   8.   2.]\n",
      " [ 32. 256.  64.   4.]\n",
      " [  8. 128.   8.   2.]\n",
      " [  2.  64.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Maximum Score : 7216.0 ,Episode : 8254\n",
      "Loss : 0.5828742764212869\n",
      "\n",
      "Episode 9000 finished with score 1324.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [2.0, 64.0, 4.0, 2], [128.0, 8.0, 32.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9001 finished with score 1836.0, result : lose board : [[2, 16.0, 8, 2], [128.0, 32.0, 16.0, 4.0], [2.0, 16.0, 2.0, 8.0], [16.0, 128.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9002 finished with score 1180.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  32.  16.   8.]\n",
      " [ 16. 128.   8.   2.]\n",
      " [ 32.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9003 finished with score 1540.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 128.0, 16.0, 4.0], [64.0, 8.0, 4.0, 8.0], [4.0, 2.0, 64.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9004 finished with score 2940.0, result : lose board : [[16.0, 8.0, 4.0, 2], [4.0, 32.0, 16.0, 8.0], [256.0, 128.0, 32.0, 4.0], [8.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9005 finished with score 3212.0, result : lose board : [[ 64.  16.   8.   4.]\n",
      " [ 32.   2.  32.   2.]\n",
      " [256. 128.  16.   8.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9006 finished with score 2500.0, result : lose board : [[16.0, 8.0, 4.0, 2], [128.0, 64.0, 16.0, 4.0], [2.0, 128.0, 32.0, 8.0], [64.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9007 finished with score 2768.0, result : lose board : [[32.0, 8, 4, 2], [64.0, 32.0, 16.0, 8.0], [2.0, 256.0, 64.0, 4.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9008 finished with score 3192.0, result : lose board : [[32.0, 2.0, 8.0, 4.0], [128.0, 64.0, 16.0, 2.0], [4.0, 32.0, 8.0, 4.0], [256.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9009 finished with score 1336.0, result : lose board : [[32.0, 8.0, 4.0, 2], [128.0, 32.0, 2.0, 8.0], [32.0, 2.0, 16.0, 2.0], [8.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9010 finished with score 1024.0, result : lose board : [[  4.   8.  16.   2.]\n",
      " [ 16.  32. 128.   4.]\n",
      " [  4.   2.   8.   2.]\n",
      " [  8.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9011 finished with score 3480.0, result : lose board : [[64.0, 16.0, 4.0, 2], [2.0, 64.0, 16.0, 4.0], [256.0, 128.0, 32.0, 8.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9012 finished with score 4228.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [256.  32.  16.   2.]\n",
      " [  4. 256.  64.   4.]\n",
      " [ 32.   8.   2.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9013 finished with score 852.0, result : lose board : [[32.0, 8, 4, 2], [8.0, 64.0, 16.0, 4.0], [32.0, 16.0, 32.0, 8.0], [4.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 223, Loss : 0.3874175548553467\n",
      "Mini-Batch - 1 Back-Prop : 223, Loss : 0.5284653902053833\n",
      "Mini-Batch - 2 Back-Prop : 223, Loss : 0.4576250910758972\n",
      "Mini-Batch - 3 Back-Prop : 223, Loss : 0.7098798155784607\n",
      "Mini-Batch - 4 Back-Prop : 223, Loss : 0.6089041233062744\n",
      "Mini-Batch - 5 Back-Prop : 223, Loss : 0.4449528157711029\n",
      "Mini-Batch - 6 Back-Prop : 223, Loss : 0.6477720141410828\n",
      "Mini-Batch - 7 Back-Prop : 223, Loss : 0.4129731059074402\n",
      "Mini-Batch - 8 Back-Prop : 223, Loss : 0.4718720614910126\n",
      "Mini-Batch - 9 Back-Prop : 223, Loss : 0.48791345953941345\n",
      "Mini-Batch - 10 Back-Prop : 223, Loss : 0.49099409580230713\n",
      "Episode 9014 finished with score 3448.0, result : lose board : [[64.0, 16.0, 8.0, 2], [8.0, 32.0, 2.0, 8.0], [128.0, 256.0, 32.0, 4.0], [4.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9015 finished with score 1884.0, result : lose board : [[16.0, 32.0, 4.0, 2], [32.0, 2.0, 8.0, 4.0], [4.0, 64.0, 128.0, 8.0], [64.0, 16.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9016 finished with score 2564.0, result : lose board : [[  4.   2.   8.   4.]\n",
      " [ 16.   8.  64.   2.]\n",
      " [ 64. 256.  16.   4.]\n",
      " [  2.  16.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9017 finished with score 1688.0, result : lose board : [[ 16.   4.   8.   2.]\n",
      " [  4. 128.  64.   8.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9018 finished with score 1484.0, result : lose board : [[  8.   4.   8.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [ 16.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9019, Score : 5556.0, Iters : 400, Finish : not over\n",
      "Episode 9019 finished with score 5572.0, result : lose board : [[ 16.   4.   8.   2.]\n",
      " [128. 512.  16.   4.]\n",
      " [ 16.  64.  32.   8.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9020 finished with score 2788.0, result : lose board : [[16.0, 8.0, 4.0, 2], [256.0, 128.0, 16.0, 8.0], [4.0, 32.0, 8.0, 2.0], [8.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9021 finished with score 1884.0, result : lose board : [[  2. 128.   8.   4.]\n",
      " [  8.   4.  16.   8.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9022 finished with score 1460.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [2.0, 64.0, 4.0, 2.0], [4, 128.0, 32.0, 8.0], [16.0, 4.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9023 finished with score 3236.0, result : lose board : [[64.0, 16.0, 8.0, 2], [256.0, 32.0, 16.0, 4.0], [2.0, 128.0, 32.0, 8.0], [16.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9024 finished with score 1380.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 32.   4.  16.   4.]\n",
      " [ 64.   8.  32.   8.]\n",
      " [  2. 128.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9025 finished with score 3404.0, result : lose board : [[  2.  64.   2.   4.]\n",
      " [  4.  32.  16.   2.]\n",
      " [256. 128.  32.   4.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9026 finished with score 1680.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [128.  32.   2.   8.]\n",
      " [  4.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9027 finished with score 1624.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 64. 128.  64.   8.]\n",
      " [  4.  16.   8.   2.]\n",
      " [ 32.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9028 finished with score 5196.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2.0, 512.0, 8.0, 4.0], [4.0, 128.0, 32.0, 16.0], [2.0, 32.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9029 finished with score 2964.0, result : lose board : [[8.0, 64.0, 4.0, 2.0], [16.0, 256.0, 8.0, 4.0], [8.0, 64.0, 32.0, 8.0], [64.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9030 finished with score 1188.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [32.0, 64.0, 16.0, 4.0], [64.0, 32.0, 8.0, 16.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9031 finished with score 1708.0, result : lose board : [[  2.   4.   2.   4.]\n",
      " [ 32.  64.  16.   2.]\n",
      " [  8. 128.  64.   4.]\n",
      " [ 32.   8.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9032 finished with score 5440.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [  8. 512.  64.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9033 finished with score 3248.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [256.0, 64.0, 16.0, 2.0], [64.0, 128.0, 2.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9034 finished with score 2724.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  2.  64.  16.   2.]\n",
      " [  4. 256.  64.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9035 finished with score 2448.0, result : lose board : [[4.0, 256.0, 8.0, 4], [32.0, 16.0, 4.0, 8.0], [4.0, 32.0, 16.0, 2.0], [64.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9036 finished with score 3136.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [ 16. 256.  32.   8.]\n",
      " [  8. 128.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9037 finished with score 3052.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [256. 128.  32.   8.]\n",
      " [  2.  64.   8.   2.]\n",
      " [ 16.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9038 finished with score 3048.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.  64. 128.   4.]\n",
      " [256.  16.   4.   8.]\n",
      " [ 32.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9039 finished with score 1364.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [16.0, 128.0, 64.0, 2.0], [8.0, 32.0, 2.0, 8.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 224, Loss : 0.45748284459114075\n",
      "Mini-Batch - 1 Back-Prop : 224, Loss : 0.4029521346092224\n",
      "Mini-Batch - 2 Back-Prop : 224, Loss : 0.4987885057926178\n",
      "Mini-Batch - 3 Back-Prop : 224, Loss : 0.5145883560180664\n",
      "Mini-Batch - 4 Back-Prop : 224, Loss : 0.49049240350723267\n",
      "Mini-Batch - 5 Back-Prop : 224, Loss : 0.6596795320510864\n",
      "Mini-Batch - 6 Back-Prop : 224, Loss : 0.3973056674003601\n",
      "Mini-Batch - 7 Back-Prop : 224, Loss : 0.4260658621788025\n",
      "Mini-Batch - 8 Back-Prop : 224, Loss : 0.6935803890228271\n",
      "Mini-Batch - 9 Back-Prop : 224, Loss : 0.5336847305297852\n",
      "Mini-Batch - 10 Back-Prop : 224, Loss : 0.4647388160228729\n",
      "Episode 9040 finished with score 1500.0, result : lose board : [[  8.  32.   8.   2.]\n",
      " [ 16.  64.  32.   8.]\n",
      " [  8. 128.  16.   2.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9041 finished with score 1876.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [ 64.  16.  32.   8.]\n",
      " [ 16.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9042 finished with score 1576.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [  2. 128.  16.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9043 finished with score 3532.0, result : lose board : [[4.0, 64.0, 16.0, 2.0], [64.0, 256.0, 32.0, 8.0], [4.0, 128.0, 16.0, 4.0], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9044 finished with score 3336.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [ 32.   8.  64.   8.]\n",
      " [  4. 256.  32.  16.]\n",
      " [128.  32.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9045 finished with score 1696.0, result : lose board : [[ 16.   4.  16.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [ 16.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9046 finished with score 2336.0, result : lose board : [[8.0, 2.0, 4.0, 2], [2.0, 256.0, 32.0, 8.0], [16.0, 64.0, 8.0, 4.0], [4.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9047 finished with score 1856.0, result : lose board : [[ 16.   8.  32.   2.]\n",
      " [  2.  64.  16.   4.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [ 64.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9048 finished with score 3628.0, result : lose board : [[  2.  32.  16.   4.]\n",
      " [  4.  16.  64.   2.]\n",
      " [128. 256.  32.   4.]\n",
      " [ 64.  32.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9049 finished with score 1792.0, result : lose board : [[  2.  64.   2.   8.]\n",
      " [  4.  32.   4.   2.]\n",
      " [ 64. 128.  32.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9050 finished with score 4848.0, result : lose board : [[8.0, 4.0, 8.0, 2.0], [2.0, 64.0, 16.0, 4.0], [32.0, 512.0, 64.0, 8.0], [4.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9051 finished with score 1396.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 64.0, 32.0, 8.0], [16.0, 128.0, 2.0, 4.0], [4.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9052 finished with score 5072.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 512.0, 2.0, 8.0], [8.0, 128.0, 32.0, 4.0], [32.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9053 finished with score 1116.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 128.0, 2.0, 4.0], [32.0, 8.0, 32.0, 2.0], [4.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9054 finished with score 2700.0, result : lose board : [[  8.   4.  16.   2.]\n",
      " [  2.  64.  32.   8.]\n",
      " [  8. 256.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9055 finished with score 3104.0, result : lose board : [[2.0, 8.0, 16.0, 2.0], [64.0, 128.0, 8.0, 4.0], [256.0, 32.0, 16.0, 8.0], [16.0, 4, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9056 finished with score 5068.0, result : lose board : [[4.0, 8.0, 16.0, 4.0], [8.0, 16.0, 512.0, 2.0], [2.0, 128.0, 16.0, 8.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9057 finished with score 2460.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  2.  16.  32.   4.]\n",
      " [ 64. 256.   4.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9058 finished with score 1592.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [128.  32.   4.   8.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9059 finished with score 3092.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 16.  64.  32.   8.]\n",
      " [128. 256.  16.   4.]\n",
      " [  8.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9060 finished with score 2852.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [4.0, 64.0, 32.0, 4.0], [16.0, 256.0, 16.0, 8.0], [64.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9061 finished with score 3924.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [  4. 256.  32.   8.]\n",
      " [128.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9062 finished with score 2724.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [64.0, 32.0, 4.0, 2.0], [4.0, 256.0, 64.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9063 finished with score 3528.0, result : lose board : [[4.0, 8.0, 4.0, 2], [16.0, 128.0, 256.0, 8.0], [4.0, 32.0, 16.0, 4.0], [128.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9064 finished with score 2700.0, result : lose board : [[4.0, 8.0, 4.0, 2], [16.0, 64.0, 8.0, 16.0], [2.0, 16.0, 256.0, 4.0], [64.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9065 finished with score 1608.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  8. 128.  32.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 225, Loss : 0.42120361328125\n",
      "Mini-Batch - 1 Back-Prop : 225, Loss : 0.644927978515625\n",
      "Mini-Batch - 2 Back-Prop : 225, Loss : 0.49587884545326233\n",
      "Mini-Batch - 3 Back-Prop : 225, Loss : 0.3452951908111572\n",
      "Mini-Batch - 4 Back-Prop : 225, Loss : 0.5059685111045837\n",
      "Mini-Batch - 5 Back-Prop : 225, Loss : 0.7728445529937744\n",
      "Mini-Batch - 6 Back-Prop : 225, Loss : 1.245110273361206\n",
      "Mini-Batch - 7 Back-Prop : 225, Loss : 0.7828887104988098\n",
      "Mini-Batch - 8 Back-Prop : 225, Loss : 0.7151365876197815\n",
      "Mini-Batch - 9 Back-Prop : 225, Loss : 0.3896579146385193\n",
      "Mini-Batch - 10 Back-Prop : 225, Loss : 0.34437891840934753\n",
      "Episode 9066 finished with score 3100.0, result : lose board : [[  2.  32.   2.   4.]\n",
      " [ 64. 256.  16.   8.]\n",
      " [  4.  64.  32.   4.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9067 finished with score 2416.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8. 256.  16.   4.]\n",
      " [ 32.   8.  64.   8.]\n",
      " [ 16.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9068 finished with score 5540.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  2.  64.  32.  16.]\n",
      " [ 32. 512. 128.   4.]\n",
      " [  2.   4.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9069 finished with score 3132.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 64.0, 32.0, 16.0], [16.0, 256.0, 2.0, 8.0], [128.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9070 finished with score 3324.0, result : lose board : [[  2.  32.  16.   2.]\n",
      " [ 32. 256. 128.   4.]\n",
      " [  2.  32.  16.   8.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9071 finished with score 740.0, result : lose board : [[16.0, 8.0, 2.0, 4], [4.0, 32.0, 4.0, 2.0], [32.0, 64.0, 16.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9072 finished with score 2204.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  2. 256.   4.   8.]\n",
      " [  4.   8.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9073, Score : 5636.0, Iters : 400, Finish : not over\n",
      "Episode 9073 finished with score 5636.0, result : lose board : [[32.0, 8.0, 4, 2], [128.0, 32.0, 8.0, 4.0], [512.0, 64.0, 32.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9074 finished with score 1284.0, result : lose board : [[  4.  32.   4.   2.]\n",
      " [  8. 128.  32.   4.]\n",
      " [ 32.  16.   4.   8.]\n",
      " [ 16.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9075 finished with score 1532.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [  2.   4.  32.   8.]\n",
      " [  4.  32.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9076 finished with score 1496.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 16.  64.   8.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9077 finished with score 1288.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [2.0, 4.0, 64.0, 4.0], [8.0, 32.0, 8.0, 16.0], [2.0, 128.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9078 finished with score 2988.0, result : lose board : [[ 16.  32.   8.   2.]\n",
      " [ 64. 256.  64.   4.]\n",
      " [  4.  32.   4.   2.]\n",
      " [ 64.   8.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9079 finished with score 3368.0, result : lose board : [[2.0, 64.0, 4.0, 2], [32.0, 16.0, 8.0, 4.0], [8.0, 64.0, 16.0, 128.0], [4.0, 256.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9080 finished with score 2312.0, result : lose board : [[16.0, 8, 4, 2], [4.0, 16.0, 64.0, 4.0], [16.0, 2.0, 256.0, 16.0], [4.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9081 finished with score 3104.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 128.0, 2.0, 4.0], [32.0, 256.0, 64.0, 2.0], [4.0, 8.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9082 finished with score 2852.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32.   8.  16.   4.]\n",
      " [256.  32.   4.   2.]\n",
      " [128.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9083 finished with score 2800.0, result : lose board : [[2, 16.0, 8.0, 2.0], [8.0, 32.0, 16.0, 8.0], [4.0, 256.0, 128.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9084 finished with score 1468.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [64.0, 128.0, 8.0, 4.0], [2, 4.0, 32.0, 16.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9085 finished with score 2864.0, result : lose board : [[16.0, 8, 4, 2], [32.0, 256.0, 32.0, 4.0], [2.0, 16.0, 4.0, 2.0], [128.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9086 finished with score 1868.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 16. 128.   8.   4.]\n",
      " [128.   4.  32.   8.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9087 finished with score 3156.0, result : lose board : [[2.0, 256.0, 4.0, 2.0], [8.0, 32.0, 64.0, 32.0], [2.0, 128.0, 16.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9088 finished with score 2624.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  4.   8.   4.   2.]\n",
      " [ 64. 256.  64.   8.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9089 finished with score 3328.0, result : lose board : [[2.0, 8.0, 4.0, 2], [8.0, 64.0, 16.0, 4.0], [128.0, 4.0, 32.0, 8.0], [4.0, 256.0, 64.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9090 finished with score 1460.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [128.  32.  16.   4.]\n",
      " [  4.  64.   4.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9091 finished with score 1364.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [4.0, 32.0, 64.0, 8.0], [16.0, 128.0, 16.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9092 finished with score 2564.0, result : lose board : [[ 32.   2.   8.  64.]\n",
      " [  8.  16.   4.   2.]\n",
      " [ 32. 256.  16.   4.]\n",
      " [  2.   8.   2.  32.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 226, Loss : 0.39841920137405396\n",
      "Mini-Batch - 1 Back-Prop : 226, Loss : 0.4692627787590027\n",
      "Mini-Batch - 2 Back-Prop : 226, Loss : 0.7379944324493408\n",
      "Mini-Batch - 3 Back-Prop : 226, Loss : 0.2933730483055115\n",
      "Mini-Batch - 4 Back-Prop : 226, Loss : 0.5138309001922607\n",
      "Mini-Batch - 5 Back-Prop : 226, Loss : 0.530701756477356\n",
      "Mini-Batch - 6 Back-Prop : 226, Loss : 0.5296242237091064\n",
      "Mini-Batch - 7 Back-Prop : 226, Loss : 0.4494709372520447\n",
      "Mini-Batch - 8 Back-Prop : 226, Loss : 0.4640929102897644\n",
      "Mini-Batch - 9 Back-Prop : 226, Loss : 0.6457580327987671\n",
      "Mini-Batch - 10 Back-Prop : 226, Loss : 0.6885305643081665\n",
      "Episode 9093 finished with score 3156.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  2.  32. 256.   8.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9094 finished with score 2760.0, result : lose board : [[32.0, 16.0, 4.0, 2], [2, 4.0, 64.0, 16.0], [256.0, 32.0, 16.0, 4.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9095 finished with score 3156.0, result : lose board : [[32.0, 8.0, 4, 2], [256.0, 4.0, 16.0, 4.0], [4.0, 32.0, 128.0, 8.0], [64.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9096 finished with score 1668.0, result : lose board : [[16.0, 8.0, 16.0, 4.0], [32.0, 16.0, 8.0, 2.0], [2.0, 128.0, 64.0, 4.0], [64.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9097 finished with score 436.0, result : lose board : [[2.0, 16.0, 4.0, 2], [16.0, 8.0, 2.0, 4.0], [8.0, 64.0, 8.0, 2.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9098 finished with score 3396.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  4. 128.  16.   2.]\n",
      " [256.  16.  64.   8.]\n",
      " [ 64.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9099 finished with score 3012.0, result : lose board : [[  2.  64.   8.   2.]\n",
      " [  4. 256.  32.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [ 64.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9100 finished with score 3624.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [4.0, 256.0, 64.0, 8.0], [2, 8.0, 128.0, 32.0], [4.0, 64.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9101 finished with score 1528.0, result : lose board : [[128.0, 32.0, 16.0, 4.0], [16.0, 4.0, 32.0, 2.0], [4.0, 64.0, 8.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9102 finished with score 2928.0, result : lose board : [[  4.   2.   8.   2.]\n",
      " [  2.  16. 256.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [128.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9103 finished with score 5060.0, result : lose board : [[128.0, 8.0, 4.0, 2.0], [4.0, 512.0, 16.0, 4.0], [16.0, 32.0, 2.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9104 finished with score 3580.0, result : lose board : [[  4.   8.   2.   4.]\n",
      " [128.  16.   4.  32.]\n",
      " [  8.   2.   8.   4.]\n",
      " [256. 128.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9105 finished with score 1924.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  2. 128.  64.   8.]\n",
      " [ 32.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9106 finished with score 1584.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2.  16.  32.   8.]\n",
      " [ 32.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9107 finished with score 1704.0, result : lose board : [[2.0, 8.0, 4.0, 2], [64.0, 16.0, 32.0, 8.0], [8.0, 64.0, 128.0, 4.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9108 finished with score 2392.0, result : lose board : [[2, 16.0, 8.0, 4.0], [4.0, 64.0, 16.0, 2], [2.0, 256.0, 8.0, 4.0], [32.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9109 finished with score 1884.0, result : lose board : [[4.0, 32.0, 16.0, 4.0], [32.0, 64.0, 32.0, 8.0], [8.0, 128.0, 16.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9110 finished with score 2412.0, result : lose board : [[4.0, 2.0, 256.0, 2.0], [2.0, 32.0, 16.0, 32.0], [8.0, 64.0, 8.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9111 finished with score 2856.0, result : lose board : [[4.0, 32.0, 2.0, 8.0], [128.0, 256.0, 4.0, 2], [4.0, 32.0, 8.0, 4.0], [8.0, 2.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9112 finished with score 2340.0, result : lose board : [[  2.   4.   2.   8.]\n",
      " [ 64.  32.   8.   2.]\n",
      " [  4. 256.  32.   4.]\n",
      " [  8.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9113 finished with score 748.0, result : lose board : [[ 2. 16.  8.  4.]\n",
      " [ 8. 32. 16.  2.]\n",
      " [16. 64. 32.  4.]\n",
      " [ 2.  8.  4.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9114, Score : 5768.0, Iters : 400, Finish : not over\n",
      "Episode 9114 finished with score 8012.0, result : lose board : [[4.0, 256.0, 4.0, 2], [256.0, 512.0, 32.0, 4.0], [64.0, 8.0, 16.0, 2.0], [2.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9115 finished with score 2456.0, result : lose board : [[2.0, 256.0, 4.0, 2], [32.0, 64.0, 8.0, 4.0], [2.0, 16.0, 32.0, 16.0], [8.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9116 finished with score 2260.0, result : lose board : [[2.0, 8.0, 4.0, 2], [8.0, 64.0, 16.0, 8.0], [64.0, 16.0, 128.0, 4.0], [8.0, 128.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9117 finished with score 1748.0, result : lose board : [[4.0, 8.0, 4.0, 2], [32.0, 2.0, 16.0, 4.0], [4.0, 128.0, 64.0, 16.0], [64.0, 16.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9118 finished with score 1960.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [ 64. 128.  16.   2.]\n",
      " [  4.   2.  64.   8.]\n",
      " [ 64.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9119 finished with score 1412.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [ 16.   8. 128.   4.]\n",
      " [  4.  64.  32.   8.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 227, Loss : 0.32068729400634766\n",
      "Mini-Batch - 1 Back-Prop : 227, Loss : 0.4786878824234009\n",
      "Mini-Batch - 2 Back-Prop : 227, Loss : 0.6032241582870483\n",
      "Mini-Batch - 3 Back-Prop : 227, Loss : 0.80826336145401\n",
      "Mini-Batch - 4 Back-Prop : 227, Loss : 1.1053905487060547\n",
      "Mini-Batch - 5 Back-Prop : 227, Loss : 0.6419050097465515\n",
      "Mini-Batch - 6 Back-Prop : 227, Loss : 0.4934135973453522\n",
      "Mini-Batch - 7 Back-Prop : 227, Loss : 0.4804620146751404\n",
      "Mini-Batch - 8 Back-Prop : 227, Loss : 0.5890048146247864\n",
      "Mini-Batch - 9 Back-Prop : 227, Loss : 0.3791070580482483\n",
      "Mini-Batch - 10 Back-Prop : 227, Loss : 0.42090409994125366\n",
      "Episode 9120 finished with score 1924.0, result : lose board : [[  2.  64.   8.   4.]\n",
      " [ 64.   2.  16.   2.]\n",
      " [  8. 128.  32.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9121 finished with score 2768.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [2.0, 16.0, 64.0, 2.0], [64.0, 256.0, 8.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9122 finished with score 3816.0, result : lose board : [[2.0, 32.0, 4.0, 2.0], [128.0, 16.0, 8.0, 4.0], [256.0, 128.0, 64.0, 16.0], [2.0, 8.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9123 finished with score 2656.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 32. 256.  32.   2.]\n",
      " [  4.  32.  64.   8.]\n",
      " [ 32.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9124 finished with score 5484.0, result : lose board : [[  2.   4.  32.   4.]\n",
      " [  8. 512.  16.   8.]\n",
      " [ 64. 128.  32.   2.]\n",
      " [ 32.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9125 finished with score 3492.0, result : lose board : [[32, 8, 4, 2], [2, 64, 32, 16], [256, 128, 8, 4], [64, 16, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9126 finished with score 1580.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [32.0, 16.0, 64.0, 4.0], [4.0, 128.0, 32.0, 16.0], [32.0, 16.0, 8.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9127 finished with score 2984.0, result : lose board : [[  2.   8.  32.   4.]\n",
      " [  4. 128.   8.   2.]\n",
      " [256.  32.  16.   4.]\n",
      " [  4.  16.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9128 finished with score 1156.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  4.   8.  16.   4.]\n",
      " [ 32.  16. 128.   8.]\n",
      " [  2.   4.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9129 finished with score 5308.0, result : lose board : [[2.0, 8.0, 4.0, 2], [512.0, 16.0, 128.0, 4.0], [4.0, 32.0, 16.0, 8.0], [2.0, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9130 finished with score 3716.0, result : lose board : [[64.0, 16.0, 4.0, 2], [4.0, 256.0, 16.0, 4.0], [128.0, 32.0, 64.0, 2.0], [64.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9131 finished with score 3196.0, result : lose board : [[  8.  32.   8.   4.]\n",
      " [  2.  16. 128.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 32.   4.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9132 finished with score 5336.0, result : lose board : [[  2.   4.   2.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2.   4. 128. 512.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9133 finished with score 1840.0, result : lose board : [[2, 16.0, 4, 2], [128.0, 32.0, 16.0, 4.0], [2.0, 128.0, 4.0, 2.0], [4.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9134 finished with score 2544.0, result : lose board : [[2.0, 4.0, 64.0, 2.0], [4.0, 64.0, 4.0, 8.0], [2, 32.0, 2.0, 16.0], [256.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9135 finished with score 3332.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [4.0, 32.0, 64.0, 4.0], [128.0, 256.0, 16.0, 2], [32.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9136 finished with score 2604.0, result : lose board : [[2, 4.0, 16.0, 4.0], [16.0, 2.0, 8.0, 2.0], [4.0, 64.0, 32.0, 4.0], [2.0, 256.0, 64.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9137 finished with score 2112.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 16.0, 8.0, 4.0], [2.0, 256.0, 32.0, 2.0], [8.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9138, Score : 6064.0, Iters : 400, Finish : not over\n",
      "Episode 9138 finished with score 6944.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  4. 128. 512.   4.]\n",
      " [  2. 256.  16.   8.]\n",
      " [  4.  32.   4.  32.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9139 finished with score 852.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [4.0, 32.0, 16.0, 4.0], [32.0, 64.0, 32.0, 16.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9140 finished with score 2572.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [  2.   4.  32.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9141 finished with score 1760.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [  4.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9142 finished with score 2344, result : lose board : [[128  32   4   2]\n",
      " [ 16  64  16   4]\n",
      " [  8 128  32   8]\n",
      " [  2  32  16   4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9143 finished with score 2172.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 16. 256.   4.   8.]\n",
      " [  2.  16.  32.   4.]\n",
      " [ 32.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 228, Loss : 0.5044985413551331\n",
      "Mini-Batch - 1 Back-Prop : 228, Loss : 0.36849892139434814\n",
      "Mini-Batch - 2 Back-Prop : 228, Loss : 0.4943159818649292\n",
      "Mini-Batch - 3 Back-Prop : 228, Loss : 0.5095158219337463\n",
      "Mini-Batch - 4 Back-Prop : 228, Loss : 0.3348451852798462\n",
      "Mini-Batch - 5 Back-Prop : 228, Loss : 0.5251544117927551\n",
      "Mini-Batch - 6 Back-Prop : 228, Loss : 0.4905416667461395\n",
      "Mini-Batch - 7 Back-Prop : 228, Loss : 0.4051109850406647\n",
      "Mini-Batch - 8 Back-Prop : 228, Loss : 0.6947745084762573\n",
      "Mini-Batch - 9 Back-Prop : 228, Loss : 0.8142880201339722\n",
      "Mini-Batch - 10 Back-Prop : 228, Loss : 0.5304205417633057\n",
      "Episode 9144 finished with score 2576.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2. 256.  32.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9145 finished with score 1128.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  2. 128.   8.   2.]\n",
      " [ 16.  32.   2.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9146 finished with score 1248.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  2. 128.  32.  16.]\n",
      " [ 32.  16.   8.   2.]\n",
      " [  4.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9147 finished with score 1528.0, result : lose board : [[4.0, 2.0, 4.0, 2.0], [32.0, 16.0, 64.0, 8.0], [2.0, 8.0, 32.0, 4.0], [128.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9148 finished with score 1476.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [  2.  16.  64.   4.]\n",
      " [ 32.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9149 finished with score 3400.0, result : lose board : [[4.0, 16.0, 8.0, 4.0], [64.0, 256.0, 64.0, 2.0], [32.0, 128.0, 16.0, 8.0], [4.0, 16.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9150 finished with score 2228.0, result : lose board : [[32.0, 2.0, 128.0, 2.0], [2.0, 8.0, 32.0, 8.0], [128.0, 64.0, 16.0, 4.0], [32.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9151 finished with score 1984.0, result : lose board : [[32.0, 2, 4, 2], [128.0, 32.0, 2.0, 8.0], [32.0, 128.0, 16.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9152 finished with score 2424.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [2.0, 4.0, 256.0, 4.0], [32.0, 64.0, 16.0, 8.0], [2.0, 32.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9153 finished with score 1400.0, result : lose board : [[2, 16.0, 2.0, 4.0], [64.0, 32.0, 16.0, 2.0], [128.0, 4.0, 8.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9154 finished with score 5452.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 64.0, 16.0, 4.0], [512.0, 128.0, 32.0, 8.0], [4.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9155 finished with score 2436.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [ 32.  64.   4.   2.]\n",
      " [ 16. 256.  32.   8.]\n",
      " [  8.   4.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9156 finished with score 1648.0, result : lose board : [[2.0, 8.0, 4.0, 2], [4.0, 32.0, 128.0, 4.0], [2.0, 64.0, 4.0, 32.0], [64.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9157, Score : 6124.0, Iters : 400, Finish : not over\n",
      "Episode 9157 finished with score 7212.0, result : lose board : [[  4.  16.   2.   4.]\n",
      " [  8.  64.   4.   8.]\n",
      " [128.   8. 512.   4.]\n",
      " [256.   2.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9158 finished with score 3140.0, result : lose board : [[4, 32.0, 4.0, 2], [32.0, 4.0, 16.0, 4.0], [4.0, 64.0, 8.0, 2.0], [128.0, 256.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9159 finished with score 2704.0, result : lose board : [[8.0, 32.0, 4.0, 2], [2.0, 64.0, 16.0, 4.0], [4.0, 256.0, 32.0, 8.0], [8.0, 64.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9160 finished with score 3488.0, result : lose board : [[16.0, 8.0, 4, 2], [64.0, 32.0, 8.0, 16.0], [2.0, 256.0, 128.0, 4.0], [32.0, 64.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9161 finished with score 1680.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [16.0, 64.0, 16.0, 4.0], [8.0, 128.0, 64.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9162 finished with score 2308.0, result : lose board : [[4.0, 32.0, 4.0, 2], [128.0, 2.0, 16.0, 4.0], [8.0, 128.0, 64.0, 8.0], [4.0, 64.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9163 finished with score 1600.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [32.0, 16.0, 8.0, 2.0], [128.0, 32.0, 16.0, 4.0], [32.0, 64.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9164 finished with score 712.0, result : lose board : [[32.  4.  2.  4.]\n",
      " [64.  8. 16.  2.]\n",
      " [ 2. 32.  4.  8.]\n",
      " [ 8. 16.  8.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9165 finished with score 1368.0, result : lose board : [[4.0, 16.0, 8.0, 2], [16.0, 4.0, 2.0, 8.0], [8.0, 128.0, 16.0, 4.0], [64.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9166 finished with score 2912.0, result : lose board : [[32.0, 2.0, 4.0, 2.0], [2.0, 256.0, 32.0, 8.0], [8.0, 128.0, 8.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9167 finished with score 1424.0, result : lose board : [[2.0, 32.0, 4.0, 2.0], [8.0, 64.0, 128.0, 4.0], [32.0, 2.0, 16.0, 8.0], [16.0, 4, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9168 finished with score 1420.0, result : lose board : [[  8.   4.   8.   2.]\n",
      " [ 32.   2. 128.   4.]\n",
      " [  8.  32.  16.   8.]\n",
      " [  2.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9169 finished with score 2744.0, result : lose board : [[256.0, 16.0, 8.0, 2.0], [4.0, 32.0, 64.0, 4.0], [64.0, 16.0, 4.0, 2], [2.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9170 finished with score 4612.0, result : lose board : [[ 16.   8.   4.   8.]\n",
      " [  4. 512.   8.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  2.   4.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9171 finished with score 5444.0, result : lose board : [[16.0, 8, 4, 2], [4.0, 16.0, 32.0, 4.0], [32.0, 128.0, 512.0, 64.0], [4.0, 16.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 229, Loss : 0.29138892889022827\n",
      "Mini-Batch - 1 Back-Prop : 229, Loss : 0.5723971128463745\n",
      "Mini-Batch - 2 Back-Prop : 229, Loss : 0.5816840529441833\n",
      "Mini-Batch - 3 Back-Prop : 229, Loss : 0.2934103012084961\n",
      "Mini-Batch - 4 Back-Prop : 229, Loss : 0.4591028392314911\n",
      "Mini-Batch - 5 Back-Prop : 229, Loss : 0.5687990188598633\n",
      "Mini-Batch - 6 Back-Prop : 229, Loss : 0.35395875573158264\n",
      "Mini-Batch - 7 Back-Prop : 229, Loss : 0.47756272554397583\n",
      "Mini-Batch - 8 Back-Prop : 229, Loss : 0.554323673248291\n",
      "Mini-Batch - 9 Back-Prop : 229, Loss : 0.4226298928260803\n",
      "Mini-Batch - 10 Back-Prop : 229, Loss : 0.6797239184379578\n",
      "Episode 9172 finished with score 3464.0, result : lose board : [[2.0, 16.0, 4.0, 2], [32.0, 128.0, 32.0, 4.0], [2.0, 256.0, 64.0, 2.0], [64.0, 16.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9173 finished with score 1352.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [128.   2.  16.   4.]\n",
      " [ 64.   8.   2.   8.]\n",
      " [ 32.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9174 finished with score 1476.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  4.  32.  64.  16.]\n",
      " [ 16.   2.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9175 finished with score 3176.0, result : lose board : [[2.0, 32.0, 4.0, 2.0], [8.0, 128.0, 16.0, 4.0], [64.0, 8.0, 256.0, 16.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9176 finished with score 2380.0, result : lose board : [[16.0, 8.0, 16.0, 4.0], [2.0, 64.0, 8.0, 2.0], [8.0, 256.0, 2.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9177 finished with score 3568.0, result : lose board : [[32.0, 2, 4, 2], [64.0, 128.0, 8.0, 4.0], [4.0, 256.0, 16.0, 32.0], [32.0, 4.0, 64.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9178 finished with score 1760.0, result : lose board : [[16.0, 32.0, 16.0, 4.0], [4.0, 128.0, 64.0, 16.0], [2.0, 32.0, 8.0, 4.0], [64.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9179 finished with score 3932.0, result : lose board : [[ 64.   8.   4.   2.]\n",
      " [  4.  16.   8.   4.]\n",
      " [ 32. 256. 128.   8.]\n",
      " [  4. 128.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9180 finished with score 2656.0, result : lose board : [[  4.  32.   4.   2.]\n",
      " [ 64.   2.  16.   8.]\n",
      " [ 16. 256.  64.   4.]\n",
      " [  8.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9181 finished with score 3220.0, result : lose board : [[2.0, 8.0, 64.0, 4.0], [4.0, 256.0, 4.0, 8.0], [128.0, 64.0, 16.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9182 finished with score 1308.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16.  64.   8.   4.]\n",
      " [  2.   4. 128.  32.]\n",
      " [ 16.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9183 finished with score 2444.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  8.   2.  16.   4.]\n",
      " [ 32.   8. 256.   8.]\n",
      " [  8.  32.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9184 finished with score 2932.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [ 64.  32.   4.   8.]\n",
      " [  2. 256.  64.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9185 finished with score 1984.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  8.  64.   8.   4.]\n",
      " [ 64. 128.  32.   2.]\n",
      " [  2.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9186 finished with score 1912.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.   4.  16.   8.]\n",
      " [128.  64. 128.   4.]\n",
      " [  2.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9187 finished with score 1732.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [ 16. 128.  32.   2.]\n",
      " [ 64.  16.  64.   8.]\n",
      " [ 16.   4.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9188 finished with score 2648.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 256.0, 8.0, 4.0], [2.0, 64.0, 32.0, 16.0], [64.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9189 finished with score 3240.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [64.0, 32.0, 16.0, 4.0], [256.0, 64.0, 32.0, 16.0], [64.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9190 finished with score 3520.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 16.0, 128.0, 4.0], [256.0, 128.0, 32.0, 8.0], [4.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9191 finished with score 2816.0, result : lose board : [[ 16.   4.   8.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [  8.   4. 256.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9192 finished with score 3216.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [ 64. 256.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9193 finished with score 2960.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [256.  32.   4.   8.]\n",
      " [  2. 128.  16.   4.]\n",
      " [ 16.   2.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9194 finished with score 1296.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [4.0, 32.0, 8.0, 4.0], [8.0, 128.0, 64.0, 8.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9195 finished with score 2728.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 16.   8.  32.   2.]\n",
      " [  2.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9196 finished with score 2592.0, result : lose board : [[32.0, 16.0, 4, 2], [2.0, 256.0, 16.0, 4.0], [32.0, 64.0, 32.0, 2.0], [2.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9197 finished with score 1480.0, result : lose board : [[16.0, 8.0, 4.0, 2.0], [128.0, 32.0, 8.0, 4.0], [32.0, 64.0, 16.0, 8.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9198 finished with score 1552.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  8.   4.  64.   8.]\n",
      " [  2.  64.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 230, Loss : 0.37614089250564575\n",
      "Mini-Batch - 1 Back-Prop : 230, Loss : 0.3719150424003601\n",
      "Mini-Batch - 2 Back-Prop : 230, Loss : 0.7525264024734497\n",
      "Mini-Batch - 3 Back-Prop : 230, Loss : 0.31256356835365295\n",
      "Mini-Batch - 4 Back-Prop : 230, Loss : 0.3806563913822174\n",
      "Mini-Batch - 5 Back-Prop : 230, Loss : 0.3691970705986023\n",
      "Mini-Batch - 6 Back-Prop : 230, Loss : 0.6374253630638123\n",
      "Mini-Batch - 7 Back-Prop : 230, Loss : 0.5794396996498108\n",
      "Mini-Batch - 8 Back-Prop : 230, Loss : 0.9609275460243225\n",
      "Mini-Batch - 9 Back-Prop : 230, Loss : 0.9775398373603821\n",
      "Mini-Batch - 10 Back-Prop : 230, Loss : 0.4489445090293884\n",
      "Episode 9199 finished with score 3068.0, result : lose board : [[  4.   2.   8.   4.]\n",
      " [  8.  16.   2.   8.]\n",
      " [128.  32.   8.   2.]\n",
      " [256.   2.  64.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9200 finished with score 2156.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [128.  64.  32.   8.]\n",
      " [ 16.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9201 finished with score 1492.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  2.  32.  16.   8.]\n",
      " [128.  64.  32.   2.]\n",
      " [  8.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9202 finished with score 932.0, result : lose board : [[ 2. 16.  2.  4.]\n",
      " [ 8. 32. 16.  2.]\n",
      " [32. 64. 32.  8.]\n",
      " [ 4. 32.  2.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9203 finished with score 1680.0, result : lose board : [[ 16.   2.  32.   2.]\n",
      " [ 64.  16.   8.   4.]\n",
      " [  8. 128.   2.  16.]\n",
      " [ 64.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9204 finished with score 3596.0, result : lose board : [[4.0, 16.0, 8.0, 4.0], [8.0, 128.0, 32.0, 2.0], [128.0, 256.0, 16.0, 4.0], [2.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9205 finished with score 1832.0, result : lose board : [[  8.   4.   2. 128.]\n",
      " [  4.  32.  16.   4.]\n",
      " [  2. 128.   8.   2.]\n",
      " [  8.   2.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9206 finished with score 2940.0, result : lose board : [[  2. 128.   8.   2.]\n",
      " [ 32.   4.  16.   4.]\n",
      " [256.  16.  32.   8.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9207 finished with score 3356.0, result : lose board : [[2.0, 128.0, 4.0, 2], [8.0, 256.0, 8.0, 4.0], [2.0, 64.0, 32.0, 8.0], [64.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9208 finished with score 3052.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [  4.  64.   4.  16.]\n",
      " [256.   4. 128.   8.]\n",
      " [ 32.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9209 finished with score 1276.0, result : lose board : [[4, 8.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [128.0, 8.0, 2.0, 8.0], [2.0, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9210 finished with score 1884.0, result : lose board : [[2.0, 32.0, 64.0, 2.0], [4.0, 64.0, 4.0, 8.0], [8.0, 128.0, 16.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9211 finished with score 816.0, result : lose board : [[2, 16.0, 8.0, 2], [4.0, 32.0, 2.0, 4.0], [32.0, 64.0, 32.0, 2.0], [4.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9212 finished with score 2804.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 64.  16.  64.   2.]\n",
      " [  2.  32.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9213 finished with score 1440.0, result : lose board : [[2.0, 8.0, 4.0, 2], [16.0, 32.0, 8.0, 4.0], [128.0, 64.0, 16.0, 2.0], [8.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9214 finished with score 3552.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 128.0, 16.0, 4.0], [8.0, 256.0, 32.0, 8.0], [4.0, 128.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9215 finished with score 1788.0, result : lose board : [[2, 16.0, 8, 2], [32.0, 64.0, 16.0, 4.0], [4.0, 128.0, 32.0, 8.0], [16.0, 2.0, 64.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9216 finished with score 3068.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  8. 256. 128.   4.]\n",
      " [ 64.  16.   4.   8.]\n",
      " [  2.   4.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9217 finished with score 3184.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [32.0, 256.0, 16.0, 4.0], [4.0, 128.0, 64.0, 8.0], [2.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9218 finished with score 3056.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4.  64. 256.  16.]\n",
      " [128.   4.   8.   2.]\n",
      " [  2.   8.  32.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9219 finished with score 5488.0, result : lose board : [[4.0, 8.0, 4.0, 2], [16.0, 64.0, 32.0, 4.0], [128.0, 16.0, 512.0, 8.0], [4.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9220 finished with score 2492.0, result : lose board : [[128.0, 8.0, 4.0, 2], [4.0, 32.0, 16.0, 4.0], [128.0, 2.0, 128.0, 8.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9221 finished with score 3504.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [128.  64.  32.   4.]\n",
      " [  4. 256.  16.   8.]\n",
      " [ 64.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9222 finished with score 2340.0, result : lose board : [[16.0, 256.0, 4.0, 2.0], [64.0, 4.0, 16.0, 4.0], [8.0, 2.0, 32.0, 8.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9223 finished with score 2896.0, result : lose board : [[32.0, 16.0, 4.0, 2], [64.0, 32.0, 16.0, 8.0], [4.0, 256.0, 64.0, 4.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9224 finished with score 1992.0, result : lose board : [[64.0, 4.0, 8.0, 4.0], [128.0, 64.0, 4.0, 8.0], [64.0, 32.0, 16.0, 4.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9225 finished with score 2460.0, result : lose board : [[  2.  32.  16.   4.]\n",
      " [128.  64.   8.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  4.   2. 128.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 231, Loss : 0.4624843895435333\n",
      "Mini-Batch - 1 Back-Prop : 231, Loss : 0.322171688079834\n",
      "Mini-Batch - 2 Back-Prop : 231, Loss : 0.3708718419075012\n",
      "Mini-Batch - 3 Back-Prop : 231, Loss : 0.44869810342788696\n",
      "Mini-Batch - 4 Back-Prop : 231, Loss : 0.37547552585601807\n",
      "Mini-Batch - 5 Back-Prop : 231, Loss : 0.41810062527656555\n",
      "Mini-Batch - 6 Back-Prop : 231, Loss : 0.48199665546417236\n",
      "Mini-Batch - 7 Back-Prop : 231, Loss : 0.3482191562652588\n",
      "Mini-Batch - 8 Back-Prop : 231, Loss : 0.30753642320632935\n",
      "Mini-Batch - 9 Back-Prop : 231, Loss : 0.40018928050994873\n",
      "Mini-Batch - 10 Back-Prop : 231, Loss : 0.33621466159820557\n",
      "Episode 9226 finished with score 3440.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [2.0, 64.0, 32.0, 4.0], [256.0, 128.0, 16.0, 8.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9227 finished with score 2328.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4. 128.  32.   4.]\n",
      " [128.  64.  16.   8.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9228 finished with score 2632.0, result : lose board : [[32.0, 16.0, 4.0, 2], [256.0, 64.0, 16.0, 8.0], [32.0, 4.0, 32.0, 2.0], [16.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9229 finished with score 4836.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  64.  16.   4.]\n",
      " [256. 128.  32.   8.]\n",
      " [  8. 256.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9230 finished with score 1304.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [ 16.   2.  32.   8.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9231 finished with score 1536.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.  16.  32.  16.]\n",
      " [  4. 128.  64.  32.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9232 finished with score 1488.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [8.0, 32.0, 64.0, 2.0], [2.0, 128.0, 16.0, 4.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9233 finished with score 1668.0, result : lose board : [[2.0, 32.0, 16.0, 2.0], [4.0, 128.0, 32.0, 4.0], [32.0, 64.0, 16.0, 8.0], [4.0, 32.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9234, Score : 6056.0, Iters : 400, Finish : not over\n",
      "Episode 9234 finished with score 6072.0, result : lose board : [[2.0, 32.0, 4.0, 8.0], [4.0, 512.0, 32.0, 2.0], [8.0, 256.0, 8.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9235 finished with score 1460.0, result : lose board : [[32.0, 4.0, 2.0, 4.0], [2.0, 128.0, 8.0, 2.0], [8.0, 32.0, 64.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9236 finished with score 3232.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64.  32.  16.   8.]\n",
      " [  4. 256.  32.   2.]\n",
      " [128.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9237 finished with score 3028.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [32.0, 128.0, 4.0, 2.0], [256.0, 32.0, 16.0, 4.0], [2, 16.0, 8.0, 32.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9238 finished with score 3476.0, result : lose board : [[16.0, 2.0, 128.0, 4.0], [64.0, 32.0, 64.0, 8.0], [2.0, 256.0, 2.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9239 finished with score 2560.0, result : lose board : [[4.0, 32.0, 16.0, 2.0], [8.0, 4.0, 64.0, 32.0], [2.0, 256.0, 16.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9240 finished with score 2368.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  4.  32.  16.   8.]\n",
      " [ 16. 256.  32.  16.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9241 finished with score 1580.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 128.0, 16.0, 4.0], [64.0, 4.0, 64.0, 2.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9242 finished with score 2684.0, result : lose board : [[8.0, 4.0, 2.0, 8.0], [32.0, 16.0, 8.0, 2], [2.0, 64.0, 256.0, 64.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9243 finished with score 3596.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [8.0, 256.0, 64.0, 16.0], [64.0, 128.0, 16.0, 4.0], [4.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9244 finished with score 3176.0, result : lose board : [[16.0, 32.0, 4.0, 2.0], [64.0, 8.0, 32.0, 4.0], [2.0, 128.0, 2.0, 8.0], [256.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9245 finished with score 836.0, result : lose board : [[ 8. 16.  8.  2.]\n",
      " [ 2. 32. 16.  4.]\n",
      " [32.  8. 64.  8.]\n",
      " [ 8.  2. 32.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9246 finished with score 1556.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [8.0, 64.0, 16.0, 2.0], [64.0, 128.0, 2.0, 8.0], [16.0, 2, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9247 finished with score 3116.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  16.  32.   4.]\n",
      " [  4. 256. 128.   8.]\n",
      " [  8.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9248 finished with score 2540.0, result : lose board : [[  4.   2.   8.   2.]\n",
      " [ 32.  16.   2.  32.]\n",
      " [  4.  32.  64.   4.]\n",
      " [  2. 256.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9249 finished with score 3448.0, result : lose board : [[ 32.   4.  16.   2.]\n",
      " [ 64.   8. 256.   8.]\n",
      " [  4. 128.  64.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9250 finished with score 2780.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 64.  16.   4.   8.]\n",
      " [  2.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9251 finished with score 2604.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [64.0, 256.0, 64.0, 8.0], [8.0, 32.0, 8.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 232, Loss : 0.577619194984436\n",
      "Mini-Batch - 1 Back-Prop : 232, Loss : 0.46908608078956604\n",
      "Mini-Batch - 2 Back-Prop : 232, Loss : 0.37494462728500366\n",
      "Mini-Batch - 3 Back-Prop : 232, Loss : 0.294558584690094\n",
      "Mini-Batch - 4 Back-Prop : 232, Loss : 0.7096744775772095\n",
      "Mini-Batch - 5 Back-Prop : 232, Loss : 0.5627428293228149\n",
      "Mini-Batch - 6 Back-Prop : 232, Loss : 0.6151063442230225\n",
      "Mini-Batch - 7 Back-Prop : 232, Loss : 0.7192874550819397\n",
      "Mini-Batch - 8 Back-Prop : 232, Loss : 0.6684284806251526\n",
      "Mini-Batch - 9 Back-Prop : 232, Loss : 0.4374060034751892\n",
      "Mini-Batch - 10 Back-Prop : 232, Loss : 0.4271809756755829\n",
      "Episode 9252 finished with score 1876.0, result : lose board : [[32.0, 2.0, 8.0, 2.0], [128.0, 4.0, 16.0, 4.0], [2.0, 16.0, 128.0, 8.0], [32.0, 2.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9253 finished with score 1620.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [128.0, 64.0, 32.0, 4.0], [32.0, 2.0, 8.0, 16.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9254 finished with score 1440.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [128.   8.  16.   8.]\n",
      " [ 64.  32.   2.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9255 finished with score 2924.0, result : lose board : [[2.0, 64.0, 4.0, 2.0], [8.0, 256.0, 32.0, 8.0], [64.0, 4.0, 64.0, 16.0], [4, 16.0, 8, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9256 finished with score 3372.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [4.0, 8.0, 16.0, 4.0], [128.0, 256.0, 64.0, 8.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9257 finished with score 5440.0, result : lose board : [[2.0, 32.0, 8.0, 32.0], [32.0, 512.0, 64.0, 2.0], [128.0, 4.0, 2.0, 4.0], [2, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9258 finished with score 3372.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [128.  16.   8.   4.]\n",
      " [256.  64.  16.   8.]\n",
      " [ 64.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9259 finished with score 1136.0, result : lose board : [[ 32.   2. 128.   2.]\n",
      " [  2.   4.   2.   4.]\n",
      " [ 16.   8.  16.   8.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9260 finished with score 3316.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 32.   8. 128.   8.]\n",
      " [  8.   4.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9261 finished with score 1976.0, result : lose board : [[2.0, 128.0, 4.0, 2.0], [4.0, 2.0, 32.0, 8.0], [128.0, 64.0, 8.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9262, Score : 6136.0, Iters : 400, Finish : not over\n",
      "Episode 9262 finished with score 7192.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [512.  64.  16.   4.]\n",
      " [  8. 256.  32.   8.]\n",
      " [  2. 128.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9263 finished with score 5480.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [512.  64. 128.   8.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9264 finished with score 2844.0, result : lose board : [[  2.  64.   8.   2.]\n",
      " [  4.  32.  16.   4.]\n",
      " [256.  64.  32.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9265 finished with score 2864.0, result : lose board : [[  4.  32.   2.   4.]\n",
      " [256.  64.  32.   8.]\n",
      " [ 64.  16.   4.   2.]\n",
      " [  8.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9266 finished with score 1488.0, result : lose board : [[32.0, 16.0, 4, 2], [64.0, 32.0, 16.0, 8.0], [4.0, 64.0, 32.0, 4.0], [64.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9267 finished with score 3260.0, result : lose board : [[128.0, 8.0, 4.0, 2], [2.0, 4.0, 64.0, 8.0], [256.0, 32.0, 2.0, 4.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9268 finished with score 2796.0, result : lose board : [[32.0, 4.0, 2.0, 4.0], [64.0, 32.0, 64.0, 2.0], [4.0, 256.0, 16.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9269 finished with score 5044.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 16. 512.  64.   8.]\n",
      " [  4.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9270 finished with score 1636.0, result : lose board : [[ 32.  64.   8.   2.]\n",
      " [  2.  32.   2.   4.]\n",
      " [ 32. 128.  32.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9271 finished with score 2208.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [256.   2.  16.   4.]\n",
      " [  2.  16.  32.   8.]\n",
      " [ 32.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9272 finished with score 1560.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 32. 128.   8.   4.]\n",
      " [  8.  64.  32.  16.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9273 finished with score 4036.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [256.  32.  16.   4.]\n",
      " [  4. 256.  32.   8.]\n",
      " [ 32.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9274 finished with score 2380.0, result : lose board : [[2.0, 4.0, 8.0, 2.0], [8.0, 16.0, 32.0, 4.0], [64.0, 256.0, 8.0, 16.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9275 finished with score 2928.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 64. 256.   8.  64.]\n",
      " [  4.  64.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9276 finished with score 1372.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  2. 128.   8.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 233, Loss : 0.28409266471862793\n",
      "Mini-Batch - 1 Back-Prop : 233, Loss : 0.4007275700569153\n",
      "Mini-Batch - 2 Back-Prop : 233, Loss : 0.43763136863708496\n",
      "Mini-Batch - 3 Back-Prop : 233, Loss : 0.2780809998512268\n",
      "Mini-Batch - 4 Back-Prop : 233, Loss : 0.42132246494293213\n",
      "Mini-Batch - 5 Back-Prop : 233, Loss : 0.4712178111076355\n",
      "Mini-Batch - 6 Back-Prop : 233, Loss : 0.7522491216659546\n",
      "Mini-Batch - 7 Back-Prop : 233, Loss : 0.4366109371185303\n",
      "Mini-Batch - 8 Back-Prop : 233, Loss : 0.5343890190124512\n",
      "Mini-Batch - 9 Back-Prop : 233, Loss : 0.4668934643268585\n",
      "Mini-Batch - 10 Back-Prop : 233, Loss : 0.7672845125198364\n",
      "Episode 9277 finished with score 3480, result : lose board : [[2, 16, 4, 2], [64, 32, 16, 4], [8, 256, 32, 2], [128, 64, 8, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9278 finished with score 3040.0, result : lose board : [[32.0, 8.0, 4.0, 2], [256.0, 128.0, 2.0, 4.0], [64.0, 8.0, 4.0, 2.0], [8.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9279 finished with score 2404.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64.   8. 256.   4.]\n",
      " [  8.  32.   8.   2.]\n",
      " [  2.   4.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9280 finished with score 3688.0, result : lose board : [[32.0, 4.0, 2.0, 4.0], [2.0, 8.0, 128.0, 8.0], [256.0, 128.0, 32.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9281 finished with score 1904.0, result : lose board : [[2.0, 16.0, 4.0, 2], [128.0, 32.0, 64.0, 8.0], [2.0, 64.0, 8.0, 2.0], [64.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9282 finished with score 2960.0, result : lose board : [[2.0, 32.0, 4, 2], [8.0, 256.0, 16.0, 4.0], [32.0, 128.0, 32.0, 8.0], [8.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9283 finished with score 2316.0, result : lose board : [[  4.   8.   2.   4.]\n",
      " [ 16.  32.   4.   2.]\n",
      " [256.   8.  64.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9284 finished with score 1572.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [ 16.   2.  64.   4.]\n",
      " [ 64. 128.   4.   8.]\n",
      " [  2.   4.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9285 finished with score 3032.0, result : lose board : [[16.0, 8.0, 4, 2], [128.0, 64.0, 8.0, 4.0], [16.0, 256.0, 32.0, 2.0], [8.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9286 finished with score 5036.0, result : lose board : [[  8.  32.   8.   2.]\n",
      " [512.   8.  16.   8.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9287 finished with score 1592.0, result : lose board : [[ 16.   2.   8.   4.]\n",
      " [128.  32.  16.   8.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9288 finished with score 700.0, result : lose board : [[2.0, 8.0, 2.0, 4.0], [8.0, 32.0, 16.0, 2], [2.0, 16.0, 64.0, 4.0], [8.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9289 finished with score 3084.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 32. 128.   8.   4.]\n",
      " [  2.   4.  16.   8.]\n",
      " [ 64.   8.   2. 256.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9290 finished with score 2792, result : lose board : [[  8   4   2   4]\n",
      " [ 64  32   4   2]\n",
      " [256  64  32   4]\n",
      " [  2  32   8   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9291 finished with score 2996.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 128.0, 16.0, 4.0], [32.0, 256.0, 32.0, 8.0], [4.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9292 finished with score 2220.0, result : lose board : [[8.0, 16.0, 8.0, 2.0], [2.0, 128.0, 32.0, 4.0], [128.0, 64.0, 16.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9293 finished with score 2464.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [128.  64.  32.   8.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9294 finished with score 1424.0, result : lose board : [[2.0, 8.0, 32.0, 2.0], [16.0, 64.0, 8.0, 4.0], [2.0, 128.0, 16.0, 8.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9295 finished with score 2928.0, result : lose board : [[  4.  32.   2.   4.]\n",
      " [  2. 256.   4.   8.]\n",
      " [  4.  32.  16.   4.]\n",
      " [  2. 128.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9296 finished with score 2868.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 32.0, 256.0, 16.0], [128.0, 8.0, 32.0, 4.0], [4.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9297 finished with score 2904.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  8. 128.  16.   4.]\n",
      " [ 16. 256.  32.   8.]\n",
      " [  2.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9298 finished with score 3672.0, result : lose board : [[2.0, 64.0, 4.0, 2], [32.0, 128.0, 16.0, 4.0], [8.0, 256.0, 64.0, 8.0], [2.0, 64.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9299 finished with score 1484, result : lose board : [[2, 16, 8, 2], [8, 128, 16, 4], [2, 32, 64, 8], [32, 16, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9300 finished with score 2648.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2.  64.  32.   8.]\n",
      " [128.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9301 finished with score 4776.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  2. 512.  16.   8.]\n",
      " [ 32.  16.  64.   4.]\n",
      " [  8.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 234, Loss : 0.47631096839904785\n",
      "Mini-Batch - 1 Back-Prop : 234, Loss : 0.4333035945892334\n",
      "Mini-Batch - 2 Back-Prop : 234, Loss : 0.4363015294075012\n",
      "Mini-Batch - 3 Back-Prop : 234, Loss : 0.47700172662734985\n",
      "Mini-Batch - 4 Back-Prop : 234, Loss : 0.4158085286617279\n",
      "Mini-Batch - 5 Back-Prop : 234, Loss : 0.29080909490585327\n",
      "Mini-Batch - 6 Back-Prop : 234, Loss : 0.31667107343673706\n",
      "Mini-Batch - 7 Back-Prop : 234, Loss : 0.34088075160980225\n",
      "Mini-Batch - 8 Back-Prop : 234, Loss : 0.4120747447013855\n",
      "Mini-Batch - 9 Back-Prop : 234, Loss : 0.6113667488098145\n",
      "Mini-Batch - 10 Back-Prop : 234, Loss : 0.608890950679779\n",
      "Episode 9302 finished with score 2904.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [256.0, 32.0, 16.0, 2.0], [2, 4.0, 128.0, 8.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9303 finished with score 1780.0, result : lose board : [[ 64.  16.   4.   2.]\n",
      " [  4.  64.  16.   8.]\n",
      " [  8. 128.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9304 finished with score 3192.0, result : lose board : [[ 32.   2.  16.   2.]\n",
      " [  2. 256.  32.   4.]\n",
      " [ 16.  64.   2.   8.]\n",
      " [  8. 128.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9305 finished with score 4968.0, result : lose board : [[2.0, 8.0, 4.0, 2], [512.0, 2.0, 64.0, 4.0], [16.0, 64.0, 32.0, 8.0], [2.0, 32.0, 2.0, 16.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9306 finished with score 3628.0, result : lose board : [[  4.  64.   8.   4.]\n",
      " [ 64.   4.  32.   2.]\n",
      " [  2.  64. 128.   8.]\n",
      " [256.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9307 finished with score 1544.0, result : lose board : [[  4.   2.  32.   2.]\n",
      " [ 32. 128.   8.  16.]\n",
      " [  2.  64.  32.   2.]\n",
      " [  8.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9308 finished with score 1440.0, result : lose board : [[16.0, 8.0, 2.0, 8.0], [64.0, 32.0, 4.0, 2.0], [2.0, 128.0, 32.0, 8.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9309 finished with score 3492.0, result : lose board : [[2.0, 16.0, 4.0, 2], [256.0, 128.0, 16.0, 8.0], [128.0, 16.0, 4.0, 2.0], [4.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9310 finished with score 2864.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  2. 256.  32.   8.]\n",
      " [ 64.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9311 finished with score 3068.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 128.0, 8.0, 4.0], [4.0, 256.0, 32.0, 16.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9312 finished with score 2676.0, result : lose board : [[2.0, 64.0, 16.0, 4.0], [4.0, 256.0, 32.0, 16.0], [16.0, 64.0, 2.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9313 finished with score 3488.0, result : lose board : [[32.0, 8.0, 4, 2], [4.0, 64.0, 16.0, 8.0], [128.0, 256.0, 32.0, 2.0], [4.0, 16.0, 64.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9314 finished with score 2680.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [ 16. 256.  16.   4.]\n",
      " [ 64.  16.  64.   8.]\n",
      " [  4.   2.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9315 finished with score 3600.0, result : lose board : [[64.0, 32.0, 4.0, 2], [2.0, 64.0, 16.0, 4.0], [4.0, 128.0, 32.0, 2.0], [256.0, 32.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9316 finished with score 3108.0, result : lose board : [[2.0, 128.0, 2.0, 32.0], [64.0, 2.0, 16.0, 2.0], [2.0, 256.0, 32.0, 8.0], [16.0, 8.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9317 finished with score 3056.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [64.0, 32.0, 128.0, 8.0], [8.0, 256.0, 8.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9318 finished with score 2272.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  2.  32.  16.   2.]\n",
      " [  4. 256.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9319 finished with score 1940.0, result : lose board : [[32.0, 8.0, 4.0, 2], [4.0, 64.0, 2.0, 16.0], [64.0, 128.0, 4.0, 2.0], [8.0, 64.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9320 finished with score 3836.0, result : lose board : [[32.0, 8.0, 4, 2], [4.0, 256.0, 8.0, 4.0], [2.0, 4.0, 16.0, 8.0], [256.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9321 finished with score 2836.0, result : lose board : [[ 32.   4.  16.   4.]\n",
      " [  2.  64.  32.   2.]\n",
      " [  4. 256.  16.   8.]\n",
      " [  2.  64.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9322 finished with score 1052.0, result : lose board : [[2, 64.0, 8.0, 2], [4.0, 8.0, 4.0, 8.0], [8.0, 64.0, 16.0, 4.0], [2.0, 4.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9323 finished with score 3492.0, result : lose board : [[4.0, 32.0, 2.0, 4.0], [2, 16.0, 256.0, 16.0], [128.0, 64.0, 16.0, 4.0], [64.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9324 finished with score 2848.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [32.0, 8.0, 256.0, 2.0], [2.0, 32.0, 16.0, 8.0], [128.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9325 finished with score 3096.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [2.0, 128.0, 32.0, 8.0], [16.0, 64.0, 256.0, 4.0], [2.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9326 finished with score 1544.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  4.  64.  16.   8.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 235, Loss : 0.42492660880088806\n",
      "Mini-Batch - 1 Back-Prop : 235, Loss : 0.36996930837631226\n",
      "Mini-Batch - 2 Back-Prop : 235, Loss : 0.33119702339172363\n",
      "Mini-Batch - 3 Back-Prop : 235, Loss : 0.5214247703552246\n",
      "Mini-Batch - 4 Back-Prop : 235, Loss : 0.3650241494178772\n",
      "Mini-Batch - 5 Back-Prop : 235, Loss : 0.33808690309524536\n",
      "Mini-Batch - 6 Back-Prop : 235, Loss : 0.9422637224197388\n",
      "Mini-Batch - 7 Back-Prop : 235, Loss : 0.43780970573425293\n",
      "Mini-Batch - 8 Back-Prop : 235, Loss : 0.48823294043540955\n",
      "Mini-Batch - 9 Back-Prop : 235, Loss : 0.786342203617096\n",
      "Mini-Batch - 10 Back-Prop : 235, Loss : 0.8354042172431946\n",
      "Episode 9327 finished with score 3388.0, result : lose board : [[32.0, 8.0, 2, 4], [64.0, 16.0, 8.0, 16.0], [256.0, 128.0, 64.0, 4.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9328 finished with score 1560.0, result : lose board : [[  8.   2.  32.   4.]\n",
      " [ 32.  16.   2.   8.]\n",
      " [ 64. 128.  32.   4.]\n",
      " [  4.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9329 finished with score 3000.0, result : lose board : [[32.0, 16.0, 4.0, 2], [256.0, 128.0, 8.0, 4.0], [2.0, 32.0, 16.0, 2.0], [32.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9330 finished with score 1496.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [4.0, 128.0, 16.0, 8.0], [32.0, 64.0, 32.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9331 finished with score 1272.0, result : lose board : [[8.0, 2.0, 4.0, 2.0], [2.0, 8.0, 16.0, 8.0], [32.0, 128.0, 2.0, 4], [2, 4.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9332 finished with score 2488.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [ 32.  64.  16.   8.]\n",
      " [256.   4.  32.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9333 finished with score 3384.0, result : lose board : [[4.0, 64.0, 8.0, 2.0], [2.0, 256.0, 2.0, 4.0], [128.0, 64.0, 16.0, 8.0], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9334 finished with score 3288.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [256.0, 64.0, 32.0, 4.0], [32.0, 128.0, 16.0, 8.0], [4.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9335 finished with score 3368.0, result : lose board : [[2.0, 64.0, 16.0, 4.0], [16.0, 128.0, 8.0, 2.0], [4.0, 256.0, 32.0, 16.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9336 finished with score 1332.0, result : lose board : [[64.0, 8.0, 2.0, 4.0], [128.0, 16.0, 32.0, 2.0], [16.0, 2.0, 8.0, 4.0], [2, 4.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9337 finished with score 1496.0, result : lose board : [[16, 8, 4, 2], [32, 64, 8, 4], [128, 32, 16, 2], [2, 16, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9338 finished with score 3184, result : lose board : [[2, 32, 4, 2], [16, 2, 8, 4], [8, 256, 64, 8], [128, 32, 16, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9339 finished with score 3440.0, result : lose board : [[4.0, 64.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [256.0, 16.0, 128.0, 16.0], [4.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9340 finished with score 3852.0, result : lose board : [[2.0, 32.0, 4.0, 2.0], [4.0, 128.0, 8.0, 4.0], [128.0, 256.0, 64.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9341 finished with score 4476.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [128. 256.   8.   4.]\n",
      " [  2.  32.  16.   8.]\n",
      " [256.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9342 finished with score 4184.0, result : lose board : [[4.0, 2.0, 16.0, 2.0], [256.0, 64.0, 32.0, 4.0], [8.0, 256.0, 16.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9343 finished with score 1204.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [ 16.   4.   8.   4.]\n",
      " [  2.  16.   4. 128.]\n",
      " [  8.   4.  64.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9344 finished with score 2624.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [ 64.   4.  32.   8.]\n",
      " [ 32.   8. 256.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9345 finished with score 836.0, result : lose board : [[4.0, 2.0, 4.0, 2.0], [8.0, 4.0, 64.0, 8.0], [4.0, 32.0, 16.0, 4.0], [64.0, 2.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9346 finished with score 2744.0, result : lose board : [[  8.  64.   8.   2.]\n",
      " [  2. 256.  16.   4.]\n",
      " [  8.  64.  32.   8.]\n",
      " [ 32.   4.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9347 finished with score 1460.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  4.  32.  16.   2.]\n",
      " [ 16. 128.  64.   8.]\n",
      " [  4.   8.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9348 finished with score 1960.0, result : lose board : [[64.0, 16.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [2.0, 128.0, 64.0, 8.0], [64.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9349 finished with score 2872.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [128.   2.  16.   8.]\n",
      " [ 32. 256.  32.   4.]\n",
      " [  4.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9350 finished with score 2376.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [64.0, 128.0, 16.0, 2.0], [2.0, 64.0, 32.0, 4.0], [128.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9351 finished with score 2124.0, result : lose board : [[  8.   2.   8.   4.]\n",
      " [ 32. 128.   4.   2.]\n",
      " [  4.  64.  16.   8.]\n",
      " [ 32. 128.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9352 finished with score 2564.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  2.  32.  64.   4.]\n",
      " [256.  16.   4.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9353 finished with score 3012.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [ 32. 256.  64.   8.]\n",
      " [  8.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 236, Loss : 0.3543071150779724\n",
      "Mini-Batch - 1 Back-Prop : 236, Loss : 0.37228822708129883\n",
      "Mini-Batch - 2 Back-Prop : 236, Loss : 0.34597358107566833\n",
      "Mini-Batch - 3 Back-Prop : 236, Loss : 0.35052981972694397\n",
      "Mini-Batch - 4 Back-Prop : 236, Loss : 0.4130648970603943\n",
      "Mini-Batch - 5 Back-Prop : 236, Loss : 0.34380611777305603\n",
      "Mini-Batch - 6 Back-Prop : 236, Loss : 0.42701807618141174\n",
      "Mini-Batch - 7 Back-Prop : 236, Loss : 0.4137533903121948\n",
      "Mini-Batch - 8 Back-Prop : 236, Loss : 0.3276650309562683\n",
      "Mini-Batch - 9 Back-Prop : 236, Loss : 0.3566649556159973\n",
      "Mini-Batch - 10 Back-Prop : 236, Loss : 0.37298932671546936\n",
      "Episode 9354 finished with score 3300.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [256. 128.  16.   4.]\n",
      " [  2.  32.  64.   2.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9355 finished with score 1872.0, result : lose board : [[4.0, 32.0, 8.0, 2.0], [32.0, 16.0, 64.0, 4.0], [4.0, 128.0, 16.0, 8.0], [64.0, 32.0, 8, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9356 finished with score 3280.0, result : lose board : [[2.0, 32.0, 8.0, 2], [4.0, 64.0, 16.0, 8.0], [128.0, 256.0, 32.0, 4.0], [8.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9357 finished with score 1680.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [  2.  64.  16.   8.]\n",
      " [ 32.   4.  32. 128.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9358 finished with score 2880.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [32.0, 2.0, 32.0, 4.0], [4.0, 128.0, 256.0, 8.0], [2, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9359 finished with score 3344.0, result : lose board : [[2.0, 8.0, 4, 2], [8.0, 64.0, 8.0, 4.0], [128.0, 256.0, 32.0, 8.0], [64.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9360 finished with score 1496.0, result : lose board : [[  8.   4.  16.   2.]\n",
      " [ 32.   8.  32.   8.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9361 finished with score 3004.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [ 64. 256.  16.   4.]\n",
      " [  2.  64.  32.   8.]\n",
      " [ 64.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9362 finished with score 2620.0, result : lose board : [[8.0, 4.0, 64.0, 4.0], [4.0, 32.0, 4.0, 2.0], [64.0, 256.0, 2.0, 8.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9363 finished with score 1720, result : lose board : [[  4  16   4   2]\n",
      " [  2 128  64   4]\n",
      " [ 64   2  32   8]\n",
      " [  2  32  16   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9364 finished with score 5584.0, result : lose board : [[32.0, 16.0, 8.0, 4.0], [128.0, 512.0, 16.0, 2.0], [32.0, 8.0, 64.0, 8.0], [4.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9365 finished with score 3180.0, result : lose board : [[4.0, 64.0, 4.0, 2], [2, 256.0, 128.0, 8.0], [32.0, 8.0, 32.0, 16.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9366 finished with score 3076.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [2, 64.0, 16.0, 8.0], [8.0, 256.0, 32.0, 2.0], [4.0, 128.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9367 finished with score 3152.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2.0, 32.0, 16.0, 8.0], [4.0, 128.0, 256.0, 4.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9368 finished with score 1432.0, result : lose board : [[2.0, 32.0, 4.0, 2], [128.0, 16.0, 8.0, 4.0], [2.0, 64.0, 32.0, 2.0], [4.0, 16.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9369 finished with score 3060.0, result : lose board : [[ 64.   8.   4.   2.]\n",
      " [  4.  32.  16.   8.]\n",
      " [  2. 128. 256.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9370 finished with score 3044.0, result : lose board : [[ 64.  16.   8.   2.]\n",
      " [  2.  64.   4.  16.]\n",
      " [ 64. 256.  32.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9371 finished with score 2764.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [4.0, 64.0, 16.0, 4.0], [2.0, 256.0, 64.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9372 finished with score 1632, result : lose board : [[  2  16   8   2]\n",
      " [128  64   4   8]\n",
      " [ 16  32  16   4]\n",
      " [ 32  16  32   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9373 finished with score 1584.0, result : lose board : [[2.0, 16.0, 8.0, 4], [16.0, 128.0, 16.0, 2.0], [32.0, 4.0, 32.0, 8.0], [64.0, 16.0, 4.0, 16.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9374 finished with score 2496.0, result : lose board : [[ 64.  16.   4.   2.]\n",
      " [  2. 128.  32.   4.]\n",
      " [128.  64.   8.  16.]\n",
      " [ 32.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9375 finished with score 3128.0, result : lose board : [[  8.   2.   8.   4.]\n",
      " [ 16.  64. 128.   8.]\n",
      " [  8. 256.  16.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9376 finished with score 2932.0, result : lose board : [[128.  16.   8.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 16. 256.  32.   2.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9377 finished with score 404.0, result : lose board : [[16.0, 8.0, 4.0, 2], [4.0, 16.0, 2.0, 4.0], [32.0, 8.0, 4.0, 8.0], [8.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9378 finished with score 3192.0, result : lose board : [[32.0, 8.0, 4, 2], [64.0, 16.0, 32.0, 4.0], [256.0, 128.0, 8.0, 2.0], [2, 8.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9379, Score : 6100.0, Iters : 400, Finish : not over\n",
      "Episode 9379 finished with score 6996.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [32.0, 256.0, 16.0, 8.0], [512.0, 128.0, 32.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 237, Loss : 0.6527789235115051\n",
      "Mini-Batch - 1 Back-Prop : 237, Loss : 0.662510871887207\n",
      "Mini-Batch - 2 Back-Prop : 237, Loss : 0.3525889813899994\n",
      "Mini-Batch - 3 Back-Prop : 237, Loss : 0.6004989147186279\n",
      "Mini-Batch - 4 Back-Prop : 237, Loss : 0.4507977068424225\n",
      "Mini-Batch - 5 Back-Prop : 237, Loss : 0.6123940348625183\n",
      "Mini-Batch - 6 Back-Prop : 237, Loss : 0.8668631911277771\n",
      "Mini-Batch - 7 Back-Prop : 237, Loss : 1.0006911754608154\n",
      "Mini-Batch - 8 Back-Prop : 237, Loss : 0.9543917775154114\n",
      "Mini-Batch - 9 Back-Prop : 237, Loss : 0.40224266052246094\n",
      "Mini-Batch - 10 Back-Prop : 237, Loss : 0.5414265394210815\n",
      "Episode 9380 finished with score 3300.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [  8. 128.  16.   8.]\n",
      " [256.   2.  32.   4.]\n",
      " [ 64.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9381 finished with score 1348.0, result : lose board : [[  4.   2.  16.   2.]\n",
      " [ 32.  16.   8.   4.]\n",
      " [  4.   8.  64.   2.]\n",
      " [  2. 128.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9382 finished with score 2808.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [  8.   4.  16.   8.]\n",
      " [  2. 128. 256.   4.]\n",
      " [ 16.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9383 finished with score 1448.0, result : lose board : [[  2.   4.   2.   4.]\n",
      " [ 64.  32.  16.   2.]\n",
      " [128.   8.  32.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9384 finished with score 1772.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [128.   8.   2.   8.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9385 finished with score 4676.0, result : lose board : [[32.0, 16.0, 8.0, 4.0], [256.0, 32.0, 4.0, 8.0], [128.0, 256.0, 16.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9386 finished with score 3544.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  4.  64.  32.   2.]\n",
      " [256. 128.  16.   4.]\n",
      " [  2.  64.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9387 finished with score 276.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 4.0, 16.0, 4.0], [8.0, 2.0, 32.0, 8.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9388 finished with score 2940.0, result : lose board : [[  8.   2.  16.   2.]\n",
      " [ 32.  16.  32.   4.]\n",
      " [  4. 256.  16.   8.]\n",
      " [  8. 128.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9389 finished with score 2796.0, result : lose board : [[2.0, 8.0, 4.0, 2], [16.0, 2.0, 256.0, 4.0], [128.0, 32.0, 16.0, 8.0], [16.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9390 finished with score 724.0, result : lose board : [[2.0, 8.0, 4, 2], [32.0, 16.0, 8.0, 4.0], [8.0, 32.0, 64.0, 8.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9391 finished with score 2984.0, result : lose board : [[4.0, 32.0, 8.0, 2.0], [256.0, 128.0, 16.0, 8.0], [32.0, 16.0, 32.0, 2.0], [2, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9392 finished with score 1772.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  2. 128.  64.   8.]\n",
      " [ 32.   4.   2.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9393 finished with score 1692.0, result : lose board : [[32.0, 16.0, 4.0, 2], [64.0, 32.0, 16.0, 8.0], [2.0, 128.0, 32.0, 4.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9394 finished with score 1764.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [2.0, 64.0, 8.0, 4.0], [4.0, 128.0, 32.0, 16.0], [64.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9395 finished with score 3312.0, result : lose board : [[4.0, 64.0, 16.0, 2.0], [2.0, 256.0, 8.0, 4.0], [128.0, 64.0, 16.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9396 finished with score 2280.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [8.0, 256.0, 16.0, 4.0], [2.0, 16.0, 64.0, 8.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9397 finished with score 1412.0, result : lose board : [[2.0, 4.0, 2.0, 8.0], [64.0, 16.0, 8.0, 16.0], [2.0, 128.0, 32.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9398 finished with score 2948.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  4.  32.  16.   8.]\n",
      " [ 32.   2. 128.  16.]\n",
      " [256.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9399 finished with score 3248.0, result : lose board : [[32.0, 2.0, 16.0, 2.0], [2.0, 64.0, 32.0, 4.0], [256.0, 128.0, 16.0, 8.0], [2.0, 32.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9400 finished with score 2172.0, result : lose board : [[  2. 256.   4.   2.]\n",
      " [  8.  32.  16.   8.]\n",
      " [  2.  16.  32.   4.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9401 finished with score 4700.0, result : lose board : [[  2.   4.  32.   4.]\n",
      " [ 16. 512.  16.   2.]\n",
      " [  4.  32.   4.   8.]\n",
      " [ 16.   2.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9402 finished with score 3732.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2. 256.  64.  16.]\n",
      " [ 64.  16.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9403 finished with score 4336.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [128.  64.  32.   8.]\n",
      " [256. 128.  16.   4.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9404 finished with score 1188.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  4.  16.   8.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9405 finished with score 2168.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 64.0, 128.0, 8.0], [16.0, 128.0, 32.0, 4.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9406 finished with score 3048.0, result : lose board : [[2.0, 8.0, 2.0, 4.0], [256.0, 64.0, 8.0, 2], [8.0, 128.0, 32.0, 8.0], [4.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 238, Loss : 0.321371465921402\n",
      "Mini-Batch - 1 Back-Prop : 238, Loss : 0.35365796089172363\n",
      "Mini-Batch - 2 Back-Prop : 238, Loss : 0.30928701162338257\n",
      "Mini-Batch - 3 Back-Prop : 238, Loss : 0.24651387333869934\n",
      "Mini-Batch - 4 Back-Prop : 238, Loss : 0.562883198261261\n",
      "Mini-Batch - 5 Back-Prop : 238, Loss : 0.5077716708183289\n",
      "Mini-Batch - 6 Back-Prop : 238, Loss : 0.46401315927505493\n",
      "Mini-Batch - 7 Back-Prop : 238, Loss : 0.4204573333263397\n",
      "Mini-Batch - 8 Back-Prop : 238, Loss : 0.3885219097137451\n",
      "Mini-Batch - 9 Back-Prop : 238, Loss : 0.36717689037323\n",
      "Mini-Batch - 10 Back-Prop : 238, Loss : 0.6521262526512146\n",
      "Episode 9407 finished with score 5196.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [128. 512.   8.   4.]\n",
      " [  2.  32.  16.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9408 finished with score 1144.0, result : lose board : [[  2.   8.  32.   4.]\n",
      " [  4.  16.   8.   2.]\n",
      " [  8.  32.  16.   4.]\n",
      " [  2. 128.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9409 finished with score 3788.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [ 16.   8.  16.   8.]\n",
      " [ 32.   2. 256.   4.]\n",
      " [  2. 256.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9410 finished with score 1788.0, result : lose board : [[8.0, 2.0, 4.0, 2.0], [128.0, 32.0, 128.0, 8.0], [2.0, 8.0, 2.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9411 finished with score 3416.0, result : lose board : [[2, 32.0, 4.0, 64.0], [8.0, 128.0, 8.0, 2.0], [64.0, 256.0, 2.0, 8.0], [2.0, 4.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9412 finished with score 1516.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 64.  32.   8.   4.]\n",
      " [  2.   8. 128.  16.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9413 finished with score 3020, result : lose board : [[32, 8, 4, 2], [4, 128, 32, 8], [16, 256, 8, 2], [2, 32, 16, 8]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9414 finished with score 1480.0, result : lose board : [[16.0, 8.0, 4, 2], [64.0, 32.0, 8.0, 4.0], [2.0, 128.0, 16.0, 8.0], [32.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9415 finished with score 1928.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [64.0, 128.0, 16.0, 4.0], [2.0, 4.0, 64.0, 16.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9416 finished with score 3852.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [4.0, 128.0, 32.0, 4.0], [128.0, 16.0, 64.0, 8.0], [256.0, 2.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9417 finished with score 2988.0, result : lose board : [[  8.   4.  16.   4.]\n",
      " [ 64.  32.  64.   8.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9418 finished with score 4184.0, result : lose board : [[64.0, 16.0, 8.0, 2.0], [4.0, 256.0, 32.0, 4.0], [128.0, 4.0, 128.0, 64.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9419 finished with score 2684.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [ 16.  64.  32.   4.]\n",
      " [  2. 256.  16.   8.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9420, Score : 5672.0, Iters : 400, Finish : not over\n",
      "Episode 9420 finished with score 7532.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [256. 128.  32.   2.]\n",
      " [512.  64.  16.   4.]\n",
      " [ 64.  16.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9421 finished with score 1760.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  8.  64.  16.   2.]\n",
      " [ 64. 128.  32.   4.]\n",
      " [ 32.   4.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9422 finished with score 2928.0, result : lose board : [[  8.   2.  16.   2.]\n",
      " [256.  32.   8.   4.]\n",
      " [128.  16.  32.  16.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9423 finished with score 3068.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 256.0, 16.0, 8.0], [128.0, 32.0, 64.0, 2.0], [4.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9424 finished with score 2772.0, result : lose board : [[4.0, 64.0, 4, 2], [8.0, 16.0, 8.0, 4.0], [2.0, 64.0, 256.0, 64.0], [4.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9425 finished with score 2208.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [ 64. 128.  64.   8.]\n",
      " [  2.  64.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9426 finished with score 3172.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [  2. 128.   8.   4.]\n",
      " [256.  64.  32.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9427 finished with score 3864.0, result : lose board : [[ 16.   4. 256.   2.]\n",
      " [ 64.  16. 128.   4.]\n",
      " [128.   8.  16.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9428 finished with score 2476.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [4.0, 64.0, 16.0, 4.0], [32.0, 16.0, 4.0, 8.0], [256.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9429 finished with score 1956.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [128.   8.   4.   8.]\n",
      " [  2.   4.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9430 finished with score 2744.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  8.  16.  64.   4.]\n",
      " [ 16. 256.   8.  32.]\n",
      " [  2.  64.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 239, Loss : 0.5482252836227417\n",
      "Mini-Batch - 1 Back-Prop : 239, Loss : 0.4326004683971405\n",
      "Mini-Batch - 2 Back-Prop : 239, Loss : 0.46722176671028137\n",
      "Mini-Batch - 3 Back-Prop : 239, Loss : 0.3436668813228607\n",
      "Mini-Batch - 4 Back-Prop : 239, Loss : 0.3149537444114685\n",
      "Mini-Batch - 5 Back-Prop : 239, Loss : 0.6007317304611206\n",
      "Mini-Batch - 6 Back-Prop : 239, Loss : 0.5977140069007874\n",
      "Mini-Batch - 7 Back-Prop : 239, Loss : 0.8153291344642639\n",
      "Mini-Batch - 8 Back-Prop : 239, Loss : 1.016944408416748\n",
      "Mini-Batch - 9 Back-Prop : 239, Loss : 0.6727627515792847\n",
      "Mini-Batch - 10 Back-Prop : 239, Loss : 0.5981265902519226\n",
      "Episode 9431 finished with score 2392.0, result : lose board : [[  4.  32.   4.   2.]\n",
      " [  8. 256.  32.   4.]\n",
      " [  2.  64.   4.   8.]\n",
      " [ 16.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9432 finished with score 4596.0, result : lose board : [[2.0, 16.0, 8.0, 2], [4.0, 32.0, 128.0, 16.0], [16.0, 8.0, 256.0, 4.0], [2.0, 256.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9433 finished with score 2216.0, result : lose board : [[  2.   4.  16.   2.]\n",
      " [256.  16.   2.   4.]\n",
      " [  4.  32.  16.   8.]\n",
      " [ 16.   8.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9434 finished with score 2504.0, result : lose board : [[16.0, 8.0, 4.0, 2], [32.0, 64.0, 32.0, 4.0], [256.0, 32.0, 2.0, 8.0], [16.0, 2.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9435 finished with score 748.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 16.0, 32.0, 4.0], [64.0, 4.0, 16.0, 2.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9436 finished with score 4696.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [ 32.  16.  64.   8.]\n",
      " [  2.   8.  16.  32.]\n",
      " [  8. 512.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9437 finished with score 2540.0, result : lose board : [[4.0, 16.0, 4.0, 2], [64.0, 32.0, 2.0, 4.0], [4.0, 256.0, 4.0, 2.0], [32.0, 16.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9438 finished with score 2472.0, result : lose board : [[64.0, 16.0, 8.0, 4.0], [128.0, 64.0, 16.0, 2.0], [4.0, 128.0, 32.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9439 finished with score 4080.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [128.0, 8.0, 32.0, 4.0], [4.0, 64.0, 128.0, 64.0], [2.0, 256.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9440 finished with score 2856.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [ 32.  64.   8.   4.]\n",
      " [  8. 256.  32.   8.]\n",
      " [ 64.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9441 finished with score 2348.0, result : lose board : [[4, 16.0, 4, 2], [8.0, 64.0, 2.0, 8.0], [16.0, 256.0, 8.0, 4.0], [4.0, 8.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9442 finished with score 3712.0, result : lose board : [[2.0, 16.0, 4.0, 2], [64.0, 32.0, 16.0, 4.0], [128.0, 256.0, 64.0, 8.0], [64.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9443 finished with score 1684.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9444 finished with score 1972.0, result : lose board : [[  4.  64.   4.   2.]\n",
      " [  2. 128.   8.   4.]\n",
      " [ 64.  32.  64.   8.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9445 finished with score 4160.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [256.0, 64.0, 32.0, 2.0], [2.0, 256.0, 16.0, 4.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9446 finished with score 1468.0, result : lose board : [[  2.  32.  16.   2.]\n",
      " [  8. 128.   2.   4.]\n",
      " [ 32.   8.   4.   2.]\n",
      " [ 64.  32.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9447 finished with score 5472.0, result : lose board : [[2.0, 8.0, 16.0, 2.0], [16.0, 32.0, 128.0, 4.0], [64.0, 16.0, 512.0, 32.0], [8.0, 2.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9448 finished with score 3188.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 32.0, 256.0, 4.0], [64.0, 128.0, 16.0, 8.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9449 finished with score 3340.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [256.  64.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [  2.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9450 finished with score 1948.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [128.0, 32.0, 16.0, 8.0], [16.0, 128.0, 4.0, 2], [2.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9451 finished with score 5340.0, result : lose board : [[128.   8.   4.   2.]\n",
      " [  2.  64.   8.   4.]\n",
      " [ 32. 512.  16.   8.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9452 finished with score 2916.0, result : lose board : [[16.0, 8, 4, 2], [2.0, 128.0, 32.0, 4.0], [4.0, 256.0, 16.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9453 finished with score 1816.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [ 64.  32.   8.   4.]\n",
      " [  4. 128.  64.  16.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9454 finished with score 5420.0, result : lose board : [[32.0, 16.0, 4.0, 2], [512.0, 32.0, 16.0, 8.0], [2.0, 128.0, 32.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 240, Loss : 0.3874579668045044\n",
      "Mini-Batch - 1 Back-Prop : 240, Loss : 0.2979089915752411\n",
      "Mini-Batch - 2 Back-Prop : 240, Loss : 0.2425297200679779\n",
      "Mini-Batch - 3 Back-Prop : 240, Loss : 0.38884180784225464\n",
      "Mini-Batch - 4 Back-Prop : 240, Loss : 0.4673216938972473\n",
      "Mini-Batch - 5 Back-Prop : 240, Loss : 0.3617525100708008\n",
      "Mini-Batch - 6 Back-Prop : 240, Loss : 0.3937467932701111\n",
      "Mini-Batch - 7 Back-Prop : 240, Loss : 0.4615870416164398\n",
      "Mini-Batch - 8 Back-Prop : 240, Loss : 0.6646544933319092\n",
      "Mini-Batch - 9 Back-Prop : 240, Loss : 0.41263020038604736\n",
      "Mini-Batch - 10 Back-Prop : 240, Loss : 0.38962608575820923\n",
      "Episode 9455 finished with score 3056.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  4.  32. 256.   8.]\n",
      " [128.  16.   8.   2.]\n",
      " [  2.  64.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9456, Score : 5888.0, Iters : 400, Finish : not over\n",
      "Episode 9456 finished with score 6128.0, result : lose board : [[ 32.   2.   4.   2.]\n",
      " [  2.  64.  32.   8.]\n",
      " [128. 512.  16.   4.]\n",
      " [  4. 128.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9457 finished with score 2728.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [  2. 256.  32.   8.]\n",
      " [ 64.   8.  64.   4.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9458 finished with score 3336.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  4.  64.  32.   8.]\n",
      " [256. 128.  16.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9459 finished with score 5020.0, result : lose board : [[ 16.   2.   8.   2.]\n",
      " [  2. 512.  64.   8.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  4.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9460 finished with score 1484.0, result : lose board : [[16.0, 8.0, 4, 2], [4.0, 32.0, 16.0, 4.0], [128.0, 64.0, 4.0, 8.0], [32.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9461 finished with score 5472.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [512.  64.  32.   4.]\n",
      " [ 32. 128.  16.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9462 finished with score 3308.0, result : lose board : [[  2.   4.   2.   4.]\n",
      " [256.  64.   8.   2.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9463 finished with score 3172.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 32. 256.  32.   8.]\n",
      " [  4. 128.  16.   4.]\n",
      " [  8.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9464 finished with score 1332.0, result : lose board : [[  2. 128.   8.   4.]\n",
      " [  8.  32.   4.   8.]\n",
      " [ 16.   2.  64.   4.]\n",
      " [  8.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9465 finished with score 1616.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [ 64.  32.   8.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9466 finished with score 3304.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32. 256. 128.   4.]\n",
      " [  8.  64.   4.  32.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9467 finished with score 2896.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [ 64.   8.  64.   8.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 64.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9468 finished with score 2716.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [ 16.   4.  16.   8.]\n",
      " [  8. 256.  64.  16.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9469 finished with score 3896.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [128.  64.  32.   4.]\n",
      " [256. 128.  16.   2.]\n",
      " [  4.  32.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9470 finished with score 3672.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [256.0, 128.0, 8.0, 4.0], [128.0, 32.0, 16.0, 8.0], [16.0, 8.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9471 finished with score 1412.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [32.0, 64.0, 4.0, 8.0], [128.0, 8.0, 32.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9472 finished with score 1316.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [8.0, 128.0, 2.0, 4.0], [2.0, 64.0, 32.0, 8.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9473 finished with score 2424.0, result : lose board : [[2.0, 32.0, 4.0, 2], [4.0, 256.0, 8.0, 4.0], [16.0, 64.0, 32.0, 8.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9474, Score : 6052.0, Iters : 400, Finish : not over\n",
      "Episode 9474 finished with score 6404.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [  2.   4. 512.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9475 finished with score 2924.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [ 64.  32.  64.   8.]\n",
      " [  8. 256.  16.   4.]\n",
      " [  4.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9476 finished with score 2708.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [256.  64.  16.   8.]\n",
      " [ 32.   4.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9477 finished with score 2396.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [16.0, 256.0, 32.0, 2.0], [32.0, 16.0, 8.0, 4.0], [8.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 241, Loss : 0.32194483280181885\n",
      "Mini-Batch - 1 Back-Prop : 241, Loss : 0.32360202074050903\n",
      "Mini-Batch - 2 Back-Prop : 241, Loss : 0.3897045850753784\n",
      "Mini-Batch - 3 Back-Prop : 241, Loss : 0.5193787813186646\n",
      "Mini-Batch - 4 Back-Prop : 241, Loss : 0.6263855695724487\n",
      "Mini-Batch - 5 Back-Prop : 241, Loss : 0.4630812108516693\n",
      "Mini-Batch - 6 Back-Prop : 241, Loss : 0.5792417526245117\n",
      "Mini-Batch - 7 Back-Prop : 241, Loss : 0.6040628552436829\n",
      "Mini-Batch - 8 Back-Prop : 241, Loss : 1.0577009916305542\n",
      "Mini-Batch - 9 Back-Prop : 241, Loss : 0.5100699663162231\n",
      "Mini-Batch - 10 Back-Prop : 241, Loss : 0.4007234275341034\n",
      "Episode 9478 finished with score 2552.0, result : lose board : [[ 32.   2.   4.   8.]\n",
      " [  2.  16. 256.   4.]\n",
      " [ 64.  32.  16.   8.]\n",
      " [  8.   2.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9479 finished with score 2216.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [ 16. 128.  32.   8.]\n",
      " [128.   2.  16.   4.]\n",
      " [  2.  64.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9480 finished with score 2536.0, result : lose board : [[  2.  16.  32.   2.]\n",
      " [256.  64.   4.  16.]\n",
      " [  2.   8.  32.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9481 finished with score 1604.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [ 64.  32.   4.   2.]\n",
      " [  2. 128.  16.   8.]\n",
      " [ 64.   4.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9482 finished with score 2756.0, result : lose board : [[ 16.   2.   4.   2.]\n",
      " [  4. 256.   8.   4.]\n",
      " [128.  16.  32.   8.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9483 finished with score 3448.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [64.0, 32.0, 8.0, 4.0], [2.0, 256.0, 128.0, 8.0], [64.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9484 finished with score 1940.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [64.0, 128.0, 8.0, 4], [4.0, 64.0, 16.0, 8.0], [64.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9485 finished with score 1588.0, result : lose board : [[32.0, 16.0, 2, 4], [4.0, 64.0, 16.0, 8.0], [32.0, 128.0, 32.0, 2.0], [2.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9486 finished with score 716.0, result : lose board : [[ 8.  2.  8.  2.]\n",
      " [32.  8. 16.  4.]\n",
      " [ 2. 64. 32.  8.]\n",
      " [16.  8.  4.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9487 finished with score 5424.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [512. 128.  32.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9488 finished with score 2196.0, result : lose board : [[4.0, 8.0, 128.0, 2.0], [8.0, 64.0, 16.0, 4.0], [2.0, 128.0, 32.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9489 finished with score 2748.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [  8. 256.  16.   8.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9490 finished with score 3152.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [128. 256.   8.  16.]\n",
      " [  2.  64.  32.   4.]\n",
      " [ 16.   8.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9491 finished with score 2460.0, result : lose board : [[16.0, 8.0, 4.0, 2.0], [64.0, 32.0, 8.0, 4.0], [2.0, 256.0, 16.0, 8.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9492 finished with score 3172.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [128.  64.  16.   2.]\n",
      " [  4. 256.   8.   4.]\n",
      " [  2.  32.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9493 finished with score 1744.0, result : lose board : [[64.0, 16.0, 4, 2], [128.0, 64.0, 32.0, 8.0], [2.0, 8.0, 16.0, 4.0], [32.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9494 finished with score 3860.0, result : lose board : [[128.0, 16.0, 4.0, 2], [256.0, 128.0, 2.0, 4.0], [4.0, 64.0, 32.0, 8.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9495 finished with score 1580.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [128.  16.   8.   4.]\n",
      " [  2.   8.  64.   8.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9496 finished with score 2412.0, result : lose board : [[  2.   8.   2.   8.]\n",
      " [ 32.  16.   8.   2.]\n",
      " [256.  64.   2.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9497 finished with score 3972.0, result : lose board : [[64.0, 2.0, 8.0, 2], [8.0, 64.0, 128.0, 8.0], [256.0, 128.0, 16.0, 4.0], [2.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9498 finished with score 2220.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [128.  32.   4.   8.]\n",
      " [  4. 128.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9499 finished with score 4028.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4.   2. 128.  64.]\n",
      " [256.  64.  32.   4.]\n",
      " [  4. 128.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9500 finished with score 2844.0, result : lose board : [[64.0, 16.0, 8.0, 4.0], [4.0, 64.0, 16.0, 8.0], [2.0, 256.0, 32.0, 16.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9501 finished with score 1864.0, result : lose board : [[4.0, 64.0, 32.0, 2.0], [2.0, 128.0, 64.0, 8.0], [16.0, 4.0, 8.0, 4.0], [4.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9502 finished with score 2584.0, result : lose board : [[ 32.   4.   8.   4.]\n",
      " [  8. 256.  32.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9503 finished with score 1592.0, result : lose board : [[  2.  16.  32.   2.]\n",
      " [128.  32.   8.  16.]\n",
      " [ 64.   8.  16.   4.]\n",
      " [ 32.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9504 finished with score 2980.0, result : lose board : [[4.0, 16.0, 4.0, 2], [16.0, 128.0, 32.0, 4.0], [8.0, 256.0, 16.0, 8.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 242, Loss : 0.4367328882217407\n",
      "Mini-Batch - 1 Back-Prop : 242, Loss : 0.40884020924568176\n",
      "Mini-Batch - 2 Back-Prop : 242, Loss : 0.5434075593948364\n",
      "Mini-Batch - 3 Back-Prop : 242, Loss : 0.5334320068359375\n",
      "Mini-Batch - 4 Back-Prop : 242, Loss : 0.4961673617362976\n",
      "Mini-Batch - 5 Back-Prop : 242, Loss : 0.5839733481407166\n",
      "Mini-Batch - 6 Back-Prop : 242, Loss : 0.3889840245246887\n",
      "Mini-Batch - 7 Back-Prop : 242, Loss : 0.46740293502807617\n",
      "Mini-Batch - 8 Back-Prop : 242, Loss : 0.41686710715293884\n",
      "Mini-Batch - 9 Back-Prop : 242, Loss : 0.4559780955314636\n",
      "Mini-Batch - 10 Back-Prop : 242, Loss : 0.7527130842208862\n",
      "Episode 9505 finished with score 5596.0, result : lose board : [[64.0, 16.0, 8.0, 2], [512.0, 32.0, 16.0, 8.0], [2.0, 128.0, 2.0, 4.0], [64.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9506 finished with score 1596.0, result : lose board : [[2.0, 8.0, 4.0, 2], [4.0, 32.0, 16.0, 4.0], [64.0, 128.0, 4.0, 2.0], [2.0, 64.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9507 finished with score 3356.0, result : lose board : [[64.0, 8.0, 2.0, 4.0], [2.0, 128.0, 64.0, 2.0], [4.0, 256.0, 16.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9508 finished with score 1000.0, result : lose board : [[32.0, 16.0, 4.0, 2], [2.0, 64.0, 32.0, 8.0], [4.0, 16.0, 64.0, 2.0], [8.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9509 finished with score 2032.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.   8. 128.  16.]\n",
      " [128.  64.   4.   2.]\n",
      " [ 32.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9510 finished with score 2668.0, result : lose board : [[ 64.  32.   8.   2.]\n",
      " [  4.   2.  32.   4.]\n",
      " [256.  16.  64.   8.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9511 finished with score 3400.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [64.0, 256.0, 16.0, 2.0], [4.0, 128.0, 32.0, 4.0], [64.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9512 finished with score 1300, result : lose board : [[4, 32, 16, 4], [16, 4, 128, 32], [2, 32, 8, 4], [16, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9513 finished with score 1888.0, result : lose board : [[2.0, 128.0, 8.0, 2.0], [16.0, 2.0, 16.0, 4.0], [4.0, 128.0, 32.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9514 finished with score 3352.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [ 64. 256.  16.   8.]\n",
      " [  2. 128.  64.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9515 finished with score 1360.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [64.0, 32.0, 16.0, 4.0], [2.0, 64.0, 32.0, 8.0], [64.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9516 finished with score 3012.0, result : lose board : [[32.0, 16.0, 4, 2], [128.0, 32.0, 16.0, 4.0], [2.0, 256.0, 32.0, 8.0], [8.0, 4.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9517 finished with score 1852.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  2. 128.  64.   4.]\n",
      " [ 32.  64.  32.  16.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9518 finished with score 1516.0, result : lose board : [[16.0, 8.0, 4.0, 2.0], [4.0, 128.0, 16.0, 4.0], [2, 64.0, 32.0, 16.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9519 finished with score 2240.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [128.  64.   8.   4.]\n",
      " [  4. 128.  32.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9520 finished with score 3024.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  8. 256.  16.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  2.  32.  16.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9521 finished with score 736.0, result : lose board : [[4.0, 16.0, 4.0, 2], [64.0, 32.0, 16.0, 8.0], [32.0, 16.0, 8.0, 2.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9522 finished with score 3240.0, result : lose board : [[4.0, 16.0, 8.0, 2], [2.0, 64.0, 16.0, 8.0], [256.0, 32.0, 128.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9523 finished with score 3164.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [ 16. 256.  16.   8.]\n",
      " [  8.  64.  32.   4.]\n",
      " [128.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9524 finished with score 3392.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  4. 128.   8.   4.]\n",
      " [256.  64.  32.   2.]\n",
      " [ 64.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9525 finished with score 3396.0, result : lose board : [[  2.   4.  32.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [ 64.   8. 256.   2.]\n",
      " [ 16.   4.   2.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9526 finished with score 2868.0, result : lose board : [[32.0, 8.0, 4.0, 2], [8.0, 256.0, 8.0, 16.0], [128.0, 2.0, 32.0, 8.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9527 finished with score 2304.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  2.   8.  16.   4.]\n",
      " [ 16. 256.  64.   8.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9528 finished with score 2392.0, result : lose board : [[128.  16.   4.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [128.   2.  64.   8.]\n",
      " [  2.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9529 finished with score 2028.0, result : lose board : [[  8.   4. 128.   4.]\n",
      " [  4. 128.  32.   8.]\n",
      " [  8.   4.  16.   4.]\n",
      " [  2.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9530 finished with score 1448.0, result : lose board : [[2.0, 8.0, 2.0, 4.0], [8.0, 32.0, 4.0, 2.0], [32.0, 128.0, 64.0, 16.0], [2.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9531 finished with score 2588.0, result : lose board : [[32.0, 16.0, 4.0, 2], [2.0, 32.0, 8.0, 4.0], [256.0, 64.0, 32.0, 2.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 243, Loss : 0.4788181483745575\n",
      "Mini-Batch - 1 Back-Prop : 243, Loss : 0.68022620677948\n",
      "Mini-Batch - 2 Back-Prop : 243, Loss : 0.5137607455253601\n",
      "Mini-Batch - 3 Back-Prop : 243, Loss : 0.35952305793762207\n",
      "Mini-Batch - 4 Back-Prop : 243, Loss : 0.39301687479019165\n",
      "Mini-Batch - 5 Back-Prop : 243, Loss : 0.7045066356658936\n",
      "Mini-Batch - 6 Back-Prop : 243, Loss : 0.659133791923523\n",
      "Mini-Batch - 7 Back-Prop : 243, Loss : 0.6854167580604553\n",
      "Mini-Batch - 8 Back-Prop : 243, Loss : 0.6084800362586975\n",
      "Mini-Batch - 9 Back-Prop : 243, Loss : 0.3972073197364807\n",
      "Mini-Batch - 10 Back-Prop : 243, Loss : 0.47135403752326965\n",
      "Episode 9532 finished with score 3184.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 64.0, 32.0, 4.0], [8.0, 128.0, 16.0, 2.0], [32.0, 256.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9533 finished with score 1512.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [  4.  32.   8.  64.]\n",
      " [ 32. 128.   2.   8.]\n",
      " [  4.   8.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9534 finished with score 3064.0, result : lose board : [[4.0, 64.0, 8.0, 2], [32.0, 4.0, 16.0, 4.0], [16.0, 128.0, 8.0, 2.0], [4.0, 256.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9535 finished with score 3288.0, result : lose board : [[2.0, 32.0, 2.0, 4.0], [256.0, 64.0, 16.0, 2.0], [2.0, 128.0, 32.0, 8.0], [32.0, 2.0, 16.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9536 finished with score 2552.0, result : lose board : [[32.0, 2.0, 4, 2], [4.0, 256.0, 8.0, 4.0], [8.0, 64.0, 16.0, 2.0], [32.0, 16.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9537 finished with score 3152.0, result : lose board : [[16.0, 4.0, 2.0, 4.0], [32.0, 16.0, 4.0, 8.0], [4.0, 256.0, 64.0, 4.0], [128.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9538 finished with score 3648.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [128.0, 4.0, 128.0, 4.0], [32.0, 256.0, 16.0, 8.0], [16.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9539 finished with score 3156.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [16.0, 128.0, 16.0, 4.0], [256.0, 64.0, 32.0, 8.0], [4.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9540 finished with score 2964.0, result : lose board : [[4.0, 8.0, 4.0, 2], [32.0, 256.0, 8.0, 4.0], [4.0, 128.0, 16.0, 32.0], [32.0, 8.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9541 finished with score 2872.0, result : lose board : [[32.0, 16.0, 4.0, 2], [64.0, 256.0, 8.0, 16.0], [2.0, 64.0, 32.0, 4.0], [32.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9542 finished with score 1832.0, result : lose board : [[  8.   4.  16.   2.]\n",
      " [ 64.  32.  64.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [  4.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9543 finished with score 1388.0, result : lose board : [[2.0, 8.0, 4.0, 2], [128.0, 16.0, 8.0, 32.0], [2.0, 32.0, 2.0, 4.0], [4.0, 2.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9544 finished with score 3204.0, result : lose board : [[  2.  32.   2.   4.]\n",
      " [  8. 128.  16.   2.]\n",
      " [ 64. 256.  32.   8.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9545 finished with score 2060.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4. 128.  64.   4.]\n",
      " [ 32.   4. 128.  16.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9546 finished with score 3364.0, result : lose board : [[2.0, 8.0, 2, 4], [32.0, 64.0, 4.0, 8.0], [128.0, 256.0, 32.0, 4.0], [8.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9547 finished with score 1308.0, result : lose board : [[4.0, 32.0, 4.0, 2], [128.0, 16.0, 2.0, 8.0], [4.0, 64.0, 8.0, 2.0], [8.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9548 finished with score 1072.0, result : lose board : [[8.0, 16.0, 8.0, 2], [16.0, 64.0, 16.0, 8.0], [32.0, 4.0, 32.0, 4.0], [2.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9549 finished with score 4800.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4. 512.   8.   4.]\n",
      " [ 16.   8.  64.   8.]\n",
      " [  2.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9550 finished with score 1448.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [  8.  64.   4.   8.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9551 finished with score 2304.0, result : lose board : [[16.0, 2.0, 8.0, 4.0], [2.0, 32.0, 16.0, 8.0], [4.0, 256.0, 2.0, 4.0], [64.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9552 finished with score 3400.0, result : lose board : [[64.0, 16.0, 4.0, 2], [2.0, 4.0, 16.0, 4.0], [8.0, 64.0, 128.0, 32.0], [256.0, 8.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9553 finished with score 2236.0, result : lose board : [[4.0, 32.0, 8.0, 4.0], [16.0, 64.0, 16.0, 8.0], [2.0, 128.0, 32.0, 4.0], [128.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9554 finished with score 732.0, result : lose board : [[8.0, 16.0, 8.0, 2], [32.0, 64.0, 16.0, 4.0], [8.0, 32.0, 4.0, 2.0], [2.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9555, Score : 5776.0, Iters : 400, Finish : not over\n",
      "Episode 9555 finished with score 7428.0, result : lose board : [[  2. 128.   4.   2.]\n",
      " [ 16. 512.  16.   4.]\n",
      " [256.  16.  64.   8.]\n",
      " [ 64.   8.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9556 finished with score 2768.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 256.0, 16.0, 8.0], [32.0, 8.0, 128.0, 4.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9557 finished with score 1676.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2.  64.  16.   8.]\n",
      " [ 32. 128.  64.   4.]\n",
      " [  8.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 244, Loss : 0.43674376606941223\n",
      "Mini-Batch - 1 Back-Prop : 244, Loss : 0.4608588218688965\n",
      "Mini-Batch - 2 Back-Prop : 244, Loss : 0.40702325105667114\n",
      "Mini-Batch - 3 Back-Prop : 244, Loss : 0.42812639474868774\n",
      "Mini-Batch - 4 Back-Prop : 244, Loss : 0.41434189677238464\n",
      "Mini-Batch - 5 Back-Prop : 244, Loss : 0.5544952154159546\n",
      "Mini-Batch - 6 Back-Prop : 244, Loss : 0.5011763572692871\n",
      "Mini-Batch - 7 Back-Prop : 244, Loss : 0.41417640447616577\n",
      "Mini-Batch - 8 Back-Prop : 244, Loss : 0.38978952169418335\n",
      "Mini-Batch - 9 Back-Prop : 244, Loss : 0.33718621730804443\n",
      "Mini-Batch - 10 Back-Prop : 244, Loss : 0.3665979504585266\n",
      "Episode 9558 finished with score 3744.0, result : lose board : [[  4.  32.   2.   4.]\n",
      " [  8. 128.   4.   2.]\n",
      " [128. 256.  16.   8.]\n",
      " [  2.  64.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9559 finished with score 5448.0, result : lose board : [[64.0, 16.0, 4.0, 2.0], [512.0, 128.0, 2.0, 8.0], [2.0, 64.0, 8.0, 4.0], [4, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9560 finished with score 2056.0, result : lose board : [[4.0, 16.0, 4.0, 2], [2.0, 128.0, 8.0, 4.0], [4.0, 64.0, 32.0, 8.0], [128.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9561 finished with score 708.0, result : lose board : [[2.0, 4.0, 2.0, 4.0], [4.0, 16.0, 32.0, 2.0], [32.0, 64.0, 16.0, 4.0], [8.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9562 finished with score 2540.0, result : lose board : [[32.0, 2.0, 4.0, 2.0], [2.0, 16.0, 32.0, 8.0], [64.0, 256.0, 8.0, 4.0], [16.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9563 finished with score 5424.0, result : lose board : [[  8.  64.   4.   2.]\n",
      " [  2.  32.   8.   4.]\n",
      " [512. 128.   4.   8.]\n",
      " [ 32.   4.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9564 finished with score 1064.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  2.  32.  16.   4.]\n",
      " [128.  16.   4.   8.]\n",
      " [  8.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9565 finished with score 2452.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [2.0, 256.0, 64.0, 8.0], [4.0, 32.0, 16.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9566 finished with score 3476.0, result : lose board : [[32.0, 16.0, 8.0, 4.0], [2, 256.0, 64.0, 32.0], [4.0, 128.0, 8.0, 4.0], [64.0, 8.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9567 finished with score 3216.0, result : lose board : [[2.0, 8.0, 4.0, 2], [64.0, 32.0, 2.0, 8.0], [32.0, 128.0, 32.0, 2.0], [256.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9568 finished with score 2756.0, result : lose board : [[64.0, 16.0, 4.0, 2.0], [2.0, 4.0, 8.0, 4.0], [64.0, 16.0, 32.0, 256.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9569 finished with score 3512.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [ 16.  64. 256.   2.]\n",
      " [128.  32.  16.   4.]\n",
      " [  4.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9570 finished with score 2476.0, result : lose board : [[16.0, 8.0, 4.0, 2.0], [2, 4.0, 64.0, 8.0], [64.0, 8.0, 4.0, 2.0], [256.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9571 finished with score 1408.0, result : lose board : [[8.0, 64.0, 4.0, 2], [2.0, 8.0, 128.0, 4.0], [32.0, 2.0, 16.0, 2.0], [4.0, 32.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9572 finished with score 2728.0, result : lose board : [[8.0, 32.0, 8.0, 2], [64.0, 8.0, 2.0, 8.0], [256.0, 32.0, 16.0, 2.0], [2, 64.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9573 finished with score 2508.0, result : lose board : [[32.0, 4, 2, 4], [64.0, 32.0, 4.0, 8.0], [2.0, 256.0, 16.0, 2.0], [32.0, 8.0, 2.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9574 finished with score 2304.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [256.0, 8.0, 4.0, 8.0], [4.0, 64.0, 32.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9575 finished with score 2308.0, result : lose board : [[2.0, 8.0, 4, 2], [4.0, 64.0, 16.0, 4.0], [32.0, 256.0, 8.0, 2.0], [16.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9576 finished with score 1536.0, result : lose board : [[32.0, 16.0, 4.0, 2], [4.0, 32.0, 8.0, 4.0], [32.0, 128.0, 64.0, 2.0], [16.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9577 finished with score 1040.0, result : lose board : [[2.0, 8.0, 4.0, 2], [8.0, 64.0, 8.0, 4.0], [64.0, 4.0, 16.0, 64.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9578 finished with score 1596.0, result : lose board : [[ 16.   2.   8.   4.]\n",
      " [  4.  32.  64.   8.]\n",
      " [ 16. 128.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9579, Score : 6192.0, Iters : 400, Finish : not over\n",
      "Episode 9579 finished with score 6600.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [256. 512.  32.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9580 finished with score 5192.0, result : lose board : [[32.0, 4.0, 2.0, 4.0], [256.0, 128.0, 4.0, 2.0], [2, 8.0, 256.0, 8.0], [128.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9581 finished with score 3816.0, result : lose board : [[128.0, 32.0, 4.0, 2], [32.0, 64.0, 2.0, 4.0], [64.0, 256.0, 32.0, 2.0], [2.0, 64.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9582 finished with score 3408.0, result : lose board : [[32.0, 16.0, 8.0, 4.0], [4.0, 256.0, 16.0, 2.0], [2.0, 128.0, 64.0, 8.0], [64.0, 16.0, 8.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 245, Loss : 0.3646349310874939\n",
      "Mini-Batch - 1 Back-Prop : 245, Loss : 0.48633652925491333\n",
      "Mini-Batch - 2 Back-Prop : 245, Loss : 0.2825317978858948\n",
      "Mini-Batch - 3 Back-Prop : 245, Loss : 0.4498419761657715\n",
      "Mini-Batch - 4 Back-Prop : 245, Loss : 0.3316555619239807\n",
      "Mini-Batch - 5 Back-Prop : 245, Loss : 0.7776719331741333\n",
      "Mini-Batch - 6 Back-Prop : 245, Loss : 1.444047212600708\n",
      "Mini-Batch - 7 Back-Prop : 245, Loss : 1.2113425731658936\n",
      "Mini-Batch - 8 Back-Prop : 245, Loss : 0.4670564830303192\n",
      "Mini-Batch - 9 Back-Prop : 245, Loss : 0.6176103353500366\n",
      "Mini-Batch - 10 Back-Prop : 245, Loss : 0.5422955751419067\n",
      "Episode 9583 finished with score 4108.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [2, 256.0, 128.0, 32.0], [128.0, 64.0, 16.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9584 finished with score 4392.0, result : lose board : [[16.0, 8, 4, 2], [512.0, 32.0, 8.0, 4.0], [2.0, 4.0, 16.0, 2.0], [4.0, 2.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9585 finished with score 1756.0, result : lose board : [[  8.   4.  64.   2.]\n",
      " [  2.  16.  32.   4.]\n",
      " [ 32. 128.  16.   8.]\n",
      " [  4.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9586 finished with score 1592.0, result : lose board : [[  8.  16.   4.   2.]\n",
      " [ 32.  64.   8.   4.]\n",
      " [  4. 128.  32.  16.]\n",
      " [ 32.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9587 finished with score 1420.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 64.0, 128.0, 8.0], [16.0, 4.0, 32.0, 2.0], [2.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9588 finished with score 5488.0, result : lose board : [[2, 32.0, 16.0, 4.0], [512.0, 128.0, 8.0, 2.0], [4.0, 32.0, 16.0, 4.0], [64.0, 8.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9589 finished with score 2188.0, result : lose board : [[32.0, 8.0, 16.0, 2.0], [4.0, 128.0, 32.0, 4.0], [2.0, 64.0, 16.0, 8.0], [8.0, 128.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9590 finished with score 3136.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  4. 128.   4.   8.]\n",
      " [256.  64.  16.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9591 finished with score 4172.0, result : lose board : [[  2.  64.   8.   2.]\n",
      " [  8. 128. 256.  32.]\n",
      " [ 32.  64.   8.   4.]\n",
      " [  2. 128.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9592 finished with score 1232.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 16.0, 32.0, 16.0], [4.0, 32.0, 128.0, 4.0], [16.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9593 finished with score 4220.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [256.0, 4.0, 32.0, 4.0], [4.0, 256.0, 16.0, 8.0], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9594 finished with score 1692.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4.   8.  64.  32.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2.  16.   8.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9595 finished with score 3220.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [256.  64.   4.   8.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9596 finished with score 1732.0, result : lose board : [[4.0, 64.0, 4.0, 2], [8.0, 128.0, 8.0, 4.0], [2.0, 64.0, 32.0, 8.0], [32.0, 2.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9597 finished with score 2180.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [ 32.   4. 128.  16.]\n",
      " [  2. 128.  32.   8.]\n",
      " [ 64.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9598 finished with score 4096.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [  2. 256. 128.   8.]\n",
      " [ 64.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9599 finished with score 2856.0, result : lose board : [[2.0, 64.0, 16.0, 4.0], [256.0, 4.0, 8.0, 2.0], [64.0, 2.0, 64.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9600 finished with score 4012.0, result : lose board : [[  4.   8.  16.   2.]\n",
      " [  8. 256.   8.   4.]\n",
      " [  4.  64.  32.   2.]\n",
      " [256.   4.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9601, Score : 6032.0, Iters : 400, Finish : not over\n",
      "Episode 9601 finished with score 6244.0, result : lose board : [[2.0, 8.0, 2.0, 4.0], [16.0, 256.0, 8.0, 2.0], [2.0, 512.0, 16.0, 8.0], [64.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9602 finished with score 2788.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [ 32.  64.  16.   8.]\n",
      " [  4. 256.  32.   4.]\n",
      " [  8.  64.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9603 finished with score 576.0, result : lose board : [[2.0, 16.0, 4.0, 2], [32.0, 4.0, 8.0, 4.0], [4.0, 64.0, 16.0, 2.0], [16.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9604 finished with score 1632.0, result : lose board : [[  4.  64.  16.   4.]\n",
      " [  8. 128.  32.   8.]\n",
      " [  4.  16.  64.   4.]\n",
      " [  2.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9605 finished with score 1728.0, result : lose board : [[32.0, 4.0, 32.0, 4.0], [64.0, 128.0, 16.0, 2.0], [2.0, 64.0, 2.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9606 finished with score 1812.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [ 64.  32.  16.   2.]\n",
      " [ 32. 128.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9607 finished with score 2584.0, result : lose board : [[  8.  32.   8.   2.]\n",
      " [  2. 256.  16.   8.]\n",
      " [ 16.  64.  32.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 246, Loss : 0.41380345821380615\n",
      "Mini-Batch - 1 Back-Prop : 246, Loss : 0.33347633481025696\n",
      "Mini-Batch - 2 Back-Prop : 246, Loss : 0.4773067831993103\n",
      "Mini-Batch - 3 Back-Prop : 246, Loss : 0.6192266941070557\n",
      "Mini-Batch - 4 Back-Prop : 246, Loss : 0.28536003828048706\n",
      "Mini-Batch - 5 Back-Prop : 246, Loss : 0.37416350841522217\n",
      "Mini-Batch - 6 Back-Prop : 246, Loss : 0.6100291013717651\n",
      "Mini-Batch - 7 Back-Prop : 246, Loss : 0.613696813583374\n",
      "Mini-Batch - 8 Back-Prop : 246, Loss : 0.497885525226593\n",
      "Mini-Batch - 9 Back-Prop : 246, Loss : 0.47210413217544556\n",
      "Mini-Batch - 10 Back-Prop : 246, Loss : 0.8415655493736267\n",
      "Episode 9608 finished with score 1396.0, result : lose board : [[32.0, 8, 4, 2], [128.0, 32.0, 8.0, 4.0], [64.0, 2.0, 16.0, 2], [8.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9609 finished with score 2064.0, result : lose board : [[  2.   4.   8.   2.]\n",
      " [128.   8.  64.   4.]\n",
      " [ 32.  16.   4.   8.]\n",
      " [  8. 128.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9610 finished with score 1628.0, result : lose board : [[  2.  64.   8.   4.]\n",
      " [  4. 128.  16.   2.]\n",
      " [  8.  64.  32.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9611 finished with score 2280.0, result : lose board : [[ 64.   2.   8.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [128.  64.   2.  16.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9612 finished with score 640.0, result : lose board : [[16.0, 8.0, 4.0, 2], [8.0, 64.0, 2.0, 4.0], [2.0, 32.0, 4.0, 2.0], [4.0, 2.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9613 finished with score 4656.0, result : lose board : [[2.0, 16.0, 8.0, 2], [4.0, 2.0, 16.0, 8.0], [512.0, 4.0, 64.0, 4.0], [4.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9614 finished with score 3308.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [64.0, 128.0, 32.0, 8.0], [2.0, 256.0, 2.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9615 finished with score 5400.0, result : lose board : [[2.0, 16.0, 4.0, 2], [32.0, 512.0, 16.0, 4.0], [4.0, 128.0, 32.0, 8.0], [64.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9616 finished with score 1672.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [ 64. 128.   8.   4.]\n",
      " [ 16.  64.  16.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9617 finished with score 3348.0, result : lose board : [[  2.  64.  16.   2.]\n",
      " [  4. 128. 256.   4.]\n",
      " [ 32.   4.  64.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9618 finished with score 3004.0, result : lose board : [[  2.   4.  32.   2.]\n",
      " [256.  16.   4.   8.]\n",
      " [128.  32.  16.   4.]\n",
      " [ 32.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9619 finished with score 3340.0, result : lose board : [[  8.   4.  16.   2.]\n",
      " [ 64.  16.  64.   8.]\n",
      " [128.   4.  16.   4.]\n",
      " [  2. 256.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9620 finished with score 1636.0, result : lose board : [[32.0, 8.0, 16.0, 2.0], [64.0, 16.0, 8.0, 4.0], [128.0, 32.0, 16.0, 8.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9621 finished with score 1648.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 64.0, 8.0, 4.0], [4.0, 128.0, 32.0, 16.0], [64.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9622 finished with score 1132.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [ 32.   4.  16.   8.]\n",
      " [  4. 128.  32.   2.]\n",
      " [  2.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9623 finished with score 1424.0, result : lose board : [[2.0, 64.0, 8.0, 4.0], [32.0, 16.0, 32.0, 8.0], [4.0, 128.0, 2.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9624 finished with score 1704.0, result : lose board : [[32.0, 16.0, 8.0, 4], [64.0, 128.0, 32.0, 2.0], [2.0, 32.0, 16.0, 8.0], [32.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9625 finished with score 4812.0, result : lose board : [[2.0, 32.0, 8.0, 4.0], [4.0, 512.0, 16.0, 2.0], [64.0, 32.0, 8.0, 32.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9626 finished with score 2900.0, result : lose board : [[  4.   2.  16.   4.]\n",
      " [ 32.  16. 128.   2.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9627 finished with score 2408.0, result : lose board : [[  8.  32.   2.   4.]\n",
      " [  4.  64.   4.   2.]\n",
      " [ 16.   4.   8.  32.]\n",
      " [  4.  16. 256.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9628 finished with score 3024.0, result : lose board : [[4.0, 8.0, 2.0, 4], [8.0, 256.0, 64.0, 128.0], [2.0, 32.0, 4.0, 2.0], [8.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9629 finished with score 3928.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [128.  32.  16.   4.]\n",
      " [256. 128.  64.  32.]\n",
      " [  4.  16.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9630 finished with score 3420.0, result : lose board : [[16.0, 8, 4, 2], [64.0, 256.0, 64.0, 8.0], [4.0, 128.0, 16.0, 4.0], [32.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9631 finished with score 3336.0, result : lose board : [[64.0, 8.0, 4.0, 2], [256.0, 64.0, 16.0, 4.0], [128.0, 8.0, 4.0, 8.0], [2.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9632 finished with score 3312.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [4.0, 128.0, 16.0, 2.0], [256.0, 64.0, 32.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9633 finished with score 1696.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  8.  64.   8.   2.]\n",
      " [  4. 128.  32.   8.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 247, Loss : 0.6541971564292908\n",
      "Mini-Batch - 1 Back-Prop : 247, Loss : 0.32936766743659973\n",
      "Mini-Batch - 2 Back-Prop : 247, Loss : 0.4170779287815094\n",
      "Mini-Batch - 3 Back-Prop : 247, Loss : 0.3404276669025421\n",
      "Mini-Batch - 4 Back-Prop : 247, Loss : 0.4534866213798523\n",
      "Mini-Batch - 5 Back-Prop : 247, Loss : 0.4744013845920563\n",
      "Mini-Batch - 6 Back-Prop : 247, Loss : 0.47818487882614136\n",
      "Mini-Batch - 7 Back-Prop : 247, Loss : 0.7605009078979492\n",
      "Mini-Batch - 8 Back-Prop : 247, Loss : 0.334105521440506\n",
      "Mini-Batch - 9 Back-Prop : 247, Loss : 0.39625805616378784\n",
      "Mini-Batch - 10 Back-Prop : 247, Loss : 0.38061028718948364\n",
      "Episode 9634 finished with score 2704.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  2.  64. 256.   2.]\n",
      " [ 16.  32.  16.   8.]\n",
      " [  2.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9635 finished with score 3268.0, result : lose board : [[4.0, 128.0, 8.0, 2], [256.0, 64.0, 16.0, 8.0], [4.0, 16.0, 64.0, 16.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9636 finished with score 3064.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [  2. 256.   2.   8.]\n",
      " [  4.  64. 128.   4.]\n",
      " [ 16.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9637 finished with score 5560.0, result : lose board : [[4.0, 16.0, 8.0, 2], [32.0, 64.0, 16.0, 8.0], [128.0, 512.0, 32.0, 4.0], [2.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9638 finished with score 1132.0, result : lose board : [[2, 16.0, 2.0, 8.0], [4.0, 8.0, 32.0, 2.0], [32.0, 128.0, 16.0, 8.0], [4.0, 2.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9639 finished with score 2360.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [ 32. 256.  16.   4.]\n",
      " [  2.  16.  32.   8.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9640 finished with score 2908.0, result : lose board : [[ 64.   8.   4.   2.]\n",
      " [  2.  16. 256.   4.]\n",
      " [ 32.  64.  16.   8.]\n",
      " [  4.   8.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9641 finished with score 1416.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [8.0, 32.0, 16.0, 8.0], [2.0, 128.0, 32.0, 4.0], [4.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9642 finished with score 3928.0, result : lose board : [[64.0, 32.0, 2.0, 4.0], [256.0, 128.0, 4.0, 2.0], [128.0, 32.0, 16.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9643 finished with score 3192.0, result : lose board : [[16.0, 8.0, 4, 2], [256.0, 64.0, 32.0, 8.0], [2.0, 128.0, 16.0, 4.0], [32.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9644 finished with score 1392.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  2.  64.   4.   8.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [  8.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9645 finished with score 3032.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16. 128.  16.   4.]\n",
      " [ 32.   2.  64.   8.]\n",
      " [  4. 256.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9646 finished with score 3324.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [256. 128.  16.   8.]\n",
      " [ 16.  64.  32.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9647 finished with score 1336.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [  8. 128.  16.   2.]\n",
      " [  2.  16.   8.   4.]\n",
      " [ 64.   8.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9648 finished with score 3952.0, result : lose board : [[16.0, 8.0, 4.0, 2], [256.0, 128.0, 16.0, 8.0], [128.0, 64.0, 32.0, 4.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9649 finished with score 3144.0, result : lose board : [[16.0, 8.0, 4.0, 2], [32.0, 64.0, 32.0, 4.0], [128.0, 8.0, 256.0, 8.0], [4.0, 2.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9650 finished with score 2316.0, result : lose board : [[ 32.   2.  16.   2.]\n",
      " [  4. 256.  32.   4.]\n",
      " [ 32.   8.   2.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9651 finished with score 3344.0, result : lose board : [[  8.  64.   8.   4.]\n",
      " [128.  32.  16.   8.]\n",
      " [ 16. 256.  32.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9652 finished with score 2004.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4.  32. 128.   8.]\n",
      " [  8. 128.   8.   2.]\n",
      " [ 64.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9653 finished with score 2488.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [64.0, 256.0, 32.0, 16.0], [2.0, 16.0, 8.0, 4.0], [32.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9654 finished with score 2864.0, result : lose board : [[16.0, 4.0, 8.0, 2.0], [2.0, 128.0, 2.0, 8.0], [256.0, 32.0, 8.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9655 finished with score 3176.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [  8. 128.   8.  16.]\n",
      " [  2.   4.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9656 finished with score 4896.0, result : lose board : [[16.0, 8, 4, 2], [32.0, 512.0, 16.0, 8.0], [64.0, 8.0, 2.0, 4.0], [8.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9657 finished with score 1388.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [16.0, 32.0, 16.0, 4.0], [2.0, 64.0, 128.0, 8.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9658 finished with score 2704.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [  8.  32.   4.   8.]\n",
      " [ 16.  64. 256.   2.]\n",
      " [ 64.   2.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 248, Loss : 0.6764569878578186\n",
      "Mini-Batch - 1 Back-Prop : 248, Loss : 0.2857625484466553\n",
      "Mini-Batch - 2 Back-Prop : 248, Loss : 0.36274176836013794\n",
      "Mini-Batch - 3 Back-Prop : 248, Loss : 0.36333873867988586\n",
      "Mini-Batch - 4 Back-Prop : 248, Loss : 0.44982510805130005\n",
      "Mini-Batch - 5 Back-Prop : 248, Loss : 0.44839346408843994\n",
      "Mini-Batch - 6 Back-Prop : 248, Loss : 0.37111520767211914\n",
      "Mini-Batch - 7 Back-Prop : 248, Loss : 0.4368214011192322\n",
      "Mini-Batch - 8 Back-Prop : 248, Loss : 0.6328353881835938\n",
      "Mini-Batch - 9 Back-Prop : 248, Loss : 0.6207001805305481\n",
      "Mini-Batch - 10 Back-Prop : 248, Loss : 0.5249840617179871\n",
      "Episode 9659 finished with score 4368.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [128.  64.  16.   2.]\n",
      " [256. 128.  32.   4.]\n",
      " [ 64.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9660 finished with score 3216.0, result : lose board : [[2, 16.0, 4, 2], [64.0, 32.0, 8.0, 4.0], [128.0, 256.0, 16.0, 2.0], [2.0, 16.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9661 finished with score 3420.0, result : lose board : [[64.0, 8.0, 4.0, 2], [128.0, 4.0, 16.0, 4.0], [64.0, 256.0, 32.0, 2.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9662 finished with score 4144.0, result : lose board : [[  2.  64.  32.   4.]\n",
      " [  4. 256.   4.   8.]\n",
      " [256.   4.  16.   4.]\n",
      " [ 16.   2.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9663 finished with score 3484.0, result : lose board : [[32.0, 16.0, 4.0, 2], [64.0, 32.0, 16.0, 4.0], [128.0, 256.0, 32.0, 8.0], [8.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9664 finished with score 2324.0, result : lose board : [[  4.  32.  16.   4.]\n",
      " [ 16. 128.  32.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [  2.  32.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9665 finished with score 3244.0, result : lose board : [[2.0, 32.0, 4.0, 2], [256.0, 128.0, 16.0, 4.0], [2.0, 64.0, 32.0, 2.0], [32.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9666 finished with score 2784.0, result : lose board : [[4.0, 128.0, 8.0, 2.0], [2.0, 16.0, 32.0, 4.0], [16.0, 4.0, 2.0, 256.0], [4.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9667 finished with score 1456.0, result : lose board : [[4.0, 2.0, 8.0, 4.0], [128.0, 32.0, 16.0, 2.0], [64.0, 4.0, 32.0, 16.0], [2.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9668 finished with score 3284.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [256. 128.   4.   8.]\n",
      " [  2.  64.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9669 finished with score 1888.0, result : lose board : [[2.0, 64.0, 4.0, 2], [4.0, 128.0, 16.0, 4.0], [2.0, 64.0, 32.0, 8.0], [64.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9670 finished with score 1508.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [32.0, 128.0, 32.0, 2.0], [8.0, 64.0, 16.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9671 finished with score 3280.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [8.0, 128.0, 64.0, 16.0], [16.0, 256.0, 8.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9672 finished with score 3476.0, result : lose board : [[4.0, 16.0, 4.0, 2], [64.0, 128.0, 32.0, 8.0], [8.0, 256.0, 64.0, 4.0], [2.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9673 finished with score 3492.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [  4. 128.   8.  32.]\n",
      " [128.   8. 256.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9674 finished with score 4880.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [2.0, 32.0, 64.0, 4.0], [16.0, 512.0, 16.0, 8.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9675 finished with score 2500.0, result : lose board : [[2.0, 16.0, 4.0, 2], [64.0, 8.0, 2.0, 4.0], [2.0, 256.0, 16.0, 8.0], [64.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9676 finished with score 3784.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [128.  32. 256.   4.]\n",
      " [  2. 128.  16.   8.]\n",
      " [ 64.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9677 finished with score 2760.0, result : lose board : [[  2. 256.   2.   4.]\n",
      " [  4.  32.   8.   2.]\n",
      " [ 64.   2.  32.   4.]\n",
      " [ 32.   8.  64.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9678 finished with score 1608.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [2.0, 32.0, 4.0, 2], [128.0, 64.0, 32.0, 4.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9679 finished with score 3688.0, result : lose board : [[64.0, 8.0, 4, 2], [2.0, 128.0, 16.0, 4.0], [256.0, 32.0, 64.0, 8.0], [64.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9680, Score : 5668.0, Iters : 400, Finish : not over\n",
      "Episode 9680 finished with score 5696.0, result : lose board : [[64.0, 8.0, 4.0, 2], [512.0, 16.0, 128.0, 8.0], [2.0, 64.0, 16.0, 4.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9681 finished with score 3392.0, result : lose board : [[8.0, 16.0, 4.0, 2], [128.0, 64.0, 2.0, 8.0], [64.0, 256.0, 16.0, 4.0], [16.0, 4.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 249, Loss : 0.539236843585968\n",
      "Mini-Batch - 1 Back-Prop : 249, Loss : 0.44002074003219604\n",
      "Mini-Batch - 2 Back-Prop : 249, Loss : 0.49038049578666687\n",
      "Mini-Batch - 3 Back-Prop : 249, Loss : 0.41715008020401\n",
      "Mini-Batch - 4 Back-Prop : 249, Loss : 0.3539406955242157\n",
      "Mini-Batch - 5 Back-Prop : 249, Loss : 0.5074692964553833\n",
      "Mini-Batch - 6 Back-Prop : 249, Loss : 0.33952245116233826\n",
      "Mini-Batch - 7 Back-Prop : 249, Loss : 0.5100385546684265\n",
      "Mini-Batch - 8 Back-Prop : 249, Loss : 0.5107302665710449\n",
      "Mini-Batch - 9 Back-Prop : 249, Loss : 0.31817692518234253\n",
      "Mini-Batch - 10 Back-Prop : 249, Loss : 0.44776567816734314\n",
      "Episode 9682 finished with score 2576.0, result : lose board : [[  4.  16.   2.   4.]\n",
      " [ 64.  32.   4.   8.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 32.  16.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9683 finished with score 3504.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [ 64.   2.  16.   4.]\n",
      " [256. 128.  32.   8.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9684 finished with score 3296.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [  2. 256.  32.   4.]\n",
      " [ 32. 128.  64.  16.]\n",
      " [  8.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9685 finished with score 3292.0, result : lose board : [[8.0, 4.0, 32.0, 2.0], [64.0, 256.0, 8.0, 4.0], [2.0, 64.0, 2.0, 8.0], [128.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9686 finished with score 3116.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 16. 128.   8.   4.]\n",
      " [256.  64.  32.   8.]\n",
      " [  8.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9687 finished with score 3916.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [ 16.   2. 256.   2.]\n",
      " [256.   8.  16.   4.]\n",
      " [ 16.   4.   2.  32.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9688 finished with score 2588.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [4.0, 2.0, 256.0, 16.0], [8.0, 64.0, 32.0, 8.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9689 finished with score 3036.0, result : lose board : [[ 16.   2.   8.   2.]\n",
      " [128.   4.  16.   4.]\n",
      " [  2. 256.  64.   2.]\n",
      " [ 16.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9690 finished with score 3248.0, result : lose board : [[16.0, 2, 4, 2], [4.0, 64.0, 16.0, 4.0], [64.0, 256.0, 8.0, 2.0], [4.0, 128.0, 2.0, 16.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9691 finished with score 2940.0, result : lose board : [[  8.  32.   8.   2.]\n",
      " [ 32. 128.  16.   4.]\n",
      " [ 16.   8. 256.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9692 finished with score 3680.0, result : lose board : [[ 64.   2.  16.   2.]\n",
      " [  2.  16.  64.   4.]\n",
      " [256. 128.  32.   8.]\n",
      " [  8.  64.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9693 finished with score 5496.0, result : lose board : [[16.0, 4.0, 2.0, 32.0], [2.0, 32.0, 512.0, 2.0], [128.0, 64.0, 8.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9694 finished with score 2228.0, result : lose board : [[32.0, 16.0, 4.0, 2.0], [2.0, 128.0, 16.0, 4.0], [64.0, 32.0, 128.0, 16.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9695 finished with score 3412.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [4.0, 8.0, 128.0, 4.0], [64.0, 256.0, 64.0, 8.0], [2.0, 32.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9696 finished with score 5492.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  8.  32. 128.  16.]\n",
      " [512.  64.  32.   8.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9697 finished with score 2828.0, result : lose board : [[2.0, 8.0, 4.0, 2], [4.0, 16.0, 256.0, 4.0], [32.0, 8.0, 32.0, 8.0], [4.0, 128.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9698 finished with score 1504.0, result : lose board : [[16.0, 8.0, 2.0, 4.0], [64.0, 32.0, 4.0, 2], [2.0, 128.0, 32.0, 4.0], [8.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9699 finished with score 2492.0, result : lose board : [[  8. 256.   2.   4.]\n",
      " [  2.  32.   8.   2.]\n",
      " [  8.  64.  32.   4.]\n",
      " [ 16.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9700 finished with score 1308.0, result : lose board : [[8.0, 2.0, 4, 2], [2.0, 4.0, 16.0, 128.0], [8.0, 32.0, 8.0, 4.0], [64.0, 8.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9701 finished with score 3584.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [128.  16.   8.   4.]\n",
      " [ 32. 128. 256.   8.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9702 finished with score 3912.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 32.0, 16.0, 8.0], [128.0, 64.0, 256.0, 2.0], [2.0, 128.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9703 finished with score 1340.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  8.  64.   8.   4.]\n",
      " [ 16. 128.  16.   8.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9704 finished with score 1440.0, result : lose board : [[8.0, 16.0, 4.0, 2.0], [2.0, 64.0, 128.0, 8.0], [32.0, 16.0, 2.0, 4.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 250, Loss : 0.32087185978889465\n",
      "Mini-Batch - 1 Back-Prop : 250, Loss : 0.603806734085083\n",
      "Mini-Batch - 2 Back-Prop : 250, Loss : 0.5302466154098511\n",
      "Mini-Batch - 3 Back-Prop : 250, Loss : 0.46425947546958923\n",
      "Mini-Batch - 4 Back-Prop : 250, Loss : 0.8029959201812744\n",
      "Mini-Batch - 5 Back-Prop : 250, Loss : 0.5556358098983765\n",
      "Mini-Batch - 6 Back-Prop : 250, Loss : 0.6558794975280762\n",
      "Mini-Batch - 7 Back-Prop : 250, Loss : 0.9017319679260254\n",
      "Mini-Batch - 8 Back-Prop : 250, Loss : 0.6860055923461914\n",
      "Mini-Batch - 9 Back-Prop : 250, Loss : 0.6029637455940247\n",
      "Mini-Batch - 10 Back-Prop : 250, Loss : 0.5751023888587952\n",
      "Episode : 9705, Score : 6068.0, Iters : 400, Finish : not over\n",
      "Episode 9705 finished with score 6384.0, result : lose board : [[16.0, 8.0, 4, 2], [4.0, 512.0, 16.0, 4.0], [2.0, 64.0, 256.0, 8.0], [8.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9706 finished with score 2716, result : lose board : [[  2  16   8   4]\n",
      " [  4 256  32   2]\n",
      " [ 32  64  16   8]\n",
      " [  4   2  64   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9707 finished with score 1588.0, result : lose board : [[16.0, 8.0, 2.0, 4], [8.0, 32.0, 64.0, 8.0], [16.0, 4.0, 128.0, 32.0], [4.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9708 finished with score 4952.0, result : lose board : [[  8. 128.  32.   2.]\n",
      " [256.  32.  64.   4.]\n",
      " [  8.   4.  16.   8.]\n",
      " [256.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9709 finished with score 1412.0, result : lose board : [[32.0, 2, 4, 2], [4.0, 64.0, 16.0, 8.0], [16.0, 2.0, 32.0, 4.0], [2.0, 128.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9710, Score : 6080.0, Iters : 400, Finish : not over\n",
      "Episode 9710 finished with score 6088.0, result : lose board : [[8.0, 2.0, 8.0, 2.0], [4.0, 8.0, 32.0, 4.0], [512.0, 256.0, 16.0, 8.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9711 finished with score 3484.0, result : lose board : [[ 32.   4.  64.   4.]\n",
      " [  2. 256.   8.   2.]\n",
      " [ 16. 128.  16.   4.]\n",
      " [ 32.  64.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9712, Score : 6068.0, Iters : 400, Finish : not over\n",
      "Episode 9712 finished with score 6536.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [ 16. 256.  16.   8.]\n",
      " [512.  64.  32.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9713 finished with score 3440.0, result : lose board : [[2.0, 8.0, 4.0, 2], [64.0, 128.0, 16.0, 8.0], [256.0, 64.0, 32.0, 4.0], [16.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9714 finished with score 2184.0, result : lose board : [[8.0, 128.0, 4.0, 2], [16.0, 64.0, 32.0, 8.0], [8.0, 16.0, 128.0, 2.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9715 finished with score 648.0, result : lose board : [[ 2. 16.  4.  2.]\n",
      " [ 4. 64.  8.  4.]\n",
      " [16. 32. 16.  2.]\n",
      " [ 2. 16.  8.  4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9716 finished with score 1420.0, result : lose board : [[ 16.   4.  16.   2.]\n",
      " [  2. 128.   8.   4.]\n",
      " [  4.  64.  32.   2.]\n",
      " [ 32.   8.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9717 finished with score 3284.0, result : lose board : [[  8.  32.   2.   4.]\n",
      " [ 32. 128.  16.   2.]\n",
      " [  4.  64. 256.   8.]\n",
      " [ 32.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9718 finished with score 1688.0, result : lose board : [[16.0, 64.0, 4.0, 2], [4.0, 128.0, 16.0, 8.0], [2.0, 16.0, 32.0, 2.0], [4.0, 64.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9719 finished with score 2788.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [8.0, 128.0, 16.0, 2], [4.0, 256.0, 32.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9720 finished with score 2528.0, result : lose board : [[4.0, 8.0, 4.0, 2], [32.0, 16.0, 32.0, 4.0], [4.0, 256.0, 4.0, 2.0], [64.0, 32.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9721 finished with score 3136.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [256.0, 64.0, 8.0, 4.0], [4.0, 128.0, 16.0, 8.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9722 finished with score 3240.0, result : lose board : [[  8.  16.   8.   2.]\n",
      " [128. 256.  32.   4.]\n",
      " [ 64.  16.   4.   8.]\n",
      " [  4.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9723 finished with score 3920.0, result : lose board : [[2.0, 128.0, 8.0, 4.0], [64.0, 8.0, 32.0, 2.0], [128.0, 256.0, 16.0, 8.0], [8.0, 32.0, 8.0, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9724 finished with score 2064.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [  2. 128.  64.   8.]\n",
      " [ 16.   8.  32.   4.]\n",
      " [128.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9725, Score : 5756.0, Iters : 400, Finish : not over\n",
      "Episode 9725 finished with score 5988.0, result : lose board : [[  2.  64.  16.   2.]\n",
      " [  4. 512.  32.   8.]\n",
      " [ 64. 128.  64.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9726 finished with score 2716.0, result : lose board : [[2.0, 256.0, 64.0, 4.0], [8.0, 64.0, 8.0, 32.0], [16.0, 4.0, 32.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9727 finished with score 3616.0, result : lose board : [[128.0, 8.0, 4.0, 2], [2, 256.0, 32.0, 8.0], [16.0, 128.0, 8.0, 2.0], [4.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 251, Loss : 0.33119529485702515\n",
      "Mini-Batch - 1 Back-Prop : 251, Loss : 0.43600714206695557\n",
      "Mini-Batch - 2 Back-Prop : 251, Loss : 0.3754858374595642\n",
      "Mini-Batch - 3 Back-Prop : 251, Loss : 0.695221483707428\n",
      "Mini-Batch - 4 Back-Prop : 251, Loss : 0.40646952390670776\n",
      "Mini-Batch - 5 Back-Prop : 251, Loss : 0.49254441261291504\n",
      "Mini-Batch - 6 Back-Prop : 251, Loss : 0.552210807800293\n",
      "Mini-Batch - 7 Back-Prop : 251, Loss : 0.4869726300239563\n",
      "Mini-Batch - 8 Back-Prop : 251, Loss : 0.7214928269386292\n",
      "Mini-Batch - 9 Back-Prop : 251, Loss : 0.6641983985900879\n",
      "Mini-Batch - 10 Back-Prop : 251, Loss : 0.8245744705200195\n",
      "Episode 9728 finished with score 2724, result : lose board : [[  4  64   8   4]\n",
      " [ 32   2  32   8]\n",
      " [256  64  16   4]\n",
      " [  2  16   8   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9729 finished with score 2600.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [ 32.  64.  16.   4.]\n",
      " [  4. 256.  32.   8.]\n",
      " [ 16.   8.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9730, Score : 5692.0, Iters : 400, Finish : not over\n",
      "Episode 9730 finished with score 5728.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [2.0, 128.0, 512.0, 4.0], [4.0, 64.0, 32.0, 16.0], [64.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9731 finished with score 3156.0, result : lose board : [[  2.  32.   2.   4.]\n",
      " [ 64. 256.   4.   2.]\n",
      " [ 16. 128.   2.   8.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9732 finished with score 5444.0, result : lose board : [[32.0, 8.0, 4.0, 2], [512.0, 16.0, 32.0, 8.0], [8.0, 64.0, 16.0, 2.0], [4.0, 128.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9733 finished with score 2048.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 128.0, 8.0, 4.0], [64.0, 8.0, 16.0, 2.0], [128.0, 2.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9734 finished with score 2764.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 64. 256.  32.   4.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9735 finished with score 1204.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [  8.  32.  16.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9736 finished with score 4396.0, result : lose board : [[2.0, 8.0, 4.0, 8.0], [16.0, 32.0, 2.0, 4.0], [2.0, 16.0, 512.0, 32.0], [4.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9737 finished with score 3200.0, result : lose board : [[32.0, 8.0, 2.0, 4.0], [4.0, 64.0, 4.0, 16.0], [2.0, 128.0, 256.0, 8.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9738 finished with score 1120.0, result : lose board : [[2.0, 8.0, 4.0, 2.0], [8.0, 32.0, 16.0, 4.0], [16.0, 4.0, 8.0, 128.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9739 finished with score 3892.0, result : lose board : [[64.0, 16.0, 8.0, 4.0], [2.0, 128.0, 32.0, 8.0], [128.0, 256.0, 8.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9740 finished with score 712.0, result : lose board : [[4.0, 16.0, 8.0, 2], [64.0, 32.0, 16.0, 4.0], [32.0, 8.0, 4.0, 2.0], [4.0, 2.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9741 finished with score 2192.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [2.0, 128.0, 8.0, 2.0], [128.0, 64.0, 16.0, 8.0], [32.0, 8.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9742 finished with score 3036.0, result : lose board : [[4.0, 16.0, 4, 2], [2.0, 4.0, 16.0, 32.0], [128.0, 8.0, 64.0, 4.0], [2.0, 256.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9743 finished with score 1396.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [  8.  16.  64.   8.]\n",
      " [  4.   2.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9744 finished with score 1996.0, result : lose board : [[16.0, 8.0, 2.0, 8.0], [128.0, 16.0, 4.0, 2.0], [8.0, 128.0, 16.0, 4.0], [2, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9745 finished with score 3244.0, result : lose board : [[4.0, 2.0, 8.0, 2.0], [128.0, 16.0, 64.0, 4.0], [4.0, 256.0, 16.0, 8.0], [8.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9746 finished with score 5092.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [64.0, 32.0, 4.0, 2.0], [2, 512.0, 64.0, 32.0], [32.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9747 finished with score 2368.0, result : lose board : [[16.0, 8.0, 2.0, 8.0], [256.0, 64.0, 8.0, 2.0], [2.0, 16.0, 32.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9748 finished with score 2472.0, result : lose board : [[4.0, 16.0, 4.0, 2], [256.0, 64.0, 16.0, 8.0], [4.0, 16.0, 32.0, 4.0], [32.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9749 finished with score 4932.0, result : lose board : [[  8.  32.   2.   4.]\n",
      " [256. 128.   4.   8.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [256.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9750 finished with score 2488.0, result : lose board : [[4.0, 64.0, 4.0, 2], [128.0, 16.0, 32.0, 8.0], [32.0, 64.0, 8.0, 4.0], [2, 128.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9751 finished with score 2420.0, result : lose board : [[2.0, 4.0, 32.0, 8.0], [8.0, 64.0, 8.0, 4.0], [256.0, 32.0, 16.0, 2.0], [2, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9752 finished with score 2276.0, result : lose board : [[4.0, 8.0, 2.0, 4.0], [8.0, 2.0, 16.0, 2.0], [32.0, 64.0, 256.0, 4.0], [4.0, 2.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 252, Loss : 0.44820770621299744\n",
      "Mini-Batch - 1 Back-Prop : 252, Loss : 0.3614733815193176\n",
      "Mini-Batch - 2 Back-Prop : 252, Loss : 0.4114076495170593\n",
      "Mini-Batch - 3 Back-Prop : 252, Loss : 0.5751398205757141\n",
      "Mini-Batch - 4 Back-Prop : 252, Loss : 0.8188503980636597\n",
      "Mini-Batch - 5 Back-Prop : 252, Loss : 0.5557581186294556\n",
      "Mini-Batch - 6 Back-Prop : 252, Loss : 0.8772672414779663\n",
      "Mini-Batch - 7 Back-Prop : 252, Loss : 0.9744343757629395\n",
      "Mini-Batch - 8 Back-Prop : 252, Loss : 0.8748478889465332\n",
      "Mini-Batch - 9 Back-Prop : 252, Loss : 0.6236447095870972\n",
      "Mini-Batch - 10 Back-Prop : 252, Loss : 0.8432978391647339\n",
      "Episode 9753 finished with score 2660.0, result : lose board : [[2.0, 16.0, 4.0, 2], [64.0, 32.0, 8.0, 4.0], [256.0, 64.0, 16.0, 8.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9754 finished with score 1216.0, result : lose board : [[ 16   2   8   2]\n",
      " [128  16  32   4]\n",
      " [  8   2  16   2]\n",
      " [  4  32   4  16]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9755 finished with score 2484.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  4. 256.   8.  32.]\n",
      " [ 64.   8.  16.   4.]\n",
      " [  8.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9756 finished with score 1356.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [16.0, 8.0, 2.0, 4.0], [128.0, 32.0, 16.0, 2], [64.0, 8.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9757 finished with score 1588.0, result : lose board : [[2.0, 8.0, 4, 2], [32.0, 64.0, 16.0, 32.0], [128.0, 32.0, 8.0, 4.0], [16.0, 2.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9758 finished with score 1220.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  4. 128.   8.   2.]\n",
      " [ 32.   8.  16.   4.]\n",
      " [  2.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9759 finished with score 3216.0, result : lose board : [[  4. 128.   8.   4.]\n",
      " [ 16. 256.  16.   8.]\n",
      " [  4.  32.  64.  32.]\n",
      " [  8.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9760 finished with score 1540.0, result : lose board : [[2.0, 4.0, 16.0, 2.0], [4.0, 128.0, 32.0, 4.0], [32.0, 64.0, 16.0, 8.0], [4.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9761 finished with score 1812.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [128.0, 32.0, 16.0, 2], [2.0, 64.0, 32.0, 4.0], [64.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9762 finished with score 2060.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  4. 256.  16.   8.]\n",
      " [  8.  32.   4.   2.]\n",
      " [ 16.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9763 finished with score 1372.0, result : lose board : [[4.0, 16.0, 2.0, 4.0], [16.0, 32.0, 16.0, 2.0], [4.0, 128.0, 8.0, 4.0], [16.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9764, Score : 6068.0, Iters : 400, Finish : not over\n",
      "Episode 9764 finished with score 6412.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [512.  64. 256.   8.]\n",
      " [ 32.   4.  16.   4.]\n",
      " [  4.   2.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9765 finished with score 1604.0, result : lose board : [[2.0, 4.0, 32.0, 4.0], [16.0, 64.0, 16.0, 2], [8.0, 128.0, 2.0, 4.0], [2.0, 4.0, 64.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9766 finished with score 2656.0, result : lose board : [[8.0, 16.0, 4.0, 2], [16.0, 2.0, 64.0, 4.0], [4.0, 256.0, 32.0, 8.0], [64.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9767 finished with score 1408.0, result : lose board : [[  4.  32.   4.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [  8. 128.   8.  16.]\n",
      " [  4.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9768 finished with score 2812.0, result : lose board : [[64.0, 32.0, 2.0, 4.0], [4.0, 16.0, 64.0, 16.0], [32.0, 256.0, 8.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9769 finished with score 1436, result : lose board : [[  4  16   8   2]\n",
      " [ 64   8   2   8]\n",
      " [  8 128  32   4]\n",
      " [  2  32   8   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9770 finished with score 2716.0, result : lose board : [[16.0, 2.0, 8.0, 2.0], [32.0, 8.0, 32.0, 8.0], [8.0, 256.0, 64.0, 4.0], [64.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9771 finished with score 3244.0, result : lose board : [[32.0, 8.0, 4, 2], [128.0, 32.0, 8.0, 4.0], [256.0, 64.0, 4.0, 2.0], [32.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9772 finished with score 1516.0, result : lose board : [[2.0, 32.0, 2.0, 4.0], [128.0, 8.0, 4, 2], [16.0, 64.0, 32.0, 8.0], [4.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9773 finished with score 624.0, result : lose board : [[2.0, 8.0, 4.0, 2], [16.0, 32.0, 8.0, 4.0], [2.0, 64.0, 16.0, 2.0], [16.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9774 finished with score 3208.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [128.0, 16.0, 32.0, 4.0], [8.0, 64.0, 16.0, 8.0], [256.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9775 finished with score 2472.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  8.  32.  16.   2.]\n",
      " [ 32. 256.  64.   8.]\n",
      " [ 16.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9776 finished with score 2432.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [128.  64.   8.   4.]\n",
      " [  8. 128.  16.   8.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9777 finished with score 3036.0, result : lose board : [[4.0, 32.0, 4.0, 2], [64.0, 16.0, 2.0, 4.0], [2.0, 256.0, 8.0, 2.0], [16.0, 2.0, 128.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9778 finished with score 3028.0, result : lose board : [[16.0, 4.0, 8.0, 2.0], [8.0, 64.0, 16.0, 4.0], [128.0, 256.0, 4.0, 8.0], [4, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9779 finished with score 1284.0, result : lose board : [[  4.   2.  16.   2.]\n",
      " [  2. 128.  32.   4.]\n",
      " [  8.  64.  16.   2.]\n",
      " [  2.   4.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9780 finished with score 1588.0, result : lose board : [[64.0, 8.0, 4.0, 2], [2.0, 128.0, 16.0, 8.0], [64.0, 4.0, 32.0, 4.0], [2.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9781 finished with score 3128.0, result : lose board : [[4.0, 32.0, 4.0, 2], [256.0, 4.0, 128.0, 4.0], [4.0, 64.0, 16.0, 8.0], [2.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9782 finished with score 1840.0, result : lose board : [[64.0, 16.0, 2.0, 4.0], [2.0, 128.0, 16.0, 2.0], [4.0, 64.0, 8.0, 4.0], [64.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9783 finished with score 972.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [64.0, 16.0, 8.0, 2], [2.0, 32.0, 2.0, 4.0], [32.0, 64.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 253, Loss : 0.41522806882858276\n",
      "Mini-Batch - 1 Back-Prop : 253, Loss : 0.37431058287620544\n",
      "Mini-Batch - 2 Back-Prop : 253, Loss : 0.5838209986686707\n",
      "Mini-Batch - 3 Back-Prop : 253, Loss : 0.5704413652420044\n",
      "Mini-Batch - 4 Back-Prop : 253, Loss : 0.7575406432151794\n",
      "Mini-Batch - 5 Back-Prop : 253, Loss : 0.46397310495376587\n",
      "Mini-Batch - 6 Back-Prop : 253, Loss : 0.5326970815658569\n",
      "Mini-Batch - 7 Back-Prop : 253, Loss : 0.5997852087020874\n",
      "Mini-Batch - 8 Back-Prop : 253, Loss : 0.7216339111328125\n",
      "Mini-Batch - 9 Back-Prop : 253, Loss : 0.7044005393981934\n",
      "Mini-Batch - 10 Back-Prop : 253, Loss : 0.4273824393749237\n",
      "Episode 9784 finished with score 1484.0, result : lose board : [[2.0, 8.0, 4.0, 2], [32.0, 128.0, 8.0, 4.0], [2.0, 64.0, 32.0, 8.0], [32.0, 2.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9785 finished with score 3260.0, result : lose board : [[2, 32.0, 16.0, 8.0], [256.0, 64.0, 32.0, 2.0], [4.0, 128.0, 2.0, 4], [32.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9786 finished with score 3096.0, result : lose board : [[2.0, 16.0, 8.0, 2], [4.0, 32.0, 64.0, 4.0], [2.0, 256.0, 16.0, 2.0], [16.0, 128.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9787 finished with score 276.0, result : lose board : [[2, 4.0, 16.0, 4.0], [16.0, 32.0, 4.0, 2], [4.0, 16.0, 2.0, 4.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9788 finished with score 2880.0, result : lose board : [[2.0, 32.0, 2.0, 4.0], [64.0, 16.0, 64.0, 2.0], [2.0, 256.0, 16.0, 4.0], [64.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9789 finished with score 1472.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  8.  64. 128.   8.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  8.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9790, Score : 5912.0, Iters : 400, Finish : not over\n",
      "Episode 9790 finished with score 5996.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 128.0, 8.0, 4.0], [64.0, 512.0, 32.0, 8.0], [8.0, 2.0, 128.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9791 finished with score 1540.0, result : lose board : [[2.0, 32.0, 16.0, 2.0], [128.0, 64.0, 8.0, 4.0], [2.0, 32.0, 16.0, 8.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9792 finished with score 1836.0, result : lose board : [[4.0, 32.0, 64.0, 4.0], [32.0, 2.0, 32.0, 2.0], [2.0, 64.0, 8.0, 16.0], [16.0, 128.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9793 finished with score 1424.0, result : lose board : [[  2.   4.   2.   8.]\n",
      " [ 16.   2.   8.   4.]\n",
      " [ 64. 128.  32.   2.]\n",
      " [  4.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9794 finished with score 3244.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [128.0, 4.0, 16.0, 4.0], [256.0, 64.0, 32.0, 16.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9795 finished with score 1572.0, result : lose board : [[  4.   2.  16.   4.]\n",
      " [128.   4.  64.  16.]\n",
      " [  4.  64.  16.   4.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9796 finished with score 1644.0, result : lose board : [[16.0, 4.0, 64.0, 8.0], [128.0, 16.0, 4.0, 2.0], [2.0, 32.0, 2.0, 4.0], [64.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9797 finished with score 3088.0, result : lose board : [[4.0, 16.0, 4.0, 2.0], [64.0, 256.0, 8.0, 4.0], [8.0, 128.0, 32.0, 8.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9798 finished with score 5596.0, result : lose board : [[ 16.   4.  16.   4.]\n",
      " [ 32. 512.  32.   8.]\n",
      " [  8. 128.  16.   4.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9799 finished with score 5784.0, result : lose board : [[  2.   8.   2.   4.]\n",
      " [128. 512.   4.   2.]\n",
      " [  2. 128.  32.   8.]\n",
      " [ 16.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9800 finished with score 3064.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  8.  32.  16.   8.]\n",
      " [  4. 256. 128.   4.]\n",
      " [ 16.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9801 finished with score 2768.0, result : lose board : [[16.0, 8.0, 4.0, 2], [256.0, 32.0, 2.0, 8.0], [2.0, 128.0, 4.0, 2.0], [16.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9802 finished with score 2308.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [  8. 256.   8.   4.]\n",
      " [  2.  64.  32.   2.]\n",
      " [ 16.   8.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9803 finished with score 3236.0, result : lose board : [[  4.  32.  16.   4.]\n",
      " [  2.  64.   8.   2.]\n",
      " [  8. 256.  16.   4.]\n",
      " [ 32.  16. 128.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9804 finished with score 4268.0, result : lose board : [[  2.  64.   4.   2.]\n",
      " [  4. 128.  16.   4.]\n",
      " [128. 256.  64.   8.]\n",
      " [  2.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9805 finished with score 2012.0, result : lose board : [[64.0, 8.0, 2, 4], [4.0, 64.0, 16.0, 8.0], [64.0, 128.0, 32.0, 4.0], [2.0, 32.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9806 finished with score 1636.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [ 64. 128.  64.   2.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [  2.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9807 finished with score 3364.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [ 16. 256.  16.   8.]\n",
      " [  2. 128.  32.   4.]\n",
      " [ 64.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9808 finished with score 1128.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [  2.  16.   4.   2.]\n",
      " [  4.   2.  32.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9809 finished with score 3128.0, result : lose board : [[64.0, 16.0, 8.0, 2], [256.0, 32.0, 4.0, 8.0], [2.0, 128.0, 16.0, 4.0], [16.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 254, Loss : 0.4199807643890381\n",
      "Mini-Batch - 1 Back-Prop : 254, Loss : 0.3649035692214966\n",
      "Mini-Batch - 2 Back-Prop : 254, Loss : 0.3633166551589966\n",
      "Mini-Batch - 3 Back-Prop : 254, Loss : 0.35857248306274414\n",
      "Mini-Batch - 4 Back-Prop : 254, Loss : 0.5215451121330261\n",
      "Mini-Batch - 5 Back-Prop : 254, Loss : 0.3196379840373993\n",
      "Mini-Batch - 6 Back-Prop : 254, Loss : 0.36390918493270874\n",
      "Mini-Batch - 7 Back-Prop : 254, Loss : 0.4027252793312073\n",
      "Mini-Batch - 8 Back-Prop : 254, Loss : 0.487862765789032\n",
      "Mini-Batch - 9 Back-Prop : 254, Loss : 0.5523470640182495\n",
      "Mini-Batch - 10 Back-Prop : 254, Loss : 0.8842048645019531\n",
      "Episode 9810 finished with score 1700.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  8.  64.   8.   4.]\n",
      " [ 32. 128.  64.   2.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9811, Score : 6212.0, Iters : 400, Finish : not over\n",
      "Episode 9811 finished with score 8104.0, result : lose board : [[  2.   4.  32.   2.]\n",
      " [512. 256.  16.   8.]\n",
      " [256.  64.   8.   4.]\n",
      " [  2.  32.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9812 finished with score 3132.0, result : lose board : [[32.0, 16.0, 4.0, 2], [4.0, 64.0, 8.0, 4.0], [128.0, 256.0, 16.0, 2.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9813 finished with score 3408.0, result : lose board : [[  8.   4.   8.   4.]\n",
      " [ 64. 256.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9814 finished with score 2672.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [  4.  64.  32.   4.]\n",
      " [  2. 256.  64.   2.]\n",
      " [  4.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9815 finished with score 2732.0, result : lose board : [[2, 32.0, 16.0, 8.0], [4.0, 256.0, 64.0, 2.0], [64.0, 32.0, 4.0, 8.0], [4.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9816 finished with score 3192.0, result : lose board : [[2.0, 8.0, 4, 2], [8.0, 64.0, 32.0, 8.0], [2.0, 128.0, 256.0, 2.0], [16.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9817 finished with score 792.0, result : lose board : [[ 2. 16.  8.  2.]\n",
      " [ 8. 32. 16.  4.]\n",
      " [16. 64. 32.  8.]\n",
      " [ 2. 16.  4.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9818 finished with score 5472.0, result : lose board : [[2.0, 8.0, 128.0, 2.0], [16.0, 512.0, 16.0, 8.0], [8.0, 64.0, 32.0, 4.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9819 finished with score 3140.0, result : lose board : [[8.0, 32.0, 4.0, 2], [4.0, 64.0, 8.0, 4.0], [32.0, 256.0, 16.0, 2.0], [2.0, 128.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9820 finished with score 632.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 16.0, 8.0, 4.0], [8.0, 64.0, 32.0, 2.0], [2.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9821 finished with score 988.0, result : lose board : [[ 8.  4. 16.  4.]\n",
      " [32. 64. 32.  2.]\n",
      " [ 2. 16.  8.  4.]\n",
      " [64.  2.  4.  8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9822 finished with score 2140.0, result : lose board : [[2.0, 64.0, 4.0, 2.0], [128.0, 16.0, 32.0, 8.0], [32.0, 128.0, 8.0, 4.0], [2, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9823 finished with score 1348.0, result : lose board : [[  8.   4.  16.   4.]\n",
      " [  4.   8.   4.   8.]\n",
      " [ 32.  64. 128.  16.]\n",
      " [  4.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9824 finished with score 1320.0, result : lose board : [[16.0, 4.0, 8.0, 4.0], [128.0, 8.0, 16.0, 8.0], [64.0, 32.0, 2.0, 4.0], [2.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9825 finished with score 3200.0, result : lose board : [[4, 16.0, 4, 2], [8.0, 256.0, 32.0, 4.0], [64.0, 128.0, 16.0, 2.0], [16.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9826 finished with score 1352.0, result : lose board : [[ 16.   2.   8.   4.]\n",
      " [128.  16.   4.   8.]\n",
      " [  2.  64.  16.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9827 finished with score 4824.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [ 32. 512.  32.   8.]\n",
      " [  4.  64.  16.   4.]\n",
      " [ 32.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9828 finished with score 3124.0, result : lose board : [[4.0, 32.0, 8.0, 2], [128.0, 256.0, 16.0, 4.0], [4.0, 64.0, 2.0, 8.0], [32.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9829 finished with score 2788.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [256.  64.   4.   8.]\n",
      " [  2.   4.  64.   4.]\n",
      " [ 16.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9830 finished with score 1864.0, result : lose board : [[  4.  32.   2.   4.]\n",
      " [ 16. 128.   4.   8.]\n",
      " [  4.   8.  32.   4.]\n",
      " [  2. 128.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9831 finished with score 2452.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 32.0, 8.0, 4.0], [8.0, 64.0, 256.0, 2.0], [32.0, 2.0, 16.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9832 finished with score 716.0, result : lose board : [[ 4.  8.  2.  4.]\n",
      " [16.  4. 16.  8.]\n",
      " [32.  8. 64.  4.]\n",
      " [ 8.  4. 32.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9833 finished with score 3756.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [128.0, 32.0, 256.0, 4.0], [4.0, 128.0, 16.0, 8.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9834 finished with score 3472.0, result : lose board : [[2.0, 64.0, 2.0, 4.0], [4.0, 256.0, 4.0, 2.0], [64.0, 128.0, 64.0, 4.0], [4.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 255, Loss : 0.2837033271789551\n",
      "Mini-Batch - 1 Back-Prop : 255, Loss : 0.47412651777267456\n",
      "Mini-Batch - 2 Back-Prop : 255, Loss : 0.34833645820617676\n",
      "Mini-Batch - 3 Back-Prop : 255, Loss : 0.22913417220115662\n",
      "Mini-Batch - 4 Back-Prop : 255, Loss : 0.33436352014541626\n",
      "Mini-Batch - 5 Back-Prop : 255, Loss : 0.5257918238639832\n",
      "Mini-Batch - 6 Back-Prop : 255, Loss : 0.2826196551322937\n",
      "Mini-Batch - 7 Back-Prop : 255, Loss : 0.2840760350227356\n",
      "Mini-Batch - 8 Back-Prop : 255, Loss : 0.4345306158065796\n",
      "Mini-Batch - 9 Back-Prop : 255, Loss : 0.5329579710960388\n",
      "Mini-Batch - 10 Back-Prop : 255, Loss : 0.8042481541633606\n",
      "Episode : 9835, Score : 6212.0, Iters : 400, Finish : not over\n",
      "Episode 9835 finished with score 6408.0, result : lose board : [[32.0, 8.0, 4, 2], [2.0, 64.0, 16.0, 8.0], [4.0, 512.0, 32.0, 4.0], [2.0, 256.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9836 finished with score 3196.0, result : lose board : [[4.0, 2.0, 32.0, 8.0], [16.0, 128.0, 64.0, 2.0], [4.0, 256.0, 8.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9837 finished with score 2756.0, result : lose board : [[  4.   2.   8.   2.]\n",
      " [ 64.   8.  64.   4.]\n",
      " [  2. 256.   2.  16.]\n",
      " [ 64.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9838 finished with score 3012.0, result : lose board : [[  4.  64.   8.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [  8.   4.  32.  16.]\n",
      " [  2. 256.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9839 finished with score 1268.0, result : lose board : [[  2.   4. 128.   4.]\n",
      " [  8.  16.   2.  16.]\n",
      " [  4.  64.  16.   8.]\n",
      " [  2.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9840, Score : 5768.0, Iters : 400, Finish : not over\n",
      "Episode 9840 finished with score 5772.0, result : lose board : [[64.0, 16.0, 2.0, 4.0], [2.0, 64.0, 16.0, 2.0], [512.0, 128.0, 8.0, 4.0], [2.0, 64.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9841 finished with score 3708.0, result : lose board : [[  4.  64.   8.   2.]\n",
      " [  8. 128.  64.   4.]\n",
      " [ 64. 256.  16.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9842 finished with score 3500.0, result : lose board : [[ 64.  16.   4.   2.]\n",
      " [  2. 128.  16.   4.]\n",
      " [ 64. 256.  32.   2.]\n",
      " [  2.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9843, Score : 5780.0, Iters : 400, Finish : not over\n",
      "Episode 9843 finished with score 5948.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [128. 512.  16.   4.]\n",
      " [  8. 128.  32.  16.]\n",
      " [  2.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9844 finished with score 1888.0, result : lose board : [[ 64.  16.   4.   2.]\n",
      " [ 32.   4.  32.   4.]\n",
      " [128.  64.  16.   8.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9845 finished with score 2756.0, result : lose board : [[  4.   2. 256.   2.]\n",
      " [ 32.   4. 128.   4.]\n",
      " [  2.  16.   4.  16.]\n",
      " [  4.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9846, Score : 6152.0, Iters : 400, Finish : not over\n",
      "Episode 9846 finished with score 7448.0, result : lose board : [[512.   8.   2.   4.]\n",
      " [  4.  32.   4.   2.]\n",
      " [128. 256.  64.   8.]\n",
      " [ 64.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9847 finished with score 3528.0, result : lose board : [[64.0, 8.0, 4.0, 2], [128.0, 256.0, 2.0, 4.0], [64.0, 16.0, 64.0, 8.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9848 finished with score 2508.0, result : lose board : [[2.0, 16.0, 4.0, 2.0], [4.0, 256.0, 2.0, 8.0], [64.0, 2.0, 64.0, 4.0], [2.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9849 finished with score 2408.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  2.  64.  16.  32.]\n",
      " [  8.  16. 256.   4.]\n",
      " [  2.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9850 finished with score 2352.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 2.0, 16.0, 4.0], [32.0, 256.0, 64.0, 2.0], [4.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9851 finished with score 2920.0, result : lose board : [[ 16   8   2   4]\n",
      " [  8  32   4   8]\n",
      " [256 128  16   4]\n",
      " [  8  32   8   2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9852, Score : 5696.0, Iters : 400, Finish : not over\n",
      "Episode 9852 finished with score 7056.0, result : lose board : [[  4.  64.  16.   2.]\n",
      " [512.  32.  64.   8.]\n",
      " [  2. 256.  16.   4.]\n",
      " [ 64.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9853 finished with score 3272.0, result : lose board : [[  4.  32.   8.   4.]\n",
      " [ 32. 256.  32.   2.]\n",
      " [128.  64.  16.   4.]\n",
      " [ 16.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9854 finished with score 1508.0, result : lose board : [[32.0, 8.0, 4.0, 2], [8.0, 32.0, 16.0, 4.0], [2.0, 64.0, 128.0, 2.0], [32.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9855 finished with score 1380.0, result : lose board : [[ 16.   2.   8.   2.]\n",
      " [  4.   8.  32.   8.]\n",
      " [  2. 128.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9856 finished with score 5260.0, result : lose board : [[  8.   4.  16.   4.]\n",
      " [512.  16.   4.   8.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  2. 128.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 256, Loss : 0.5519578456878662\n",
      "Mini-Batch - 1 Back-Prop : 256, Loss : 0.24235844612121582\n",
      "Mini-Batch - 2 Back-Prop : 256, Loss : 0.533937931060791\n",
      "Mini-Batch - 3 Back-Prop : 256, Loss : 0.3327060043811798\n",
      "Mini-Batch - 4 Back-Prop : 256, Loss : 0.43546053767204285\n",
      "Mini-Batch - 5 Back-Prop : 256, Loss : 0.33679527044296265\n",
      "Mini-Batch - 6 Back-Prop : 256, Loss : 0.8038407564163208\n",
      "Mini-Batch - 7 Back-Prop : 256, Loss : 0.7338305711746216\n",
      "Mini-Batch - 8 Back-Prop : 256, Loss : 0.6882836818695068\n",
      "Mini-Batch - 9 Back-Prop : 256, Loss : 0.5599592924118042\n",
      "Mini-Batch - 10 Back-Prop : 256, Loss : 0.3732735812664032\n",
      "Episode 9857 finished with score 1612.0, result : lose board : [[ 32.  16.   2.   4.]\n",
      " [  2.  32.   4.   8.]\n",
      " [ 16.  64.  16.   4.]\n",
      " [128.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9858 finished with score 4600.0, result : lose board : [[32.0, 8.0, 4.0, 2], [2, 64.0, 512.0, 16.0], [8.0, 16.0, 4.0, 8.0], [2.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9859 finished with score 4676.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 16.  64.   8.  16.]\n",
      " [  2.  32. 512.   2.]\n",
      " [ 16.   8.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9860 finished with score 3460.0, result : lose board : [[ 32.   4.   8.   2.]\n",
      " [ 64. 128.  64.   4.]\n",
      " [  8. 256.  16.   8.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9861 finished with score 5280.0, result : lose board : [[2, 4.0, 16.0, 4], [512.0, 16.0, 64.0, 2.0], [2.0, 128.0, 8.0, 4.0], [4.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9862 finished with score 4096.0, result : lose board : [[  2.  32.   4.   2.]\n",
      " [  4.  16.   8.   4.]\n",
      " [256.   4. 256.  16.]\n",
      " [ 64.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9863 finished with score 2308.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [ 32. 256.  16.   4.]\n",
      " [  2.   8.  32.   8.]\n",
      " [ 32.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9864 finished with score 1552.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  2.   4.  32.   2.]\n",
      " [ 64. 128.  16.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9865 finished with score 1588.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 32.0, 8.0, 4.0], [2.0, 64.0, 128.0, 8.0], [64.0, 8.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9866 finished with score 1604.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  8. 128.  16.   8.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9867 finished with score 3420.0, result : lose board : [[2.0, 64.0, 16.0, 2.0], [64.0, 256.0, 128.0, 8.0], [8.0, 32.0, 8.0, 16.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9868 finished with score 2216.0, result : lose board : [[4.0, 32.0, 4.0, 2.0], [64.0, 128.0, 16.0, 8.0], [128.0, 16.0, 4, 2], [2.0, 32.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9869 finished with score 2724.0, result : lose board : [[2, 64.0, 8.0, 4.0], [4.0, 32.0, 16.0, 2.0], [32.0, 256.0, 64.0, 4.0], [2.0, 16.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9870 finished with score 3888.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [8.0, 32.0, 128.0, 4.0], [128.0, 256.0, 16.0, 8.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9871 finished with score 1848.0, result : lose board : [[2.0, 16.0, 4.0, 2], [32.0, 4.0, 32.0, 4.0], [4.0, 128.0, 16.0, 2.0], [128.0, 16.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9872 finished with score 2464.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [  8.  64.  16.   4.]\n",
      " [  2. 256.  32.  16.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9873 finished with score 4052.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [128.  32.  64.   4.]\n",
      " [  2. 256.  32.   8.]\n",
      " [  4. 128.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9874 finished with score 5024.0, result : lose board : [[  4.  32.   4.   2.]\n",
      " [ 64. 512.   8.   4.]\n",
      " [ 32.  16.  64.   8.]\n",
      " [  8.   4.   8.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9875 finished with score 3812.0, result : lose board : [[  2.   4.  64.  16.]\n",
      " [128. 256.   8.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [  2.   4.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9876 finished with score 4152.0, result : lose board : [[2, 32.0, 4, 2], [4.0, 256.0, 2.0, 4.0], [16.0, 64.0, 16.0, 2.0], [2.0, 256.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9877 finished with score 3220.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [ 16.  64.  16.   8.]\n",
      " [256. 128.  32.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9878 finished with score 3020.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8. 128.  16.   4.]\n",
      " [ 32. 256.  32.   8.]\n",
      " [  2.  32.   4.  16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9879 finished with score 1032.0, result : lose board : [[  4.   8.   4.   2.]\n",
      " [  8.  32.   2.   4.]\n",
      " [ 16. 128.  16.   8.]\n",
      " [  2.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9880 finished with score 1512.0, result : lose board : [[8.0, 32.0, 8.0, 4.0], [16.0, 8.0, 16.0, 8.0], [2.0, 128.0, 64.0, 16.0], [32.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 257, Loss : 0.3706340789794922\n",
      "Mini-Batch - 1 Back-Prop : 257, Loss : 0.4176569879055023\n",
      "Mini-Batch - 2 Back-Prop : 257, Loss : 0.4324406683444977\n",
      "Mini-Batch - 3 Back-Prop : 257, Loss : 0.32860463857650757\n",
      "Mini-Batch - 4 Back-Prop : 257, Loss : 0.29022806882858276\n",
      "Mini-Batch - 5 Back-Prop : 257, Loss : 0.4696376621723175\n",
      "Mini-Batch - 6 Back-Prop : 257, Loss : 0.3775797486305237\n",
      "Mini-Batch - 7 Back-Prop : 257, Loss : 0.27020999789237976\n",
      "Mini-Batch - 8 Back-Prop : 257, Loss : 0.6663917303085327\n",
      "Mini-Batch - 9 Back-Prop : 257, Loss : 0.43403756618499756\n",
      "Mini-Batch - 10 Back-Prop : 257, Loss : 0.8185305595397949\n",
      "Episode : 9881, Score : 5604.0, Iters : 400, Finish : not over\n",
      "Episode 9881 finished with score 5668.0, result : lose board : [[  2.  32.  16.   4.]\n",
      " [  4. 128.  64.   2.]\n",
      " [ 32. 512.  32.   4.]\n",
      " [ 16.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9882 finished with score 2348.0, result : lose board : [[ 32. 128.   8.   4.]\n",
      " [  2.  64.  16.   8.]\n",
      " [128.  16.  32.   4.]\n",
      " [  2.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9883 finished with score 2472.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [256.0, 32.0, 64.0, 2.0], [32.0, 16.0, 8.0, 4.0], [16.0, 8.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9884 finished with score 2300.0, result : lose board : [[  8.   4.   2.   4.]\n",
      " [ 16. 256.  16.   2.]\n",
      " [  8.  64.  32.   8.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9885 finished with score 1808.0, result : lose board : [[2.0, 32.0, 4.0, 2], [32.0, 128.0, 8.0, 4.0], [2.0, 64.0, 16.0, 8.0], [64.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9886 finished with score 3952.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  4. 128.  64.   8.]\n",
      " [256.  16.   8.   4.]\n",
      " [  2. 128.  64.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9887 finished with score 1080.0, result : lose board : [[ 16. 128.   8.   4.]\n",
      " [  2.   8.  16.   8.]\n",
      " [ 16.   4.  32.   4.]\n",
      " [  8.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9888 finished with score 3032.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [ 16.  64.  16.   8.]\n",
      " [256.  16. 128.   4.]\n",
      " [ 16.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9889 finished with score 3212.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [64.0, 128.0, 32.0, 4.0], [16.0, 256.0, 8.0, 16.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9890 finished with score 2380.0, result : lose board : [[2.0, 256.0, 4.0, 2], [4.0, 64.0, 32.0, 4.0], [32.0, 8.0, 4.0, 2.0], [8.0, 4.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9891 finished with score 920.0, result : lose board : [[ 2. 32.  8.  2.]\n",
      " [32.  2. 32.  4.]\n",
      " [ 4. 64. 16.  8.]\n",
      " [32. 16.  8.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9892 finished with score 2128.0, result : lose board : [[  4. 128.   4.   2.]\n",
      " [ 64.   4.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 32.   8.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9893 finished with score 3924.0, result : lose board : [[  2.  16.   8.   4.]\n",
      " [  4. 128.  16.   8.]\n",
      " [128. 256.  32.   4.]\n",
      " [ 32.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9894 finished with score 1908.0, result : lose board : [[  2.  32.   8.   2.]\n",
      " [  4.   2.  16.   4.]\n",
      " [ 64. 128.  64.   8.]\n",
      " [  4.  64.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9895 finished with score 2064.0, result : lose board : [[32.0, 16.0, 4.0, 2], [128.0, 4.0, 8.0, 4.0], [4.0, 128.0, 16.0, 2.0], [64.0, 8.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9896 finished with score 2396.0, result : lose board : [[ 64.   4.   2.   4.]\n",
      " [  2.  32.   8.   2.]\n",
      " [  4. 256.  16.   8.]\n",
      " [ 32.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9897 finished with score 1756.0, result : lose board : [[ 64.   2.  16.   2.]\n",
      " [  4.  32.   8.   4.]\n",
      " [ 32.  64.  16.   8.]\n",
      " [  2. 128.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9898 finished with score 5492.0, result : lose board : [[2.0, 16.0, 4.0, 2], [32.0, 512.0, 128.0, 16.0], [8.0, 64.0, 32.0, 8.0], [2.0, 4.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9899 finished with score 2996.0, result : lose board : [[4.0, 2.0, 128.0, 4.0], [16.0, 8.0, 64.0, 2.0], [8.0, 256.0, 16.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9900 finished with score 4212.0, result : lose board : [[8.0, 2.0, 8.0, 2.0], [16.0, 256.0, 16.0, 4.0], [256.0, 64.0, 32.0, 8.0], [32.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9901, Score : 5812.0, Iters : 400, Finish : not over\n",
      "Episode 9901 finished with score 7136.0, result : lose board : [[  2.  32.   8.   4.]\n",
      " [  4. 128.  64.   8.]\n",
      " [  2. 256. 512.  16.]\n",
      " [  8.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9902 finished with score 3348.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [128.   8. 128.   8.]\n",
      " [  2. 256.   8.   4.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9903 finished with score 3484.0, result : lose board : [[  8.  32.   4.   2.]\n",
      " [ 64. 256.  16.   4.]\n",
      " [  2. 128.  64.   8.]\n",
      " [ 32.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9904 finished with score 2624.0, result : lose board : [[ 16.   4.   8.   2.]\n",
      " [ 32.  16.  32.   4.]\n",
      " [256.  64.  16.   8.]\n",
      " [  2.   8.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 258, Loss : 0.3242415487766266\n",
      "Mini-Batch - 1 Back-Prop : 258, Loss : 0.2833499312400818\n",
      "Mini-Batch - 2 Back-Prop : 258, Loss : 0.23467424511909485\n",
      "Mini-Batch - 3 Back-Prop : 258, Loss : 0.3420960307121277\n",
      "Mini-Batch - 4 Back-Prop : 258, Loss : 0.27123621106147766\n",
      "Mini-Batch - 5 Back-Prop : 258, Loss : 0.3644373118877411\n",
      "Mini-Batch - 6 Back-Prop : 258, Loss : 0.32403236627578735\n",
      "Mini-Batch - 7 Back-Prop : 258, Loss : 0.43151766061782837\n",
      "Mini-Batch - 8 Back-Prop : 258, Loss : 0.4103681445121765\n",
      "Mini-Batch - 9 Back-Prop : 258, Loss : 0.6114277839660645\n",
      "Mini-Batch - 10 Back-Prop : 258, Loss : 0.6467921137809753\n",
      "Episode 9905 finished with score 1572.0, result : lose board : [[2.0, 16.0, 4.0, 2], [4.0, 64.0, 16.0, 8.0], [32.0, 128.0, 32.0, 4.0], [2.0, 32.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9906 finished with score 2472.0, result : lose board : [[  2.  16.  32.   2.]\n",
      " [ 16.  32. 256.   4.]\n",
      " [  4.  64.   4.   8.]\n",
      " [ 16.   8.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9907 finished with score 1440.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [  2. 128.  32.   2.]\n",
      " [  8.  64.  16.   8.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9908 finished with score 1424.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [ 16. 128.  16.   8.]\n",
      " [ 32.  64.  32.   4.]\n",
      " [  4.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9909 finished with score 2548.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [ 32. 256.  16.   8.]\n",
      " [  8.  64.  32.   2.]\n",
      " [ 32.   2.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9910 finished with score 2968.0, result : lose board : [[2.0, 16.0, 2.0, 4.0], [32.0, 256.0, 8.0, 2], [2.0, 32.0, 16.0, 8.0], [128.0, 4.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9911 finished with score 3464.0, result : lose board : [[2.0, 128.0, 8.0, 4.0], [8.0, 4.0, 256.0, 8.0], [2.0, 128.0, 8.0, 4.0], [32.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9912 finished with score 1008.0, result : lose board : [[ 2. 16.  8.  2.]\n",
      " [64.  4. 64. 16.]\n",
      " [16. 32. 16.  4.]\n",
      " [ 2. 16.  4.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9913 finished with score 4908.0, result : lose board : [[64.0, 16.0, 4, 2], [2.0, 512.0, 8.0, 16.0], [4.0, 64.0, 32.0, 8.0], [2.0, 8.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9914 finished with score 1456.0, result : lose board : [[ 16.   2.   8.   4.]\n",
      " [  2.  64.  32.   8.]\n",
      " [  8. 128.  16.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9915 finished with score 3272.0, result : lose board : [[16.0, 2, 4, 2], [64.0, 16.0, 128.0, 16.0], [8.0, 4.0, 64.0, 4.0], [4.0, 256.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9916 finished with score 2632.0, result : lose board : [[  4.  16.   8.   2.]\n",
      " [256.  64.  16.   4.]\n",
      " [  4.   8.  64.   2.]\n",
      " [ 32.   4.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9917 finished with score 2568.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  2.  64.  16.   4.]\n",
      " [ 32. 256.  32.   8.]\n",
      " [  4.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9918 finished with score 3440.0, result : lose board : [[4.0, 16.0, 8.0, 2.0], [256.0, 64.0, 16.0, 4.0], [2.0, 128.0, 32.0, 16.0], [64.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9919 finished with score 4596.0, result : lose board : [[  8.   2.   4.   2.]\n",
      " [  2.  32.   8.   4.]\n",
      " [512.  64.   2.  16.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9920 finished with score 3184.0, result : lose board : [[16.0, 8.0, 4.0, 2], [2.0, 64.0, 32.0, 4.0], [32.0, 256.0, 16.0, 8.0], [2.0, 128.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9921 finished with score 928.0, result : lose board : [[32.0, 8.0, 4, 2], [4.0, 16.0, 8.0, 4.0], [32.0, 64.0, 16.0, 32.0], [2.0, 32.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9922 finished with score 3120.0, result : lose board : [[  4.   2.  16.   2.]\n",
      " [  2. 128. 256.   4.]\n",
      " [ 64.   2.   4.   8.]\n",
      " [ 32.   4.   2.  32.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9923 finished with score 2708.0, result : lose board : [[ 32.   8.   4.   2.]\n",
      " [  4.  64.  16.   4.]\n",
      " [ 64. 256.   4.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9924 finished with score 2740.0, result : lose board : [[  4.  16.   4.   2.]\n",
      " [ 32.  64.   8.   4.]\n",
      " [256.  32.  16.   8.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9925 finished with score 2312.0, result : lose board : [[8.0, 4.0, 2.0, 4.0], [16.0, 32.0, 8.0, 64.0], [2.0, 4.0, 256.0, 4.0], [4.0, 16.0, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9926 finished with score 2884.0, result : lose board : [[8.0, 4.0, 32.0, 4.0], [32.0, 128.0, 256.0, 16.0], [4.0, 16.0, 2.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9927 finished with score 676.0, result : lose board : [[ 2.  4.  8.  4.]\n",
      " [32. 64.  4.  8.]\n",
      " [ 2. 32. 16.  4.]\n",
      " [16.  4.  8.  2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9928 finished with score 1632.0, result : lose board : [[  4.   2.   4.   2.]\n",
      " [  2.   8.  16.   4.]\n",
      " [  4. 128.   4. 128.]\n",
      " [  2.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9929 finished with score 2272.0, result : lose board : [[ 16.   4. 128.   2.]\n",
      " [  2.  64.  16.   8.]\n",
      " [128.   8.  64.   4.]\n",
      " [  2.   4.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9930 finished with score 2336.0, result : lose board : [[ 16.   4.   2.   4.]\n",
      " [  8.  16.  64. 256.]\n",
      " [  2.   8.  32.   8.]\n",
      " [  4.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9931 finished with score 1388.0, result : lose board : [[2.0, 4.0, 2.0, 4.0], [8.0, 64.0, 4.0, 2], [128.0, 4.0, 8.0, 4.0], [2.0, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9932 finished with score 4568.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  4.   2.  64.   8.]\n",
      " [512.   8.  16.   4.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 259, Loss : 0.36608630418777466\n",
      "Mini-Batch - 1 Back-Prop : 259, Loss : 0.5898504853248596\n",
      "Mini-Batch - 2 Back-Prop : 259, Loss : 0.4774172902107239\n",
      "Mini-Batch - 3 Back-Prop : 259, Loss : 0.376900315284729\n",
      "Mini-Batch - 4 Back-Prop : 259, Loss : 0.31565749645233154\n",
      "Mini-Batch - 5 Back-Prop : 259, Loss : 0.520026683807373\n",
      "Mini-Batch - 6 Back-Prop : 259, Loss : 0.4489106237888336\n",
      "Mini-Batch - 7 Back-Prop : 259, Loss : 0.6947083473205566\n",
      "Mini-Batch - 8 Back-Prop : 259, Loss : 0.6438615322113037\n",
      "Mini-Batch - 9 Back-Prop : 259, Loss : 0.6298395991325378\n",
      "Mini-Batch - 10 Back-Prop : 259, Loss : 0.6698852181434631\n",
      "Episode 9933 finished with score 2532.0, result : lose board : [[  4.  32.   8.   2.]\n",
      " [ 32.  16.  32.   4.]\n",
      " [  4.  64.   4.   2.]\n",
      " [256.  16.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9934 finished with score 1692.0, result : lose board : [[16.0, 8.0, 4.0, 2], [4.0, 128.0, 32.0, 4.0], [8.0, 64.0, 16.0, 8.0], [64.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9935 finished with score 1004.0, result : lose board : [[64.0, 8.0, 4, 2], [2.0, 16.0, 32.0, 8.0], [8.0, 64.0, 16.0, 2.0], [32.0, 4.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9936 finished with score 3208.0, result : lose board : [[8.0, 64.0, 4.0, 2], [32.0, 16.0, 8.0, 4.0], [8.0, 256.0, 128.0, 16.0], [2.0, 32.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9937 finished with score 1484.0, result : lose board : [[  4.  32.   2.   4.]\n",
      " [128.  16.   4.   8.]\n",
      " [ 32.  64.  16.   2.]\n",
      " [  8.  16.   2.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9938 finished with score 2888.0, result : lose board : [[ 32.   4.   2.   4.]\n",
      " [256.   8.  32.   8.]\n",
      " [128.   4.  16.   4.]\n",
      " [  2.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9939 finished with score 5504.0, result : lose board : [[  4.  32.  16.   4.]\n",
      " [  8. 512.  32.   8.]\n",
      " [ 64. 128.  16.   4.]\n",
      " [  2.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9940 finished with score 5452.0, result : lose board : [[32.0, 16.0, 2.0, 4.0], [4.0, 512.0, 8.0, 2], [128.0, 64.0, 16.0, 8.0], [32.0, 16.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9941 finished with score 3392.0, result : lose board : [[ 16.   8.   4.   2.]\n",
      " [  2. 128.   8.   4.]\n",
      " [ 64.   8.  64.   8.]\n",
      " [  4. 256.   8.  32.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9942 finished with score 1616.0, result : lose board : [[ 32.   8.   2.   4.]\n",
      " [  2.  64.   4.   8.]\n",
      " [ 64.  16. 128.   4.]\n",
      " [ 16.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9943 finished with score 2296.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 64.0, 2.0, 4.0], [16.0, 4.0, 32.0, 2.0], [8.0, 256.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9944 finished with score 2204.0, result : lose board : [[32.0, 16.0, 8.0, 2], [64.0, 32.0, 16.0, 8.0], [128.0, 64.0, 32.0, 2.0], [64.0, 16.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9945 finished with score 3332.0, result : lose board : [[64.0, 16.0, 4.0, 2], [2.0, 256.0, 8.0, 4.0], [8.0, 128.0, 32.0, 8.0], [2.0, 64.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9946 finished with score 1444.0, result : lose board : [[2.0, 64.0, 8.0, 2.0], [8.0, 128.0, 32.0, 8.0], [16.0, 8.0, 16.0, 4.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9947 finished with score 3332.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [128.  64.  32.   8.]\n",
      " [  4. 256.  16.   4.]\n",
      " [ 32.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9948 finished with score 3164.0, result : lose board : [[ 16.   4.  16.   2.]\n",
      " [128.  16. 256.   4.]\n",
      " [ 16.  32.  16.   8.]\n",
      " [  4.  64.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9949 finished with score 1244.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 4.0, 32.0, 4.0], [32.0, 128.0, 16.0, 2.0], [4.0, 32.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9950 finished with score 2960.0, result : lose board : [[2.0, 4.0, 2.0, 4.0], [8.0, 256.0, 4.0, 2], [128.0, 64.0, 32.0, 4.0], [8.0, 2.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9951 finished with score 2840.0, result : lose board : [[  4. 256.   8.   4.]\n",
      " [128.   8.  32.   8.]\n",
      " [ 16.   4.  16.   4.]\n",
      " [  4.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9952 finished with score 1764.0, result : lose board : [[  2.  16.   2.   4.]\n",
      " [  8.  64.   4.   8.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [  8. 128.  32.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9953 finished with score 1588.0, result : lose board : [[  2.   8.   4.   2.]\n",
      " [  8.  32.  16.   4.]\n",
      " [  2. 128.   8.  64.]\n",
      " [ 64.  16.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9954 finished with score 3076.0, result : lose board : [[  2.   8.   2.  16.]\n",
      " [  8.  64.   8.   2.]\n",
      " [ 32. 256. 128.   4.]\n",
      " [  4.  16.   4.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9955 finished with score 2368.0, result : lose board : [[ 32.  16.   8.   2.]\n",
      " [  4. 128.  32.   4.]\n",
      " [128.  64.  16.   8.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9956 finished with score 2988.0, result : lose board : [[4.0, 32.0, 2.0, 4.0], [2.0, 8.0, 4.0, 8.0], [128.0, 32.0, 256.0, 16.0], [32.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9957 finished with score 3380.0, result : lose board : [[2.0, 8.0, 4.0, 2], [16.0, 256.0, 2.0, 8.0], [64.0, 128.0, 64.0, 2.0], [2.0, 8.0, 32.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9958 finished with score 3192.0, result : lose board : [[2.0, 16.0, 4.0, 2], [256.0, 64.0, 32.0, 8.0], [32.0, 128.0, 16.0, 4.0], [2.0, 4.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 260, Loss : 0.3920063376426697\n",
      "Mini-Batch - 1 Back-Prop : 260, Loss : 0.34205085039138794\n",
      "Mini-Batch - 2 Back-Prop : 260, Loss : 0.2690136730670929\n",
      "Mini-Batch - 3 Back-Prop : 260, Loss : 0.21668319404125214\n",
      "Mini-Batch - 4 Back-Prop : 260, Loss : 0.3432348668575287\n",
      "Mini-Batch - 5 Back-Prop : 260, Loss : 0.3353726863861084\n",
      "Mini-Batch - 6 Back-Prop : 260, Loss : 0.3811897337436676\n",
      "Mini-Batch - 7 Back-Prop : 260, Loss : 0.5559802055358887\n",
      "Mini-Batch - 8 Back-Prop : 260, Loss : 0.37537020444869995\n",
      "Mini-Batch - 9 Back-Prop : 260, Loss : 0.5540958642959595\n",
      "Mini-Batch - 10 Back-Prop : 260, Loss : 0.7237471342086792\n",
      "Episode 9959 finished with score 1708.0, result : lose board : [[4.0, 8.0, 4.0, 2], [16.0, 128.0, 32.0, 4.0], [8.0, 32.0, 4.0, 64.0], [2.0, 64.0, 2.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9960 finished with score 1468.0, result : lose board : [[4.0, 16.0, 4.0, 2], [128.0, 64.0, 32.0, 8.0], [32.0, 2.0, 16.0, 4.0], [4.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9961 finished with score 5156.0, result : lose board : [[2, 16.0, 2, 4], [4.0, 64.0, 8.0, 2.0], [128.0, 16.0, 2.0, 4], [4.0, 512.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9962 finished with score 5584.0, result : lose board : [[ 32.  16.   8.   4.]\n",
      " [  2. 128.  32.   8.]\n",
      " [512.  32.  16.   4.]\n",
      " [ 64.  16.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9963 finished with score 1880.0, result : lose board : [[ 32.   8.  16.   2.]\n",
      " [  2.  32.   8.   4.]\n",
      " [ 64. 128.  64.   2.]\n",
      " [  8.  32.  16.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9964 finished with score 1544.0, result : lose board : [[  8.   2.   8.   2.]\n",
      " [  2.  64.  32.   4.]\n",
      " [ 32. 128.  16.   8.]\n",
      " [  4.  32.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9965 finished with score 1724.0, result : lose board : [[  2.  16.   4.   2.]\n",
      " [  4.  32.   2.   8.]\n",
      " [  8.  64. 128.   2.]\n",
      " [ 64.  32.   2.   8.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9966 finished with score 1700.0, result : lose board : [[16.0, 2.0, 4.0, 8.0], [8.0, 128.0, 8.0, 4.0], [128.0, 2.0, 16.0, 8.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9967 finished with score 3068.0, result : lose board : [[2.0, 16.0, 4.0, 2], [8.0, 128.0, 8.0, 4.0], [64.0, 16.0, 256.0, 32.0], [2.0, 4.0, 8.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9968 finished with score 3088.0, result : lose board : [[  2.  16.   8.   2.]\n",
      " [  8. 128.  16.   8.]\n",
      " [256.  64.  32.   4.]\n",
      " [  8.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9969 finished with score 3228.0, result : lose board : [[2, 4.0, 256.0, 4.0], [16.0, 64.0, 8.0, 2.0], [128.0, 32.0, 16.0, 4.0], [32.0, 16.0, 4.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9970 finished with score 1384.0, result : lose board : [[ 16.   8.   2.   4.]\n",
      " [  2.  32. 128.   8.]\n",
      " [ 16.   4.  16.   4.]\n",
      " [  2.  64.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9971 finished with score 1228.0, result : lose board : [[64.0, 2.0, 4, 2], [2, 32.0, 16.0, 4.0], [4.0, 64.0, 8.0, 2.0], [64.0, 4.0, 32.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9972 finished with score 3792.0, result : lose board : [[2.0, 8.0, 4.0, 2], [4.0, 64.0, 128.0, 4.0], [16.0, 256.0, 16.0, 32.0], [2.0, 128.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9973 finished with score 2436.0, result : lose board : [[  2. 256.   2.  32.]\n",
      " [ 16.  32.   4.   2.]\n",
      " [ 64.   4.  16.   8.]\n",
      " [  8.   2.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9974 finished with score 928.0, result : lose board : [[2, 8.0, 16.0, 4.0], [4.0, 32.0, 4.0, 8.0], [16.0, 8.0, 64.0, 4.0], [2.0, 64.0, 16.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9975 finished with score 3312.0, result : lose board : [[  8.  32.   8.   4.]\n",
      " [  2. 256.  16.   8.]\n",
      " [  4. 128.  32.   4.]\n",
      " [ 64.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9976 finished with score 2732.0, result : lose board : [[32.0, 16.0, 8.0, 2.0], [2.0, 256.0, 64.0, 8.0], [4.0, 32.0, 8.0, 2], [2.0, 64.0, 16.0, 4.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9977 finished with score 2996.0, result : lose board : [[2.0, 16.0, 8.0, 2.0], [128.0, 256.0, 32.0, 4.0], [32.0, 2.0, 16.0, 8.0], [2.0, 32.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9978 finished with score 2508.0, result : lose board : [[16.0, 8.0, 16.0, 2.0], [32.0, 256.0, 32.0, 8.0], [2.0, 4.0, 64.0, 4.0], [16.0, 8.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9979 finished with score 3632.0, result : lose board : [[ 32.  16.   4.   2.]\n",
      " [128.  64.  32.   4.]\n",
      " [ 64. 256.  16.   2.]\n",
      " [ 32.  16.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9980 finished with score 400.0, result : lose board : [[ 4.  2.  8.  4.]\n",
      " [ 8.  4. 32.  2.]\n",
      " [32.  2.  8.  4.]\n",
      " [ 8. 16.  2. 16.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9981 finished with score 2940.0, result : lose board : [[ 32.   4.   2.   8.]\n",
      " [  4. 256.   8.  32.]\n",
      " [ 32.   8. 128.   4.]\n",
      " [  4.   2.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9982 finished with score 2440.0, result : lose board : [[2.0, 16.0, 8.0, 4.0], [32.0, 8.0, 32.0, 8.0], [64.0, 256.0, 8.0, 4.0], [2.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9983 finished with score 1492.0, result : lose board : [[32.0, 16.0, 8.0, 2], [2.0, 128.0, 16.0, 8.0], [8.0, 64.0, 32.0, 4.0], [2.0, 16.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9984 finished with score 4876.0, result : lose board : [[64.0, 256.0, 4.0, 2], [4.0, 32.0, 16.0, 4.0], [2.0, 128.0, 4.0, 8.0], [256.0, 8.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9985 finished with score 2340.0, result : lose board : [[4.0, 32.0, 8.0, 2.0], [64.0, 4.0, 16.0, 4.0], [2.0, 8.0, 256.0, 8.0], [4.0, 2.0, 16.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Mini-Batch - 0 Back-Prop : 261, Loss : 0.39678293466567993\n",
      "Mini-Batch - 1 Back-Prop : 261, Loss : 0.3948171138763428\n",
      "Mini-Batch - 2 Back-Prop : 261, Loss : 0.23934762179851532\n",
      "Mini-Batch - 3 Back-Prop : 261, Loss : 0.6445031762123108\n",
      "Mini-Batch - 4 Back-Prop : 261, Loss : 0.36818885803222656\n",
      "Mini-Batch - 5 Back-Prop : 261, Loss : 0.7867059111595154\n",
      "Mini-Batch - 6 Back-Prop : 261, Loss : 0.6132000684738159\n",
      "Mini-Batch - 7 Back-Prop : 261, Loss : 0.5196258425712585\n",
      "Mini-Batch - 8 Back-Prop : 261, Loss : 0.5024705529212952\n",
      "Mini-Batch - 9 Back-Prop : 261, Loss : 0.3710162043571472\n",
      "Mini-Batch - 10 Back-Prop : 261, Loss : 0.40758711099624634\n",
      "Episode 9986 finished with score 4404.0, result : lose board : [[2, 8.0, 4.0, 2], [256.0, 32.0, 8.0, 4.0], [2.0, 64.0, 256.0, 64.0], [16.0, 32.0, 4.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9987 finished with score 1812.0, result : lose board : [[  4.  16.   4.   8.]\n",
      " [ 64.  32.  16.   4.]\n",
      " [ 16. 128.  64.  16.]\n",
      " [  2.  32.   4.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9988 finished with score 3272.0, result : lose board : [[  2.  64.   8.   4.]\n",
      " [  4.   2.  32.   8.]\n",
      " [  8. 128. 256.   4.]\n",
      " [ 64.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9989 finished with score 1300.0, result : lose board : [[4.0, 32.0, 4.0, 2.0], [128.0, 16.0, 32.0, 8.0], [4.0, 32.0, 16.0, 4.0], [16.0, 8, 4, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9990 finished with score 3108.0, result : lose board : [[16.0, 8.0, 4, 2], [2.0, 16.0, 128.0, 8.0], [32.0, 64.0, 16.0, 4.0], [2.0, 256.0, 8.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode : 9991, Score : 5652.0, Iters : 400, Finish : not over\n",
      "Episode 9991 finished with score 6184.0, result : lose board : [[  4. 128.   2.   4.]\n",
      " [128.  16.   8.  32.]\n",
      " [  4.  32. 512.   4.]\n",
      " [ 64.   4.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9992 finished with score 1532.0, result : lose board : [[2, 32.0, 16.0, 4.0], [4.0, 64.0, 32.0, 2.0], [16.0, 128.0, 4.0, 8.0], [4.0, 2.0, 32.0, 2.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9993 finished with score 2592.0, result : lose board : [[2.0, 32.0, 8.0, 2.0], [16.0, 256.0, 16.0, 4.0], [64.0, 32.0, 4.0, 8.0], [32.0, 16.0, 2, 4]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9994 finished with score 1448.0, result : lose board : [[  4.   2.   8.   2.]\n",
      " [ 16.  32.  16.   4.]\n",
      " [ 64.   4. 128.   8.]\n",
      " [  2.  32.   8.   4.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9995 finished with score 3284.0, result : lose board : [[ 32. 256.   4.   2.]\n",
      " [  4.  32.  64.   8.]\n",
      " [128.   8.  16.   4.]\n",
      " [ 32.   2.   8.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9996 finished with score 3256.0, result : lose board : [[  4.  16.   8.   4.]\n",
      " [  8. 128.  16.   8.]\n",
      " [ 32. 256.  64.   4.]\n",
      " [  4.  32.  16.   2.]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9997 finished with score 2528.0, result : lose board : [[8.0, 4.0, 16.0, 2.0], [32.0, 8.0, 32.0, 4.0], [2, 64.0, 256.0, 16.0], [8.0, 16.0, 8.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9998 finished with score 1744.0, result : lose board : [[32.0, 8.0, 4.0, 2.0], [4.0, 32.0, 64.0, 16.0], [64.0, 128.0, 8.0, 4.0], [4.0, 16.0, 4.0, 2]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Episode 9999 finished with score 2724.0, result : lose board : [[2.0, 64.0, 4.0, 2], [64.0, 256.0, 16.0, 8.0], [4.0, 16.0, 32.0, 2.0], [2, 32.0, 2.0, 8.0]], epsilon  : 0.09977213709935216, learning rate : 0.00040499999886378646 \n",
      "\n",
      "Maximum Score : 8104.0 ,Episode : 9811\n",
      "Loss : 0.4767495813694867\n",
      "\n",
      "Maximum Score : 8104.0 ,Episode : 9811\n",
      "conv1_layer1_weights written!\n",
      "conv1_layer2_weights written!\n",
      "conv2_layer1_weights written!\n",
      "conv2_layer2_weights written!\n",
      "fc_layer1_weights written!\n",
      "fc_layer1_biases written!\n",
      "fc_layer2_weights written!\n",
      "fc_layer2_biases written!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    global epsilon\n",
    "    global replay_labels\n",
    "    global replay_memory\n",
    "\n",
    "    #for episode with max score\n",
    "    maximum = -1\n",
    "    episode = -1\n",
    "    \n",
    "    #total_iters \n",
    "    total_iters = 1\n",
    "    \n",
    "    #number of back props\n",
    "    back=0\n",
    "    \n",
    "    for ep in range(M):\n",
    "        global board\n",
    "        board = new_game(4)\n",
    "        add_two(board)\n",
    "        add_two(board)\n",
    "        \n",
    "        #whether episode finished or not\n",
    "        finish = 'not over'\n",
    "        \n",
    "        #total_score of this episode\n",
    "        total_score = 0\n",
    "        \n",
    "        #iters per episode\n",
    "        local_iters = 1\n",
    "        \n",
    "        while(finish=='not over'):\n",
    "            prev_board = deepcopy(board)\n",
    "            \n",
    "            #get the required move for this state\n",
    "            state = deepcopy(board)\n",
    "            state = change_values(state)\n",
    "            state = np.array(state,dtype = np.float32).reshape(1,4,4,16)\n",
    "            feed_dict = {single_dataset:state}\n",
    "            control_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "            \n",
    "            #find the move with max Q value\n",
    "            control_buttons = np.flip(np.argsort(control_scores),axis=1)\n",
    "            \n",
    "            #copy the Q-values as labels\n",
    "            labels = deepcopy(control_scores[0])\n",
    "            \n",
    "            #generate random number for epsilon greedy approach\n",
    "            num = random.uniform(0,1)\n",
    "            \n",
    "            #store prev max\n",
    "            prev_max = np.max(prev_board)\n",
    "            \n",
    "            #num is less epsilon generate random move\n",
    "            if(num<epsilon):\n",
    "                #find legal moves\n",
    "                legal_moves = list()\n",
    "                for i in range(4):\n",
    "                    temp_board = deepcopy(prev_board)\n",
    "                    temp_board,_,_ = controls[i](temp_board)\n",
    "                    if(np.array_equal(temp_board,prev_board)):\n",
    "                        continue\n",
    "                    else:\n",
    "                        legal_moves.append(i)\n",
    "                if(len(legal_moves)==0):\n",
    "                    finish = 'lose'\n",
    "                    continue\n",
    "                \n",
    "                #generate random move.\n",
    "                con = random.sample(legal_moves,1)[0]\n",
    "                \n",
    "                #apply the move\n",
    "                temp_state = deepcopy(prev_board)\n",
    "                temp_state,_,score = controls[con](temp_state)\n",
    "                total_score += score\n",
    "                finish = game_state(temp_state)\n",
    "                \n",
    "                #get number of merges\n",
    "                empty1 = findemptyCell(prev_board)\n",
    "                empty2 = findemptyCell(temp_state)\n",
    "                \n",
    "                if(finish=='not over'):\n",
    "                    temp_state = add_two(temp_state)\n",
    "\n",
    "                board = deepcopy(temp_state)\n",
    "\n",
    "                #get next max after applying the move\n",
    "                next_max = np.max(temp_state)\n",
    "                \n",
    "                #reward math.log(next_max,2)*0.1 if next_max is higher than prev max\n",
    "                labels[con] = (math.log(next_max,2))*0.1\n",
    "                \n",
    "                if(next_max==prev_max):\n",
    "                    labels[con] = 0\n",
    "                \n",
    "                #reward is also the number of merges\n",
    "                labels[con] += (empty2-empty1)\n",
    "                \n",
    "                #get the next state max Q-value\n",
    "                temp_state = change_values(temp_state)\n",
    "                temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
    "                feed_dict = {single_dataset:temp_state}\n",
    "                temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "                    \n",
    "                max_qvalue = np.max(temp_scores)\n",
    "                \n",
    "                #final labels add gamma*max_qvalue\n",
    "                labels[con] = (labels[con] + gamma*max_qvalue)\n",
    "            \n",
    "            #generate the the max predicted move\n",
    "            else:\n",
    "                for con in control_buttons[0]:\n",
    "                    prev_state = deepcopy(prev_board)\n",
    "                    \n",
    "                    #apply the LEGAl Move with max q_value\n",
    "                    temp_state,_,score = controls[con](prev_state)\n",
    "                    \n",
    "                    #if illegal move label = 0\n",
    "                    if(np.array_equal(prev_board,temp_state)):\n",
    "                        labels[con] = 0\n",
    "                        continue\n",
    "                        \n",
    "                    #get number of merges\n",
    "                    empty1 = findemptyCell(prev_board)\n",
    "                    empty2 = findemptyCell(temp_state)\n",
    "\n",
    "                    \n",
    "                    temp_state = add_two(temp_state)\n",
    "                    board = deepcopy(temp_state)\n",
    "                    total_score += score\n",
    "\n",
    "                    next_max = np.max(temp_state)\n",
    "                    \n",
    "                    #reward\n",
    "                    labels[con] = (math.log(next_max,2))*0.1\n",
    "                    if(next_max==prev_max):\n",
    "                        labels[con] = 0\n",
    "                    \n",
    "                    labels[con] += (empty2-empty1)\n",
    "\n",
    "                    #get next max qvalue\n",
    "                    temp_state = change_values(temp_state)\n",
    "                    temp_state = np.array(temp_state,dtype = np.float32).reshape(1,4,4,16)\n",
    "                    feed_dict = {single_dataset:temp_state}\n",
    "                    temp_scores = session.run(single_output,feed_dict=feed_dict)\n",
    "\n",
    "                    max_qvalue = np.max(temp_scores)\n",
    "\n",
    "                    #final labels\n",
    "                    labels[con] = (labels[con] + gamma*max_qvalue)\n",
    "                    break\n",
    "                    \n",
    "                if(np.array_equal(prev_board,board)):\n",
    "                    finish = 'lose'\n",
    "            \n",
    "            #decrease the epsilon value\n",
    "            if((ep>10000) or (epsilon>0.1 and total_iters%2500==0)):\n",
    "                epsilon = epsilon/1.005\n",
    "                \n",
    "           \n",
    "            #change the matrix values and store them in memory\n",
    "            prev_state = deepcopy(prev_board)\n",
    "            prev_state = change_values(prev_state)\n",
    "            prev_state = np.array(prev_state,dtype=np.float32).reshape(1,4,4,16)\n",
    "            replay_labels.append(labels)\n",
    "            replay_memory.append(prev_state)\n",
    "            \n",
    "            \n",
    "            #back-propagation\n",
    "            if(len(replay_memory)>=mem_capacity):\n",
    "                back_loss = 0\n",
    "                batch_num = 0\n",
    "                z = list(zip(replay_memory,replay_labels))\n",
    "                np.random.shuffle(z)\n",
    "                np.random.shuffle(z)\n",
    "                replay_memory,replay_labels = zip(*z)\n",
    "                \n",
    "                for i in range(0,len(replay_memory),batch_size):\n",
    "                    if(i + batch_size>len(replay_memory)):\n",
    "                        break\n",
    "                        \n",
    "                    batch_data = deepcopy(replay_memory[i:i+batch_size])\n",
    "                    batch_labels = deepcopy(replay_labels[i:i+batch_size])\n",
    "                    \n",
    "                    batch_data = np.array(batch_data,dtype=np.float32).reshape(batch_size,4,4,16)\n",
    "                    batch_labels = np.array(batch_labels,dtype=np.float32).reshape(batch_size,output_units)\n",
    "                \n",
    "                    feed_dict = {tf_batch_dataset: batch_data, tf_batch_labels: batch_labels}\n",
    "                    _,l = session.run([optimizer,loss],feed_dict=feed_dict)\n",
    "                    back_loss += l \n",
    "                    \n",
    "                    print(\"Mini-Batch - {} Back-Prop : {}, Loss : {}\".format(batch_num,back,l))\n",
    "                    batch_num +=1\n",
    "                back_loss /= batch_num\n",
    "                J.append(back_loss)\n",
    "                \n",
    "                #store the parameters in a dictionary\n",
    "                final_parameters['conv1_layer1_weights'] = session.run(conv1_layer1_weights)\n",
    "                final_parameters['conv1_layer2_weights'] = session.run(conv1_layer2_weights)\n",
    "                final_parameters['conv2_layer1_weights'] = session.run(conv2_layer1_weights)\n",
    "                final_parameters['conv2_layer2_weights'] = session.run(conv2_layer2_weights)\n",
    "                final_parameters['fc_layer1_weights'] = session.run(fc_layer1_weights)\n",
    "                final_parameters['fc_layer2_weights'] = session.run(fc_layer2_weights)\n",
    "                final_parameters['fc_layer1_biases'] = session.run(fc_layer1_biases)\n",
    "                final_parameters['fc_layer2_biases'] = session.run(fc_layer2_biases)\n",
    "                \n",
    "                #number of back-props\n",
    "                back+=1\n",
    "                \n",
    "                #make new memory \n",
    "                replay_memory = list()\n",
    "                replay_labels = list()\n",
    "                \n",
    "            \n",
    "            if(local_iters%400==0):\n",
    "                print(\"Episode : {}, Score : {}, Iters : {}, Finish : {}\".format(ep,total_score,local_iters,finish))\n",
    "            \n",
    "            local_iters += 1\n",
    "            total_iters += 1\n",
    "            \n",
    "        scores.append(total_score)\n",
    "        print(\"Episode {} finished with score {}, result : {} board : {}, epsilon  : {}, learning rate : {} \".format(ep,total_score,finish,board,epsilon,session.run(learning_rate)))\n",
    "        print()\n",
    "        \n",
    "        if((ep+1)%1000==0):\n",
    "            print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))    \n",
    "            print(\"Loss : {}\".format(J[len(J)-1]))\n",
    "            print()\n",
    "            \n",
    "        if(maximum<total_score):\n",
    "            maximum = total_score\n",
    "            episode = ep\n",
    "    print(\"Maximum Score : {} ,Episode : {}\".format(maximum,episode))\n",
    "\n",
    "\n",
    "path = r'/content/MyDrive/MyDrive/RL/Weights/10000'\n",
    "weights = ['conv1_layer1_weights','conv1_layer2_weights','conv2_layer1_weights','conv2_layer2_weights','fc_layer1_weights','fc_layer1_biases','fc_layer2_weights','fc_layer2_biases']\n",
    "for w in weights:\n",
    "    flatten = final_parameters[w].reshape(-1,1)\n",
    "    file = open(path + '/' + w +'.csv','w')\n",
    "    file.write('Sno,Weight\\n')\n",
    "    for i in range(flatten.shape[0]):\n",
    "        file.write(str(i) +',' +str(flatten[i][0])+'\\n') \n",
    "    file.close()\n",
    "    print(w + \" written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMYE_4sq7u89"
   },
   "source": [
    "Store Trained Weights in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OBRjSjPuznDE",
    "outputId": "951eee2a-65d6-4e18-a212-acb52b69e843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_layer1_weights written!\n",
      "conv1_layer2_weights written!\n",
      "conv2_layer1_weights written!\n",
      "conv2_layer2_weights written!\n",
      "fc_layer1_weights written!\n",
      "fc_layer1_biases written!\n",
      "fc_layer2_weights written!\n",
      "fc_layer2_biases written!\n"
     ]
    }
   ],
   "source": [
    "path = r'/content/MyDrive/MyDrive/RL/Weights/Saved'\n",
    "weights = ['conv1_layer1_weights','conv1_layer2_weights','conv2_layer1_weights','conv2_layer2_weights','fc_layer1_weights','fc_layer1_biases','fc_layer2_weights','fc_layer2_biases']\n",
    "for w in weights:\n",
    "    flatten = final_parameters[w].reshape(-1,1)\n",
    "    file = open(path + '/' + w +'.csv','w')\n",
    "    file.write('Sno,Weight\\n')\n",
    "    for i in range(flatten.shape[0]):\n",
    "        file.write(str(i) +',' +str(flatten[i][0])+'\\n') \n",
    "    file.close()\n",
    "    print(w + \" written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdUJ5P2H75HH"
   },
   "source": [
    "Store J and scores too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Rzpcpliv7wOZ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fp = open(\"/content/MyDrive/MyDrive/RL/Weights/Saved/J\", \"wb\")   #Pickling\n",
    "pickle.dump(J, fp)\n",
    "\n",
    "fp = open(\"/content/MyDrive/MyDrive/RL/Weights/Saved/scores\", \"wb\")  #Pickling\n",
    "pickle.dump(scores, fp)\n",
    " \n",
    "# open_file = open(file_name, \"rb\")\n",
    "# loaded_list = pickle.load(open_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8drI4SV8ABR"
   },
   "source": [
    "Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "Rkor3_M578PV",
    "outputId": "ec3efe8f-75fe-48b3-ddce-7af8d9e7bfe7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8104.0 9811\n"
     ]
    }
   ],
   "source": [
    "# plot of scores performance\n",
    "import matplotlib.pyplot as plt\n",
    "avg_scores = []\n",
    "summ = 0\n",
    "for index,value in enumerate(scores):\n",
    "    if((index+1)%100==0):\n",
    "        avg_scores.append(summ/50)\n",
    "        summ=0\n",
    "    summ+=value\n",
    "plt.figure()\n",
    "# Add title and axis names\n",
    "plt.title('Loss Graph')\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylabel('Avg Loss of the 100 games')\n",
    "plt.plot(list(range(len(J)-1)),J[1:])\n",
    "plt.savefig('/content/MyDrive/MyDrive/RL/Weights/Saved/loss_graph.png')\n",
    "plt.show()\n",
    "# Add title and axis names\n",
    "plt.title('Scores Graph')\n",
    "plt.xlabel('Number of Episodes')\n",
    "plt.ylabel('Avg Score of the 100 games')\n",
    "plt.plot(list(range(len(avg_scores))),avg_scores)\n",
    "plt.savefig('/content/MyDrive/MyDrive/RL/Weights/Saved/scores_graph.png')\n",
    "plt.show()\n",
    "print(np.max(scores),np.argmax(scores))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-DQL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
